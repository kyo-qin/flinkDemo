[2019-11-28 00:15:56.056] [org.apache.flink.streaming.api.environment.LocalStreamEnvironment] [main] [108] [INFO ] Running job on local embedded Flink mini cluster
[2019-11-28 00:15:56.056] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [254] [INFO ] Starting Flink Mini Cluster
[2019-11-28 00:15:56.056] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [263] [INFO ] Starting Metrics Registry
[2019-11-28 00:15:56.056] [org.apache.flink.runtime.metrics.MetricRegistryImpl] [main] [114] [INFO ] No metrics reporter configured, no metrics will be exposed/reported.
[2019-11-28 00:15:56.056] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [267] [INFO ] Starting RPC Service(s)
[2019-11-28 00:15:56.056] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1] [flink-akka.actor.default-dispatcher-2] [92] [INFO ] Slf4jLogger started
[2019-11-28 00:15:56.056] [org.apache.flink.runtime.clusterframework.BootstrapTools] [main] [244] [INFO ] Trying to start actor system at :0
[2019-11-28 00:15:56.056] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1] [flink-metrics-2] [92] [INFO ] Slf4jLogger started
[2019-11-28 00:15:56.056] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-2] [83] [INFO ] Starting remoting
[2019-11-28 00:15:56.056] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-2] [83] [INFO ] Remoting started; listening on addresses :[akka.tcp://flink-metrics@192.168.1.14:51903]
[2019-11-28 00:15:56.056] [org.apache.flink.runtime.clusterframework.BootstrapTools] [main] [256] [INFO ] Actor system started at akka.tcp://flink-metrics@192.168.1.14:51903
[2019-11-28 00:15:56.056] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
[2019-11-28 00:15:56.056] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [398] [INFO ] Starting high-availability services
[2019-11-28 00:15:56.056] [org.apache.flink.runtime.blob.BlobServer] [main] [141] [INFO ] Created BLOB server storage directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/blobStore-189f1ca2-8c16-41c1-b821-6b80d6a0c254
[2019-11-28 00:15:56.056] [org.apache.flink.runtime.blob.BlobServer] [main] [203] [INFO ] Started BLOB server at 0.0.0.0:51904 - max concurrent requests: 50 - max backlog: 1000
[2019-11-28 00:15:56.056] [org.apache.flink.runtime.blob.AbstractBlobCache] [main] [107] [INFO ] Created BLOB cache storage directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/blobStore-5882bc1d-a048-4056-a9d8-eb50fcc74893
[2019-11-28 00:15:56.056] [org.apache.flink.runtime.blob.AbstractBlobCache] [main] [107] [INFO ] Created BLOB cache storage directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/blobStore-793bca32-e820-4d18-9619-d0488c9ee9cb
[2019-11-28 00:15:56.056] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [480] [INFO ] Starting 1 TaskManger(s)
[2019-11-28 00:15:56.056] [org.apache.flink.runtime.taskexecutor.TaskManagerRunner] [main] [351] [INFO ] Starting TaskManager with ResourceID: ad331430-ef31-4a9a-b17a-a21f1edda720
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskManagerServices] [main] [519] [INFO ] Temporary file directory '/var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T': total 233 GB, usable 170 GB (72.96% usable)
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [main] [76] [INFO ] FileChannelManager uses directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-io-6d5799a4-e9cb-4c29-a9d4-8a15a2ccaf77 for spill files.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [main] [76] [INFO ] FileChannelManager uses directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-netty-shuffle-3af051a0-c656-46c5-abad-63416a0e6de1 for spill files.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.io.network.buffer.NetworkBufferPool] [main] [140] [INFO ] Allocated 202 MB for network buffer pool (number of memory segments: 6472, bytes per segment: 32768).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.io.network.NettyShuffleEnvironment] [main] [283] [INFO ] Starting the network environment and its components.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.KvStateService] [main] [89] [INFO ] Starting the kvState service and its components.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskManagerServices] [main] [364] [INFO ] Limiting managed memory to 0.7 of the currently free heap space (1267 MB), memory will be allocated lazily.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskManagerConfiguration] [main] [197] [INFO ] Messages have a max timeout of 10000 ms
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-2] [125] [INFO ] Start job leader service.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.filecache.FileCache] [flink-akka.actor.default-dispatcher-2] [107] [INFO ] User file cache uses directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-dist-cache-95a23438-b58b-44d1-8a7f-c9dd67ea8388
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.rest.RestServerEndpoint] [main] [454] [INFO ] Upload directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-web-upload does not exist. 
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.rest.RestServerEndpoint] [main] [476] [INFO ] Created directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-web-upload for file uploads.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.rest.RestServerEndpoint] [main] [136] [INFO ] Starting rest endpoint.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.webmonitor.WebMonitorUtils$LogFileLocation] [main] [87] [WARN ] Log file environment variable 'log.file' is not set.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.webmonitor.WebMonitorUtils$LogFileLocation] [main] [93] [WARN ] JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] [main] [114] [INFO ] Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.rest.RestServerEndpoint] [main] [233] [INFO ] Rest endpoint listening at localhost:51905
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [main] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@1ad8df52 @ http://localhost:51905
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.webmonitor.WebMonitorEndpoint] [mini-cluster-io-thread-1] [711] [INFO ] http://localhost:51905 was granted leadership with leaderSessionID=dfb982c0-6f28-43b5-86a0-14e5d13d1023
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [mini-cluster-io-thread-1] [250] [INFO ] Received confirmation of leadership for leader http://localhost:51905 , session=dfb982c0-6f28-43b5-86a0-14e5d13d1023
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-4] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@6d527a0b @ akka://flink/user/resourcemanager
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-2] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@395c4e6 @ akka://flink/user/dispatcher
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-4] [919] [INFO ] ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token a51296f44d845e884758dbf25131457f
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-2] [885] [INFO ] Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token 6ea6ca51-1e60-4886-99ef-75cfb53f199a
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [363] [INFO ] Flink Mini Cluster started successfully
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-3] [717] [INFO ] Recovering all persisted jobs.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl] [flink-akka.actor.default-dispatcher-4] [215] [INFO ] Starting the SlotManager.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-2] [250] [INFO ] Received confirmation of leadership for leader akka://flink/user/dispatcher , session=6ea6ca51-1e60-4886-99ef-75cfb53f199a
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-3] [250] [INFO ] Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=4758dbf2-5131-457f-a512-96f44d845e88
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [982] [INFO ] Connecting to ResourceManager akka://flink/user/resourcemanager(a51296f44d845e884758dbf25131457f).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-4] [155] [INFO ] Resolved ResourceManager address, beginning registration
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-4] [204] [INFO ] Registration at ResourceManager attempt 1 (timeout=100ms)
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-2] [711] [INFO ] Registering TaskManager with ResourceID ad331430-ef31-4a9a-b17a-a21f1edda720 (akka://flink/user/taskmanager_0) at ResourceManager
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutorToResourceManagerConnection] [flink-akka.actor.default-dispatcher-2] [100] [INFO ] Successful registration at resource manager akka://flink/user/resourcemanager under registration id d8e37ed5a74aa3e2d3c3eacdcfbc198e.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-5] [264] [INFO ] Received JobGraph submission 3ffd409fa6f1f2208fd774f371adfd5c (Window WordCount).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-5] [321] [INFO ] Submitting job 3ffd409fa6f1f2208fd774f371adfd5c (Window WordCount).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [flink-akka.actor.default-dispatcher-2] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-2] [241] [INFO ] Initializing job Window WordCount (3ffd409fa6f1f2208fd774f371adfd5c).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.scheduler.LegacyScheduler] [flink-akka.actor.default-dispatcher-2] [171] [INFO ] Using restart strategy NoRestartStrategy for Window WordCount (3ffd409fa6f1f2208fd774f371adfd5c).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-2] [516] [INFO ] Job recovers via failover strategy: full graph restart
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.ExecutionGraphBuilder] [flink-akka.actor.default-dispatcher-2] [204] [INFO ] Running initialization on master for job Window WordCount (3ffd409fa6f1f2208fd774f371adfd5c).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.ExecutionGraphBuilder] [flink-akka.actor.default-dispatcher-2] [222] [INFO ] Successfully ran initialization on master in 0 ms.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.state.StateBackendLoader] [flink-akka.actor.default-dispatcher-2] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-2] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@6936cada @ akka://flink/user/jobmanager_1
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.JobManagerRunner] [mini-cluster-io-thread-3] [313] [INFO ] JobManager runner for job Window WordCount (3ffd409fa6f1f2208fd774f371adfd5c) was granted leadership with session id a5e66f81-142f-4a63-8b4d-cf899770eba8 at akka://flink/user/jobmanager_1.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-3] [709] [INFO ] Starting execution of job Window WordCount (3ffd409fa6f1f2208fd774f371adfd5c) under job master id 8b4dcf899770eba8a5e66f81142f4a63.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-3] [1324] [INFO ] Job Window WordCount (3ffd409fa6f1f2208fd774f371adfd5c) switched from state CREATED to RUNNING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Socket Stream (1/1) (a05c12d36161847f0001a334895f0770) switched from CREATED to SCHEDULED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-3] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{2854ef2852e7dbb0af4ef66baa4b1f93}]
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Flat Map (1/8) (0d3612057d40c03568b473ffea0ea280) switched from CREATED to SCHEDULED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Flat Map (2/8) (a1331e270071ba9a5e9fd1cd9bf5aa5b) switched from CREATED to SCHEDULED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Flat Map (3/8) (06abc077f270a718b56c798f71535ac9) switched from CREATED to SCHEDULED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Flat Map (4/8) (ebb4af68c665b03da635ba881b16b555) switched from CREATED to SCHEDULED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Flat Map (5/8) (2e3bc122b357383cf8e1eccf7bfff5cd) switched from CREATED to SCHEDULED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Flat Map (6/8) (12e0adfe1b33a96beaa337d07dcc16c5) switched from CREATED to SCHEDULED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Flat Map (7/8) (9433a30a8e14d6c3105aa8cb399c6614) switched from CREATED to SCHEDULED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Flat Map (8/8) (2343a48b815eec63d0d79953790c2954) switched from CREATED to SCHEDULED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8) (34d8454e78bf0a232027194ea93ef047) switched from CREATED to SCHEDULED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8) (a5a6c076649cf00dd82d65d011a65266) switched from CREATED to SCHEDULED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8) (564750312c29d01141ab9265a3489f95) switched from CREATED to SCHEDULED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8) (186610f6583cd1a8129973fe60ad43ec) switched from CREATED to SCHEDULED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8) (c0aa12f9fb53b838e81a51744220eebb) switched from CREATED to SCHEDULED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8) (02778ee96c8d0bbc52b3896c3966a5ce) switched from CREATED to SCHEDULED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8) (d45431d1bf89a7a4f9e74162125048f1) switched from CREATED to SCHEDULED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8) (ccafb461f99dd3f9c3e271fdec5d49b6) switched from CREATED to SCHEDULED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [jobmanager-future-thread-1] [250] [INFO ] Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=a5e66f81-142f-4a63-8b4d-cf899770eba8
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-3] [940] [INFO ] Connecting to ResourceManager akka://flink/user/resourcemanager(a51296f44d845e884758dbf25131457f)
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-3] [155] [INFO ] Resolved ResourceManager address, beginning registration
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-3] [204] [INFO ] Registration at ResourceManager attempt 1 (timeout=100ms)
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-2] [302] [INFO ] Registering job manager 8b4dcf899770eba8a5e66f81142f4a63@akka://flink/user/jobmanager_1 for job 3ffd409fa6f1f2208fd774f371adfd5c.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-5] [657] [INFO ] Registered job manager 8b4dcf899770eba8a5e66f81142f4a63@akka://flink/user/jobmanager_1 for job 3ffd409fa6f1f2208fd774f371adfd5c.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-5] [962] [INFO ] JobManager successfully registered at ResourceManager, leader id: a51296f44d845e884758dbf25131457f.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [319] [INFO ] Requesting new slot [SlotRequestId{2854ef2852e7dbb0af4ef66baa4b1f93}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-2] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 3ffd409fa6f1f2208fd774f371adfd5c with allocation id 89b14a2a1e9b993318eceda1848476a7.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [816] [INFO ] Receive slot request 89b14a2a1e9b993318eceda1848476a7 for job 3ffd409fa6f1f2208fd774f371adfd5c from resource manager with leader id a51296f44d845e884758dbf25131457f.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [828] [INFO ] Allocated slot for 89b14a2a1e9b993318eceda1848476a7.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-5] [193] [INFO ] Add job 3ffd409fa6f1f2208fd774f371adfd5c for job leader monitoring.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-8] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id a5e66f81-142f-4a63-8b4d-cf899770eba8.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-2] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-2] [204] [INFO ] Registration at JobManager attempt 1 (timeout=100ms)
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener$JobManagerRegisteredRpcConnection] [flink-akka.actor.default-dispatcher-4] [382] [INFO ] Successful registration at job manager akka://flink/user/jobmanager_1 for job 3ffd409fa6f1f2208fd774f371adfd5c.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [1220] [INFO ] Establish JobManager connection for job 3ffd409fa6f1f2208fd774f371adfd5c.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [1121] [INFO ] Offer reserved slots to the leader of job 3ffd409fa6f1f2208fd774f371adfd5c.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [319] [INFO ] Requesting new slot [SlotRequestId{2995500df9cb5c96acb5b874bcfb988a}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-4] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 3ffd409fa6f1f2208fd774f371adfd5c with allocation id 8168a0bbe7a1c90b2539dd55253c7b81.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [319] [INFO ] Requesting new slot [SlotRequestId{0c1ddafeddc6f9d2341a8becb0212f63}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request 8168a0bbe7a1c90b2539dd55253c7b81 for job 3ffd409fa6f1f2208fd774f371adfd5c from resource manager with leader id a51296f44d845e884758dbf25131457f.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-4] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 3ffd409fa6f1f2208fd774f371adfd5c with allocation id 4b181b30d311516f1d5de69264e4a197.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for 8168a0bbe7a1c90b2539dd55253c7b81.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [319] [INFO ] Requesting new slot [SlotRequestId{2e28499ed89e7ab5a1e816ba4957c55f}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [1121] [INFO ] Offer reserved slots to the leader of job 3ffd409fa6f1f2208fd774f371adfd5c.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-4] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 3ffd409fa6f1f2208fd774f371adfd5c with allocation id 887912af8e66959eaca51a7d7c83ddb5.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [319] [INFO ] Requesting new slot [SlotRequestId{bdbf45e100e32d4bd028038f5a0950b0}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request 4b181b30d311516f1d5de69264e4a197 for job 3ffd409fa6f1f2208fd774f371adfd5c from resource manager with leader id a51296f44d845e884758dbf25131457f.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-4] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 3ffd409fa6f1f2208fd774f371adfd5c with allocation id abbf8eb715750d0b6a07f501bf5517b1.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [319] [INFO ] Requesting new slot [SlotRequestId{ef1f47e1a0f50389ce973d5c32a02921}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for 4b181b30d311516f1d5de69264e4a197.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [1121] [INFO ] Offer reserved slots to the leader of job 3ffd409fa6f1f2208fd774f371adfd5c.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-4] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 3ffd409fa6f1f2208fd774f371adfd5c with allocation id 8b984717981d0e18811a84ae4a681f3d.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [319] [INFO ] Requesting new slot [SlotRequestId{2d066206ec2da33c0bd9bec9884fc7da}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request 887912af8e66959eaca51a7d7c83ddb5 for job 3ffd409fa6f1f2208fd774f371adfd5c from resource manager with leader id a51296f44d845e884758dbf25131457f.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 3ffd409fa6f1f2208fd774f371adfd5c with allocation id 1143579274d86f8630842db3bf1e1934.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for 887912af8e66959eaca51a7d7c83ddb5.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [319] [INFO ] Requesting new slot [SlotRequestId{f3f11258c4ae3232d41a08f920f73d70}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [1121] [INFO ] Offer reserved slots to the leader of job 3ffd409fa6f1f2208fd774f371adfd5c.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 3ffd409fa6f1f2208fd774f371adfd5c with allocation id a7bf60b1606d2e231478bc1f96682b24.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request abbf8eb715750d0b6a07f501bf5517b1 for job 3ffd409fa6f1f2208fd774f371adfd5c from resource manager with leader id a51296f44d845e884758dbf25131457f.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for abbf8eb715750d0b6a07f501bf5517b1.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [1121] [INFO ] Offer reserved slots to the leader of job 3ffd409fa6f1f2208fd774f371adfd5c.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request 8b984717981d0e18811a84ae4a681f3d for job 3ffd409fa6f1f2208fd774f371adfd5c from resource manager with leader id a51296f44d845e884758dbf25131457f.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [618] [INFO ] Received repeated offer for slot [89b14a2a1e9b993318eceda1848476a7]. Ignoring.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for 8b984717981d0e18811a84ae4a681f3d.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [618] [INFO ] Received repeated offer for slot [8168a0bbe7a1c90b2539dd55253c7b81]. Ignoring.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [1121] [INFO ] Offer reserved slots to the leader of job 3ffd409fa6f1f2208fd774f371adfd5c.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [618] [INFO ] Received repeated offer for slot [89b14a2a1e9b993318eceda1848476a7]. Ignoring.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request 1143579274d86f8630842db3bf1e1934 for job 3ffd409fa6f1f2208fd774f371adfd5c from resource manager with leader id a51296f44d845e884758dbf25131457f.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for 1143579274d86f8630842db3bf1e1934.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [618] [INFO ] Received repeated offer for slot [8168a0bbe7a1c90b2539dd55253c7b81]. Ignoring.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [1121] [INFO ] Offer reserved slots to the leader of job 3ffd409fa6f1f2208fd774f371adfd5c.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [618] [INFO ] Received repeated offer for slot [4b181b30d311516f1d5de69264e4a197]. Ignoring.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [618] [INFO ] Received repeated offer for slot [89b14a2a1e9b993318eceda1848476a7]. Ignoring.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request a7bf60b1606d2e231478bc1f96682b24 for job 3ffd409fa6f1f2208fd774f371adfd5c from resource manager with leader id a51296f44d845e884758dbf25131457f.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [618] [INFO ] Received repeated offer for slot [8168a0bbe7a1c90b2539dd55253c7b81]. Ignoring.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for a7bf60b1606d2e231478bc1f96682b24.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [618] [INFO ] Received repeated offer for slot [887912af8e66959eaca51a7d7c83ddb5]. Ignoring.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [1121] [INFO ] Offer reserved slots to the leader of job 3ffd409fa6f1f2208fd774f371adfd5c.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [618] [INFO ] Received repeated offer for slot [4b181b30d311516f1d5de69264e4a197]. Ignoring.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [618] [INFO ] Received repeated offer for slot [89b14a2a1e9b993318eceda1848476a7]. Ignoring.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 89b14a2a1e9b993318eceda1848476a7.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [618] [INFO ] Received repeated offer for slot [8168a0bbe7a1c90b2539dd55253c7b81]. Ignoring.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 8168a0bbe7a1c90b2539dd55253c7b81.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [618] [INFO ] Received repeated offer for slot [887912af8e66959eaca51a7d7c83ddb5]. Ignoring.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 89b14a2a1e9b993318eceda1848476a7.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [618] [INFO ] Received repeated offer for slot [4b181b30d311516f1d5de69264e4a197]. Ignoring.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 8168a0bbe7a1c90b2539dd55253c7b81.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 89b14a2a1e9b993318eceda1848476a7.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [618] [INFO ] Received repeated offer for slot [abbf8eb715750d0b6a07f501bf5517b1]. Ignoring.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 4b181b30d311516f1d5de69264e4a197.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [618] [INFO ] Received repeated offer for slot [89b14a2a1e9b993318eceda1848476a7]. Ignoring.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 8168a0bbe7a1c90b2539dd55253c7b81.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 887912af8e66959eaca51a7d7c83ddb5.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [618] [INFO ] Received repeated offer for slot [887912af8e66959eaca51a7d7c83ddb5]. Ignoring.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 4b181b30d311516f1d5de69264e4a197.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 89b14a2a1e9b993318eceda1848476a7.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [618] [INFO ] Received repeated offer for slot [abbf8eb715750d0b6a07f501bf5517b1]. Ignoring.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 8168a0bbe7a1c90b2539dd55253c7b81.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [618] [INFO ] Received repeated offer for slot [8168a0bbe7a1c90b2539dd55253c7b81]. Ignoring.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 887912af8e66959eaca51a7d7c83ddb5.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [618] [INFO ] Received repeated offer for slot [4b181b30d311516f1d5de69264e4a197]. Ignoring.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 4b181b30d311516f1d5de69264e4a197.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [618] [INFO ] Received repeated offer for slot [8b984717981d0e18811a84ae4a681f3d]. Ignoring.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot abbf8eb715750d0b6a07f501bf5517b1.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [618] [INFO ] Received repeated offer for slot [89b14a2a1e9b993318eceda1848476a7]. Ignoring.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 89b14a2a1e9b993318eceda1848476a7.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 8168a0bbe7a1c90b2539dd55253c7b81.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [618] [INFO ] Received repeated offer for slot [887912af8e66959eaca51a7d7c83ddb5]. Ignoring.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 887912af8e66959eaca51a7d7c83ddb5.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [618] [INFO ] Received repeated offer for slot [1143579274d86f8630842db3bf1e1934]. Ignoring.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 4b181b30d311516f1d5de69264e4a197.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [618] [INFO ] Received repeated offer for slot [abbf8eb715750d0b6a07f501bf5517b1]. Ignoring.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 8b984717981d0e18811a84ae4a681f3d.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [618] [INFO ] Received repeated offer for slot [8168a0bbe7a1c90b2539dd55253c7b81]. Ignoring.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot abbf8eb715750d0b6a07f501bf5517b1.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [618] [INFO ] Received repeated offer for slot [4b181b30d311516f1d5de69264e4a197]. Ignoring.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 89b14a2a1e9b993318eceda1848476a7.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [618] [INFO ] Received repeated offer for slot [8b984717981d0e18811a84ae4a681f3d]. Ignoring.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 887912af8e66959eaca51a7d7c83ddb5.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 1143579274d86f8630842db3bf1e1934.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot abbf8eb715750d0b6a07f501bf5517b1.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 8168a0bbe7a1c90b2539dd55253c7b81.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 4b181b30d311516f1d5de69264e4a197.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 8b984717981d0e18811a84ae4a681f3d.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 89b14a2a1e9b993318eceda1848476a7.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Socket Stream (1/1) (a05c12d36161847f0001a334895f0770) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [712] [INFO ] Deploying Source: Socket Stream (1/1) (attempt #0) to ad331430-ef31-4a9a-b17a-a21f1edda720 @ localhost (dataPort=-1)
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Flat Map (1/8) (0d3612057d40c03568b473ffea0ea280) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [712] [INFO ] Deploying Flat Map (1/8) (attempt #0) to ad331430-ef31-4a9a-b17a-a21f1edda720 @ localhost (dataPort=-1)
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Flat Map (2/8) (a1331e270071ba9a5e9fd1cd9bf5aa5b) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [712] [INFO ] Deploying Flat Map (2/8) (attempt #0) to ad331430-ef31-4a9a-b17a-a21f1edda720 @ localhost (dataPort=-1)
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Flat Map (3/8) (06abc077f270a718b56c798f71535ac9) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [712] [INFO ] Deploying Flat Map (3/8) (attempt #0) to ad331430-ef31-4a9a-b17a-a21f1edda720 @ localhost (dataPort=-1)
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Flat Map (4/8) (ebb4af68c665b03da635ba881b16b555) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [712] [INFO ] Deploying Flat Map (4/8) (attempt #0) to ad331430-ef31-4a9a-b17a-a21f1edda720 @ localhost (dataPort=-1)
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Flat Map (5/8) (2e3bc122b357383cf8e1eccf7bfff5cd) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [712] [INFO ] Deploying Flat Map (5/8) (attempt #0) to ad331430-ef31-4a9a-b17a-a21f1edda720 @ localhost (dataPort=-1)
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Flat Map (6/8) (12e0adfe1b33a96beaa337d07dcc16c5) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [712] [INFO ] Deploying Flat Map (6/8) (attempt #0) to ad331430-ef31-4a9a-b17a-a21f1edda720 @ localhost (dataPort=-1)
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Flat Map (7/8) (9433a30a8e14d6c3105aa8cb399c6614) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [712] [INFO ] Deploying Flat Map (7/8) (attempt #0) to ad331430-ef31-4a9a-b17a-a21f1edda720 @ localhost (dataPort=-1)
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Flat Map (8/8) (2343a48b815eec63d0d79953790c2954) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [712] [INFO ] Deploying Flat Map (8/8) (attempt #0) to ad331430-ef31-4a9a-b17a-a21f1edda720 @ localhost (dataPort=-1)
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8) (34d8454e78bf0a232027194ea93ef047) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [712] [INFO ] Deploying Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8) (attempt #0) to ad331430-ef31-4a9a-b17a-a21f1edda720 @ localhost (dataPort=-1)
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8) (a5a6c076649cf00dd82d65d011a65266) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [712] [INFO ] Deploying Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8) (attempt #0) to ad331430-ef31-4a9a-b17a-a21f1edda720 @ localhost (dataPort=-1)
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8) (564750312c29d01141ab9265a3489f95) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [712] [INFO ] Deploying Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8) (attempt #0) to ad331430-ef31-4a9a-b17a-a21f1edda720 @ localhost (dataPort=-1)
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8) (186610f6583cd1a8129973fe60ad43ec) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [712] [INFO ] Deploying Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8) (attempt #0) to ad331430-ef31-4a9a-b17a-a21f1edda720 @ localhost (dataPort=-1)
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8) (c0aa12f9fb53b838e81a51744220eebb) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [712] [INFO ] Deploying Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8) (attempt #0) to ad331430-ef31-4a9a-b17a-a21f1edda720 @ localhost (dataPort=-1)
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8) (02778ee96c8d0bbc52b3896c3966a5ce) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [712] [INFO ] Deploying Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8) (attempt #0) to ad331430-ef31-4a9a-b17a-a21f1edda720 @ localhost (dataPort=-1)
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8) (d45431d1bf89a7a4f9e74162125048f1) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [712] [INFO ] Deploying Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8) (attempt #0) to ad331430-ef31-4a9a-b17a-a21f1edda720 @ localhost (dataPort=-1)
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8) (ccafb461f99dd3f9c3e271fdec5d49b6) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [712] [INFO ] Deploying Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8) (attempt #0) to ad331430-ef31-4a9a-b17a-a21f1edda720 @ localhost (dataPort=-1)
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [618] [INFO ] Received repeated offer for slot [89b14a2a1e9b993318eceda1848476a7]. Ignoring.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Source: Socket Stream (1/1).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Source: Socket Stream (1/1)] [958] [INFO ] Source: Socket Stream (1/1) (a05c12d36161847f0001a334895f0770) switched from CREATED to DEPLOYING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Source: Socket Stream (1/1)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Socket Stream (1/1) (a05c12d36161847f0001a334895f0770) [DEPLOYING]
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Source: Socket Stream (1/1)] [593] [INFO ] Loading JAR files for task Source: Socket Stream (1/1) (a05c12d36161847f0001a334895f0770) [DEPLOYING].
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Source: Socket Stream (1/1)] [619] [INFO ] Registering task at network: Source: Socket Stream (1/1) (a05c12d36161847f0001a334895f0770) [DEPLOYING].
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Flat Map (1/8).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (1/8)] [958] [INFO ] Flat Map (1/8) (0d3612057d40c03568b473ffea0ea280) switched from CREATED to DEPLOYING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (1/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Flat Map (1/8) (0d3612057d40c03568b473ffea0ea280) [DEPLOYING]
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (1/8)] [593] [INFO ] Loading JAR files for task Flat Map (1/8) (0d3612057d40c03568b473ffea0ea280) [DEPLOYING].
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Flat Map (2/8).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (2/8)] [958] [INFO ] Flat Map (2/8) (a1331e270071ba9a5e9fd1cd9bf5aa5b) switched from CREATED to DEPLOYING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (2/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Flat Map (2/8) (a1331e270071ba9a5e9fd1cd9bf5aa5b) [DEPLOYING]
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (1/8)] [619] [INFO ] Registering task at network: Flat Map (1/8) (0d3612057d40c03568b473ffea0ea280) [DEPLOYING].
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (2/8)] [593] [INFO ] Loading JAR files for task Flat Map (2/8) (a1331e270071ba9a5e9fd1cd9bf5aa5b) [DEPLOYING].
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (2/8)] [619] [INFO ] Registering task at network: Flat Map (2/8) (a1331e270071ba9a5e9fd1cd9bf5aa5b) [DEPLOYING].
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Flat Map (3/8).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (3/8)] [958] [INFO ] Flat Map (3/8) (06abc077f270a718b56c798f71535ac9) switched from CREATED to DEPLOYING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (3/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Flat Map (3/8) (06abc077f270a718b56c798f71535ac9) [DEPLOYING]
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (3/8)] [593] [INFO ] Loading JAR files for task Flat Map (3/8) (06abc077f270a718b56c798f71535ac9) [DEPLOYING].
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (3/8)] [619] [INFO ] Registering task at network: Flat Map (3/8) (06abc077f270a718b56c798f71535ac9) [DEPLOYING].
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Flat Map (4/8).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (4/8)] [958] [INFO ] Flat Map (4/8) (ebb4af68c665b03da635ba881b16b555) switched from CREATED to DEPLOYING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (4/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Flat Map (4/8) (ebb4af68c665b03da635ba881b16b555) [DEPLOYING]
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (4/8)] [593] [INFO ] Loading JAR files for task Flat Map (4/8) (ebb4af68c665b03da635ba881b16b555) [DEPLOYING].
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (4/8)] [619] [INFO ] Registering task at network: Flat Map (4/8) (ebb4af68c665b03da635ba881b16b555) [DEPLOYING].
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Flat Map (5/8).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (5/8)] [958] [INFO ] Flat Map (5/8) (2e3bc122b357383cf8e1eccf7bfff5cd) switched from CREATED to DEPLOYING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (5/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Flat Map (5/8) (2e3bc122b357383cf8e1eccf7bfff5cd) [DEPLOYING]
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (5/8)] [593] [INFO ] Loading JAR files for task Flat Map (5/8) (2e3bc122b357383cf8e1eccf7bfff5cd) [DEPLOYING].
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (5/8)] [619] [INFO ] Registering task at network: Flat Map (5/8) (2e3bc122b357383cf8e1eccf7bfff5cd) [DEPLOYING].
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Flat Map (6/8).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (6/8)] [958] [INFO ] Flat Map (6/8) (12e0adfe1b33a96beaa337d07dcc16c5) switched from CREATED to DEPLOYING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (6/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Flat Map (6/8) (12e0adfe1b33a96beaa337d07dcc16c5) [DEPLOYING]
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (6/8)] [593] [INFO ] Loading JAR files for task Flat Map (6/8) (12e0adfe1b33a96beaa337d07dcc16c5) [DEPLOYING].
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Source: Socket Stream (1/1)] [958] [INFO ] Source: Socket Stream (1/1) (a05c12d36161847f0001a334895f0770) switched from DEPLOYING to RUNNING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (4/8)] [958] [INFO ] Flat Map (4/8) (ebb4af68c665b03da635ba881b16b555) switched from DEPLOYING to RUNNING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (1/8)] [958] [INFO ] Flat Map (1/8) (0d3612057d40c03568b473ffea0ea280) switched from DEPLOYING to RUNNING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (6/8)] [619] [INFO ] Registering task at network: Flat Map (6/8) (12e0adfe1b33a96beaa337d07dcc16c5) [DEPLOYING].
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (2/8)] [958] [INFO ] Flat Map (2/8) (a1331e270071ba9a5e9fd1cd9bf5aa5b) switched from DEPLOYING to RUNNING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (3/8)] [958] [INFO ] Flat Map (3/8) (06abc077f270a718b56c798f71535ac9) switched from DEPLOYING to RUNNING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (5/8)] [958] [INFO ] Flat Map (5/8) (2e3bc122b357383cf8e1eccf7bfff5cd) switched from DEPLOYING to RUNNING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Flat Map (7/8).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Socket Stream (1/1) (a05c12d36161847f0001a334895f0770) switched from DEPLOYING to RUNNING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Socket Stream (1/1)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.state.StateBackendLoader] [Flat Map (1/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.state.StateBackendLoader] [Flat Map (2/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.state.StateBackendLoader] [Flat Map (4/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.state.StateBackendLoader] [Flat Map (3/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.state.StateBackendLoader] [Flat Map (5/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (7/8)] [958] [INFO ] Flat Map (7/8) (9433a30a8e14d6c3105aa8cb399c6614) switched from CREATED to DEPLOYING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (6/8)] [958] [INFO ] Flat Map (6/8) (12e0adfe1b33a96beaa337d07dcc16c5) switched from DEPLOYING to RUNNING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Flat Map (4/8) (ebb4af68c665b03da635ba881b16b555) switched from DEPLOYING to RUNNING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (7/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Flat Map (7/8) (9433a30a8e14d6c3105aa8cb399c6614) [DEPLOYING]
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.state.StateBackendLoader] [Flat Map (6/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Flat Map (1/8) (0d3612057d40c03568b473ffea0ea280) switched from DEPLOYING to RUNNING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (7/8)] [593] [INFO ] Loading JAR files for task Flat Map (7/8) (9433a30a8e14d6c3105aa8cb399c6614) [DEPLOYING].
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Flat Map (2/8) (a1331e270071ba9a5e9fd1cd9bf5aa5b) switched from DEPLOYING to RUNNING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Flat Map (3/8) (06abc077f270a718b56c798f71535ac9) switched from DEPLOYING to RUNNING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Flat Map (5/8) (2e3bc122b357383cf8e1eccf7bfff5cd) switched from DEPLOYING to RUNNING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Flat Map (8/8).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Flat Map (6/8) (12e0adfe1b33a96beaa337d07dcc16c5) switched from DEPLOYING to RUNNING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (7/8)] [619] [INFO ] Registering task at network: Flat Map (7/8) (9433a30a8e14d6c3105aa8cb399c6614) [DEPLOYING].
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (8/8)] [958] [INFO ] Flat Map (8/8) (2343a48b815eec63d0d79953790c2954) switched from CREATED to DEPLOYING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (8/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Flat Map (8/8) (2343a48b815eec63d0d79953790c2954) [DEPLOYING]
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (8/8)] [593] [INFO ] Loading JAR files for task Flat Map (8/8) (2343a48b815eec63d0d79953790c2954) [DEPLOYING].
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (7/8)] [958] [INFO ] Flat Map (7/8) (9433a30a8e14d6c3105aa8cb399c6614) switched from DEPLOYING to RUNNING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.state.StateBackendLoader] [Flat Map (7/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (8/8)] [619] [INFO ] Registering task at network: Flat Map (8/8) (2343a48b815eec63d0d79953790c2954) [DEPLOYING].
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Flat Map (7/8) (9433a30a8e14d6c3105aa8cb399c6614) switched from DEPLOYING to RUNNING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (8/8)] [958] [INFO ] Flat Map (8/8) (2343a48b815eec63d0d79953790c2954) switched from DEPLOYING to RUNNING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.state.StateBackendLoader] [Flat Map (8/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8)] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8) (34d8454e78bf0a232027194ea93ef047) switched from CREATED to DEPLOYING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Flat Map (8/8) (2343a48b815eec63d0d79953790c2954) switched from DEPLOYING to RUNNING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8) (34d8454e78bf0a232027194ea93ef047) [DEPLOYING]
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8)] [593] [INFO ] Loading JAR files for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8) (34d8454e78bf0a232027194ea93ef047) [DEPLOYING].
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8)] [619] [INFO ] Registering task at network: Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8) (34d8454e78bf0a232027194ea93ef047) [DEPLOYING].
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8)] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8) (a5a6c076649cf00dd82d65d011a65266) switched from CREATED to DEPLOYING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8)] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8) (34d8454e78bf0a232027194ea93ef047) switched from DEPLOYING to RUNNING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8) (a5a6c076649cf00dd82d65d011a65266) [DEPLOYING]
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.state.StateBackendLoader] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8)] [593] [INFO ] Loading JAR files for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8) (a5a6c076649cf00dd82d65d011a65266) [DEPLOYING].
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8) (34d8454e78bf0a232027194ea93ef047) switched from DEPLOYING to RUNNING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8)] [619] [INFO ] Registering task at network: Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8) (a5a6c076649cf00dd82d65d011a65266) [DEPLOYING].
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8)] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8) (564750312c29d01141ab9265a3489f95) switched from CREATED to DEPLOYING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8) (564750312c29d01141ab9265a3489f95) [DEPLOYING]
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8)] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8) (a5a6c076649cf00dd82d65d011a65266) switched from DEPLOYING to RUNNING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8)] [593] [INFO ] Loading JAR files for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8) (564750312c29d01141ab9265a3489f95) [DEPLOYING].
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.state.StateBackendLoader] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8) (a5a6c076649cf00dd82d65d011a65266) switched from DEPLOYING to RUNNING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8)] [619] [INFO ] Registering task at network: Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8) (564750312c29d01141ab9265a3489f95) [DEPLOYING].
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8)] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8) (186610f6583cd1a8129973fe60ad43ec) switched from CREATED to DEPLOYING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8) (186610f6583cd1a8129973fe60ad43ec) [DEPLOYING]
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8)] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8) (564750312c29d01141ab9265a3489f95) switched from DEPLOYING to RUNNING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8)] [593] [INFO ] Loading JAR files for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8) (186610f6583cd1a8129973fe60ad43ec) [DEPLOYING].
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.state.StateBackendLoader] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8) (564750312c29d01141ab9265a3489f95) switched from DEPLOYING to RUNNING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8)] [619] [INFO ] Registering task at network: Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8) (186610f6583cd1a8129973fe60ad43ec) [DEPLOYING].
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.metrics.groups.TaskMetricGroup] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8)] [143] [WARN ] The operator name Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) exceeded the 80 characters length limit and was truncated.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.metrics.groups.TaskMetricGroup] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8)] [143] [WARN ] The operator name Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) exceeded the 80 characters length limit and was truncated.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8)] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8) (186610f6583cd1a8129973fe60ad43ec) switched from DEPLOYING to RUNNING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8)] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8) (c0aa12f9fb53b838e81a51744220eebb) switched from CREATED to DEPLOYING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.state.StateBackendLoader] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8) (c0aa12f9fb53b838e81a51744220eebb) [DEPLOYING]
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.metrics.groups.TaskMetricGroup] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8)] [143] [WARN ] The operator name Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) exceeded the 80 characters length limit and was truncated.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8) (186610f6583cd1a8129973fe60ad43ec) switched from DEPLOYING to RUNNING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8)] [593] [INFO ] Loading JAR files for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8) (c0aa12f9fb53b838e81a51744220eebb) [DEPLOYING].
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.metrics.groups.TaskMetricGroup] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8)] [143] [WARN ] The operator name Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) exceeded the 80 characters length limit and was truncated.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8)] [619] [INFO ] Registering task at network: Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8) (c0aa12f9fb53b838e81a51744220eebb) [DEPLOYING].
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8)] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8) (c0aa12f9fb53b838e81a51744220eebb) switched from DEPLOYING to RUNNING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8)] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8) (02778ee96c8d0bbc52b3896c3966a5ce) switched from CREATED to DEPLOYING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.state.StateBackendLoader] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8) (02778ee96c8d0bbc52b3896c3966a5ce) [DEPLOYING]
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8) (c0aa12f9fb53b838e81a51744220eebb) switched from DEPLOYING to RUNNING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8)] [593] [INFO ] Loading JAR files for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8) (02778ee96c8d0bbc52b3896c3966a5ce) [DEPLOYING].
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8)] [619] [INFO ] Registering task at network: Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8) (02778ee96c8d0bbc52b3896c3966a5ce) [DEPLOYING].
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.metrics.groups.TaskMetricGroup] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8)] [143] [WARN ] The operator name Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) exceeded the 80 characters length limit and was truncated.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8)] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8) (02778ee96c8d0bbc52b3896c3966a5ce) switched from DEPLOYING to RUNNING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8)] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8) (d45431d1bf89a7a4f9e74162125048f1) switched from CREATED to DEPLOYING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.state.StateBackendLoader] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8) (02778ee96c8d0bbc52b3896c3966a5ce) switched from DEPLOYING to RUNNING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8) (d45431d1bf89a7a4f9e74162125048f1) [DEPLOYING]
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8)] [593] [INFO ] Loading JAR files for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8) (d45431d1bf89a7a4f9e74162125048f1) [DEPLOYING].
[2019-11-28 00:15:57.057] [org.apache.flink.streaming.api.functions.source.SocketTextStreamFunction] [Thread-7] [95] [INFO ] Connecting to server socket localhost:9999
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.metrics.groups.TaskMetricGroup] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8)] [143] [WARN ] The operator name Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) exceeded the 80 characters length limit and was truncated.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 887912af8e66959eaca51a7d7c83ddb5.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8)] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8) (ccafb461f99dd3f9c3e271fdec5d49b6) switched from CREATED to DEPLOYING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8)] [619] [INFO ] Registering task at network: Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8) (d45431d1bf89a7a4f9e74162125048f1) [DEPLOYING].
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 1143579274d86f8630842db3bf1e1934.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8) (ccafb461f99dd3f9c3e271fdec5d49b6) [DEPLOYING]
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8)] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8) (d45431d1bf89a7a4f9e74162125048f1) switched from DEPLOYING to RUNNING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot abbf8eb715750d0b6a07f501bf5517b1.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8)] [593] [INFO ] Loading JAR files for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8) (ccafb461f99dd3f9c3e271fdec5d49b6) [DEPLOYING].
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.state.StateBackendLoader] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 8168a0bbe7a1c90b2539dd55253c7b81.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8) (d45431d1bf89a7a4f9e74162125048f1) switched from DEPLOYING to RUNNING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8)] [619] [INFO ] Registering task at network: Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8) (ccafb461f99dd3f9c3e271fdec5d49b6) [DEPLOYING].
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 4b181b30d311516f1d5de69264e4a197.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 8b984717981d0e18811a84ae4a681f3d.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8)] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8) (ccafb461f99dd3f9c3e271fdec5d49b6) switched from DEPLOYING to RUNNING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.metrics.groups.TaskMetricGroup] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8)] [143] [WARN ] The operator name Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) exceeded the 80 characters length limit and was truncated.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot a7bf60b1606d2e231478bc1f96682b24.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.state.StateBackendLoader] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8) (ccafb461f99dd3f9c3e271fdec5d49b6) switched from DEPLOYING to RUNNING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Source: Socket Stream (1/1)] [960] [INFO ] Source: Socket Stream (1/1) (a05c12d36161847f0001a334895f0770) switched from RUNNING to FAILED.
java.lang.Exception: java.net.ConnectException: Connection refused (Connection refused)
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:212) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.performDefaultAction(SourceStreamTask.java:132) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:298) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:403) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) [flink-runtime_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) [flink-runtime_2.11-1.9.0.jar:1.9.0]
	at java.lang.Thread.run(Thread.java:748) [na:1.8.0_131]
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method) ~[na:1.8.0_131]
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) ~[na:1.8.0_131]
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) ~[na:1.8.0_131]
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) ~[na:1.8.0_131]
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) ~[na:1.8.0_131]
	at java.net.Socket.connect(Socket.java:589) ~[na:1.8.0_131]
	at org.apache.flink.streaming.api.functions.source.SocketTextStreamFunction.run(SocketTextStreamFunction.java:96) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:202) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 89b14a2a1e9b993318eceda1848476a7.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.metrics.groups.TaskMetricGroup] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8)] [143] [WARN ] The operator name Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) exceeded the 80 characters length limit and was truncated.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Source: Socket Stream (1/1)] [804] [INFO ] Freeing task resources for Source: Socket Stream (1/1) (a05c12d36161847f0001a334895f0770).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Source: Socket Stream (1/1)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Source: Socket Stream (1/1) (a05c12d36161847f0001a334895f0770) [FAILED]
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.state.heap.HeapKeyedStateBackend] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8)] [140] [INFO ] Initializing heap keyed state backend with stream factory.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.state.heap.HeapKeyedStateBackend] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8)] [140] [INFO ] Initializing heap keyed state backend with stream factory.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.state.heap.HeapKeyedStateBackend] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8)] [140] [INFO ] Initializing heap keyed state backend with stream factory.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.state.heap.HeapKeyedStateBackend] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8)] [140] [INFO ] Initializing heap keyed state backend with stream factory.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.state.heap.HeapKeyedStateBackend] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8)] [140] [INFO ] Initializing heap keyed state backend with stream factory.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.state.heap.HeapKeyedStateBackend] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8)] [140] [INFO ] Initializing heap keyed state backend with stream factory.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.state.heap.HeapKeyedStateBackend] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8)] [140] [INFO ] Initializing heap keyed state backend with stream factory.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.state.heap.HeapKeyedStateBackend] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8)] [140] [INFO ] Initializing heap keyed state backend with stream factory.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [1438] [INFO ] Un-registering task and sending final execution state FAILED to JobManager for task Source: Socket Stream a05c12d36161847f0001a334895f0770.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1493] [INFO ] Source: Socket Stream (1/1) (a05c12d36161847f0001a334895f0770) switched from RUNNING to FAILED.
java.lang.Exception: java.net.ConnectException: Connection refused (Connection refused)
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:212) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.performDefaultAction(SourceStreamTask.java:132) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:298) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:403) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_131]
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method) ~[na:1.8.0_131]
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) ~[na:1.8.0_131]
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) ~[na:1.8.0_131]
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) ~[na:1.8.0_131]
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) ~[na:1.8.0_131]
	at java.net.Socket.connect(Socket.java:589) ~[na:1.8.0_131]
	at org.apache.flink.streaming.api.functions.source.SocketTextStreamFunction.run(SocketTextStreamFunction.java:96) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:202) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-2] [1324] [INFO ] Job Window WordCount (3ffd409fa6f1f2208fd774f371adfd5c) switched from state RUNNING to FAILING.
java.lang.Exception: java.net.ConnectException: Connection refused (Connection refused)
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:212) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.performDefaultAction(SourceStreamTask.java:132) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:298) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:403) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_131]
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method) ~[na:1.8.0_131]
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) ~[na:1.8.0_131]
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) ~[na:1.8.0_131]
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) ~[na:1.8.0_131]
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) ~[na:1.8.0_131]
	at java.net.Socket.connect(Socket.java:589) ~[na:1.8.0_131]
	at org.apache.flink.streaming.api.functions.source.SocketTextStreamFunction.run(SocketTextStreamFunction.java:96) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:202) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Flat Map (1/8) (0d3612057d40c03568b473ffea0ea280) switched from RUNNING to CANCELING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [982] [INFO ] Attempting to cancel task Flat Map (1/8) (0d3612057d40c03568b473ffea0ea280).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [958] [INFO ] Flat Map (1/8) (0d3612057d40c03568b473ffea0ea280) switched from RUNNING to CANCELING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [1031] [INFO ] Triggering cancellation of task code Flat Map (1/8) (0d3612057d40c03568b473ffea0ea280).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Flat Map (2/8) (a1331e270071ba9a5e9fd1cd9bf5aa5b) switched from RUNNING to CANCELING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Flat Map (3/8) (06abc077f270a718b56c798f71535ac9) switched from RUNNING to CANCELING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (1/8)] [958] [INFO ] Flat Map (1/8) (0d3612057d40c03568b473ffea0ea280) switched from CANCELING to CANCELED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [982] [INFO ] Attempting to cancel task Flat Map (2/8) (a1331e270071ba9a5e9fd1cd9bf5aa5b).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (1/8)] [804] [INFO ] Freeing task resources for Flat Map (1/8) (0d3612057d40c03568b473ffea0ea280).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Flat Map (4/8) (ebb4af68c665b03da635ba881b16b555) switched from RUNNING to CANCELING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [958] [INFO ] Flat Map (2/8) (a1331e270071ba9a5e9fd1cd9bf5aa5b) switched from RUNNING to CANCELING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (1/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Flat Map (1/8) (0d3612057d40c03568b473ffea0ea280) [CANCELED]
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [1031] [INFO ] Triggering cancellation of task code Flat Map (2/8) (a1331e270071ba9a5e9fd1cd9bf5aa5b).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Flat Map (5/8) (2e3bc122b357383cf8e1eccf7bfff5cd) switched from RUNNING to CANCELING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Flat Map (6/8) (12e0adfe1b33a96beaa337d07dcc16c5) switched from RUNNING to CANCELING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (2/8)] [958] [INFO ] Flat Map (2/8) (a1331e270071ba9a5e9fd1cd9bf5aa5b) switched from CANCELING to CANCELED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [982] [INFO ] Attempting to cancel task Flat Map (3/8) (06abc077f270a718b56c798f71535ac9).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (2/8)] [804] [INFO ] Freeing task resources for Flat Map (2/8) (a1331e270071ba9a5e9fd1cd9bf5aa5b).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Flat Map (7/8) (9433a30a8e14d6c3105aa8cb399c6614) switched from RUNNING to CANCELING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [958] [INFO ] Flat Map (3/8) (06abc077f270a718b56c798f71535ac9) switched from RUNNING to CANCELING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (2/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Flat Map (2/8) (a1331e270071ba9a5e9fd1cd9bf5aa5b) [CANCELED]
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [1031] [INFO ] Triggering cancellation of task code Flat Map (3/8) (06abc077f270a718b56c798f71535ac9).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Flat Map (8/8) (2343a48b815eec63d0d79953790c2954) switched from RUNNING to CANCELING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8) (34d8454e78bf0a232027194ea93ef047) switched from RUNNING to CANCELING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [982] [INFO ] Attempting to cancel task Flat Map (4/8) (ebb4af68c665b03da635ba881b16b555).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (3/8)] [958] [INFO ] Flat Map (3/8) (06abc077f270a718b56c798f71535ac9) switched from CANCELING to CANCELED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8) (a5a6c076649cf00dd82d65d011a65266) switched from RUNNING to CANCELING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [958] [INFO ] Flat Map (4/8) (ebb4af68c665b03da635ba881b16b555) switched from RUNNING to CANCELING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (3/8)] [804] [INFO ] Freeing task resources for Flat Map (3/8) (06abc077f270a718b56c798f71535ac9).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [1031] [INFO ] Triggering cancellation of task code Flat Map (4/8) (ebb4af68c665b03da635ba881b16b555).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8) (564750312c29d01141ab9265a3489f95) switched from RUNNING to CANCELING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (3/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Flat Map (3/8) (06abc077f270a718b56c798f71535ac9) [CANCELED]
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8) (186610f6583cd1a8129973fe60ad43ec) switched from RUNNING to CANCELING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Flat Map 0d3612057d40c03568b473ffea0ea280.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (4/8)] [958] [INFO ] Flat Map (4/8) (ebb4af68c665b03da635ba881b16b555) switched from CANCELING to CANCELED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8) (c0aa12f9fb53b838e81a51744220eebb) switched from RUNNING to CANCELING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (4/8)] [804] [INFO ] Freeing task resources for Flat Map (4/8) (ebb4af68c665b03da635ba881b16b555).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [982] [INFO ] Attempting to cancel task Flat Map (5/8) (2e3bc122b357383cf8e1eccf7bfff5cd).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8) (02778ee96c8d0bbc52b3896c3966a5ce) switched from RUNNING to CANCELING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (4/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Flat Map (4/8) (ebb4af68c665b03da635ba881b16b555) [CANCELED]
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [958] [INFO ] Flat Map (5/8) (2e3bc122b357383cf8e1eccf7bfff5cd) switched from RUNNING to CANCELING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8) (d45431d1bf89a7a4f9e74162125048f1) switched from RUNNING to CANCELING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [1031] [INFO ] Triggering cancellation of task code Flat Map (5/8) (2e3bc122b357383cf8e1eccf7bfff5cd).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8) (ccafb461f99dd3f9c3e271fdec5d49b6) switched from RUNNING to CANCELING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [982] [INFO ] Attempting to cancel task Flat Map (6/8) (12e0adfe1b33a96beaa337d07dcc16c5).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (5/8)] [958] [INFO ] Flat Map (5/8) (2e3bc122b357383cf8e1eccf7bfff5cd) switched from CANCELING to CANCELED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [958] [INFO ] Flat Map (6/8) (12e0adfe1b33a96beaa337d07dcc16c5) switched from RUNNING to CANCELING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (5/8)] [804] [INFO ] Freeing task resources for Flat Map (5/8) (2e3bc122b357383cf8e1eccf7bfff5cd).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [1031] [INFO ] Triggering cancellation of task code Flat Map (6/8) (12e0adfe1b33a96beaa337d07dcc16c5).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (5/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Flat Map (5/8) (2e3bc122b357383cf8e1eccf7bfff5cd) [CANCELED]
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [982] [INFO ] Attempting to cancel task Flat Map (7/8) (9433a30a8e14d6c3105aa8cb399c6614).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (6/8)] [958] [INFO ] Flat Map (6/8) (12e0adfe1b33a96beaa337d07dcc16c5) switched from CANCELING to CANCELED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [958] [INFO ] Flat Map (7/8) (9433a30a8e14d6c3105aa8cb399c6614) switched from RUNNING to CANCELING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (6/8)] [804] [INFO ] Freeing task resources for Flat Map (6/8) (12e0adfe1b33a96beaa337d07dcc16c5).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [1031] [INFO ] Triggering cancellation of task code Flat Map (7/8) (9433a30a8e14d6c3105aa8cb399c6614).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (6/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Flat Map (6/8) (12e0adfe1b33a96beaa337d07dcc16c5) [CANCELED]
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (7/8)] [958] [INFO ] Flat Map (7/8) (9433a30a8e14d6c3105aa8cb399c6614) switched from CANCELING to CANCELED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Flat Map a1331e270071ba9a5e9fd1cd9bf5aa5b.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (7/8)] [804] [INFO ] Freeing task resources for Flat Map (7/8) (9433a30a8e14d6c3105aa8cb399c6614).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (7/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Flat Map (7/8) (9433a30a8e14d6c3105aa8cb399c6614) [CANCELED]
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [982] [INFO ] Attempting to cancel task Flat Map (8/8) (2343a48b815eec63d0d79953790c2954).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [958] [INFO ] Flat Map (8/8) (2343a48b815eec63d0d79953790c2954) switched from RUNNING to CANCELING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [1031] [INFO ] Triggering cancellation of task code Flat Map (8/8) (2343a48b815eec63d0d79953790c2954).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Flat Map (1/8) (0d3612057d40c03568b473ffea0ea280) switched from CANCELING to CANCELED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [982] [INFO ] Attempting to cancel task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8) (34d8454e78bf0a232027194ea93ef047).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (8/8)] [958] [INFO ] Flat Map (8/8) (2343a48b815eec63d0d79953790c2954) switched from CANCELING to CANCELED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8) (34d8454e78bf0a232027194ea93ef047) switched from RUNNING to CANCELING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (8/8)] [804] [INFO ] Freeing task resources for Flat Map (8/8) (2343a48b815eec63d0d79953790c2954).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [1031] [INFO ] Triggering cancellation of task code Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8) (34d8454e78bf0a232027194ea93ef047).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (8/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Flat Map (8/8) (2343a48b815eec63d0d79953790c2954) [CANCELED]
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Flat Map (2/8) (a1331e270071ba9a5e9fd1cd9bf5aa5b) switched from CANCELING to CANCELED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [982] [INFO ] Attempting to cancel task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8) (a5a6c076649cf00dd82d65d011a65266).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8)] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8) (34d8454e78bf0a232027194ea93ef047) switched from CANCELING to CANCELED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8) (a5a6c076649cf00dd82d65d011a65266) switched from RUNNING to CANCELING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8)] [804] [INFO ] Freeing task resources for Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8) (34d8454e78bf0a232027194ea93ef047).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [1031] [INFO ] Triggering cancellation of task code Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8) (a5a6c076649cf00dd82d65d011a65266).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8) (34d8454e78bf0a232027194ea93ef047) [CANCELED]
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8)] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8) (a5a6c076649cf00dd82d65d011a65266) switched from CANCELING to CANCELED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8)] [804] [INFO ] Freeing task resources for Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8) (a5a6c076649cf00dd82d65d011a65266).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Flat Map 06abc077f270a718b56c798f71535ac9.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8) (a5a6c076649cf00dd82d65d011a65266) [CANCELED]
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [982] [INFO ] Attempting to cancel task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8) (564750312c29d01141ab9265a3489f95).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Flat Map (3/8) (06abc077f270a718b56c798f71535ac9) switched from CANCELING to CANCELED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8) (564750312c29d01141ab9265a3489f95) switched from RUNNING to CANCELING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [1031] [INFO ] Triggering cancellation of task code Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8) (564750312c29d01141ab9265a3489f95).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8)] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8) (564750312c29d01141ab9265a3489f95) switched from CANCELING to CANCELED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [982] [INFO ] Attempting to cancel task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8) (186610f6583cd1a8129973fe60ad43ec).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8)] [804] [INFO ] Freeing task resources for Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8) (564750312c29d01141ab9265a3489f95).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8) (186610f6583cd1a8129973fe60ad43ec) switched from RUNNING to CANCELING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8) (564750312c29d01141ab9265a3489f95) [CANCELED]
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [1031] [INFO ] Triggering cancellation of task code Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8) (186610f6583cd1a8129973fe60ad43ec).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8)] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8) (186610f6583cd1a8129973fe60ad43ec) switched from CANCELING to CANCELED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [982] [INFO ] Attempting to cancel task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8) (c0aa12f9fb53b838e81a51744220eebb).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8)] [804] [INFO ] Freeing task resources for Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8) (186610f6583cd1a8129973fe60ad43ec).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8) (c0aa12f9fb53b838e81a51744220eebb) switched from RUNNING to CANCELING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8) (186610f6583cd1a8129973fe60ad43ec) [CANCELED]
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [1031] [INFO ] Triggering cancellation of task code Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8) (c0aa12f9fb53b838e81a51744220eebb).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8)] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8) (c0aa12f9fb53b838e81a51744220eebb) switched from CANCELING to CANCELED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Flat Map ebb4af68c665b03da635ba881b16b555.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8)] [804] [INFO ] Freeing task resources for Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8) (c0aa12f9fb53b838e81a51744220eebb).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8) (c0aa12f9fb53b838e81a51744220eebb) [CANCELED]
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [982] [INFO ] Attempting to cancel task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8) (02778ee96c8d0bbc52b3896c3966a5ce).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8) (02778ee96c8d0bbc52b3896c3966a5ce) switched from RUNNING to CANCELING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Flat Map (4/8) (ebb4af68c665b03da635ba881b16b555) switched from CANCELING to CANCELED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [1031] [INFO ] Triggering cancellation of task code Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8) (02778ee96c8d0bbc52b3896c3966a5ce).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8)] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8) (02778ee96c8d0bbc52b3896c3966a5ce) switched from CANCELING to CANCELED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [982] [INFO ] Attempting to cancel task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8) (d45431d1bf89a7a4f9e74162125048f1).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8)] [804] [INFO ] Freeing task resources for Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8) (02778ee96c8d0bbc52b3896c3966a5ce).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8) (d45431d1bf89a7a4f9e74162125048f1) switched from RUNNING to CANCELING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8) (02778ee96c8d0bbc52b3896c3966a5ce) [CANCELED]
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [1031] [INFO ] Triggering cancellation of task code Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8) (d45431d1bf89a7a4f9e74162125048f1).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8)] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8) (d45431d1bf89a7a4f9e74162125048f1) switched from CANCELING to CANCELED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8)] [804] [INFO ] Freeing task resources for Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8) (d45431d1bf89a7a4f9e74162125048f1).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8) (d45431d1bf89a7a4f9e74162125048f1) [CANCELED]
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [982] [INFO ] Attempting to cancel task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8) (ccafb461f99dd3f9c3e271fdec5d49b6).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8) (ccafb461f99dd3f9c3e271fdec5d49b6) switched from RUNNING to CANCELING.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-3] [1031] [INFO ] Triggering cancellation of task code Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8) (ccafb461f99dd3f9c3e271fdec5d49b6).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8)] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8) (ccafb461f99dd3f9c3e271fdec5d49b6) switched from CANCELING to CANCELED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Flat Map 2e3bc122b357383cf8e1eccf7bfff5cd.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8)] [804] [INFO ] Freeing task resources for Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8) (ccafb461f99dd3f9c3e271fdec5d49b6).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Flat Map 12e0adfe1b33a96beaa337d07dcc16c5.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Flat Map (5/8) (2e3bc122b357383cf8e1eccf7bfff5cd) switched from CANCELING to CANCELED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8) (ccafb461f99dd3f9c3e271fdec5d49b6) [CANCELED]
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Flat Map 9433a30a8e14d6c3105aa8cb399c6614.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Flat Map (6/8) (12e0adfe1b33a96beaa337d07dcc16c5) switched from CANCELING to CANCELED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Flat Map 2343a48b815eec63d0d79953790c2954.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out 34d8454e78bf0a232027194ea93ef047.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Flat Map (7/8) (9433a30a8e14d6c3105aa8cb399c6614) switched from CANCELING to CANCELED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out a5a6c076649cf00dd82d65d011a65266.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out 564750312c29d01141ab9265a3489f95.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Flat Map (8/8) (2343a48b815eec63d0d79953790c2954) switched from CANCELING to CANCELED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out 186610f6583cd1a8129973fe60ad43ec.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out c0aa12f9fb53b838e81a51744220eebb.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8) (34d8454e78bf0a232027194ea93ef047) switched from CANCELING to CANCELED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out 02778ee96c8d0bbc52b3896c3966a5ce.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out d45431d1bf89a7a4f9e74162125048f1.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out ccafb461f99dd3f9c3e271fdec5d49b6.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8) (a5a6c076649cf00dd82d65d011a65266) switched from CANCELING to CANCELED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8) (564750312c29d01141ab9265a3489f95) switched from CANCELING to CANCELED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8) (186610f6583cd1a8129973fe60ad43ec) switched from CANCELING to CANCELED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8) (c0aa12f9fb53b838e81a51744220eebb) switched from CANCELING to CANCELED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8) (02778ee96c8d0bbc52b3896c3966a5ce) switched from CANCELING to CANCELED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8) (d45431d1bf89a7a4f9e74162125048f1) switched from CANCELING to CANCELED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8) (ccafb461f99dd3f9c3e271fdec5d49b6) switched from CANCELING to CANCELED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-5] [1446] [INFO ] Try to restart or fail the job Window WordCount (3ffd409fa6f1f2208fd774f371adfd5c) if no longer possible.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-5] [1324] [INFO ] Job Window WordCount (3ffd409fa6f1f2208fd774f371adfd5c) switched from state FAILING to FAILED.
java.lang.Exception: java.net.ConnectException: Connection refused (Connection refused)
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:212) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.performDefaultAction(SourceStreamTask.java:132) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:298) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:403) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_131]
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method) ~[na:1.8.0_131]
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) ~[na:1.8.0_131]
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) ~[na:1.8.0_131]
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) ~[na:1.8.0_131]
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) ~[na:1.8.0_131]
	at java.net.Socket.connect(Socket.java:589) ~[na:1.8.0_131]
	at org.apache.flink.streaming.api.functions.source.SocketTextStreamFunction.run(SocketTextStreamFunction.java:96) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:202) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-5] [1472] [INFO ] Could not restart the job Window WordCount (3ffd409fa6f1f2208fd774f371adfd5c) because the restart strategy prevented it.
java.lang.Exception: java.net.ConnectException: Connection refused (Connection refused)
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:212) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.performDefaultAction(SourceStreamTask.java:132) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:298) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:403) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_131]
Caused by: java.net.ConnectException: Connection refused (Connection refused)
	at java.net.PlainSocketImpl.socketConnect(Native Method) ~[na:1.8.0_131]
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350) ~[na:1.8.0_131]
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206) ~[na:1.8.0_131]
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188) ~[na:1.8.0_131]
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392) ~[na:1.8.0_131]
	at java.net.Socket.connect(Socket.java:589) ~[na:1.8.0_131]
	at org.apache.flink.streaming.api.functions.source.SocketTextStreamFunction.run(SocketTextStreamFunction.java:96) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:202) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.checkpoint.CheckpointCoordinator] [flink-akka.actor.default-dispatcher-5] [329] [INFO ] Stopping checkpoint coordinator for job 3ffd409fa6f1f2208fd774f371adfd5c.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore] [flink-akka.actor.default-dispatcher-5] [97] [INFO ] Shutting down
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-3] [775] [INFO ] Job 3ffd409fa6f1f2208fd774f371adfd5c reached globally terminal state FAILED.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [417] [INFO ] Shutting down Flink Mini Cluster
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [334] [INFO ] Stopping TaskExecutor akka://flink/user/taskmanager_0.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.rest.RestServerEndpoint] [main] [290] [INFO ] Shutting down rest endpoint.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-4] [142] [INFO ] Stop job leader service.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-5] [335] [INFO ] Stopping the JobMaster for job Window WordCount(3ffd409fa6f1f2208fd774f371adfd5c).
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager] [flink-akka.actor.default-dispatcher-4] [213] [INFO ] Shutting down TaskExecutorLocalStateStoresManager.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [228] [INFO ] Suspending SlotPool.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-5] [1010] [INFO ] Close ResourceManager connection 8fc0f946d3eabc2cf856f98fe445ba68: JobManager is shutting down..
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [249] [INFO ] Stopping SlotPool.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [774] [INFO ] Disconnect job manager 8b4dcf899770eba8a5e66f81142f4a63@akka://flink/user/jobmanager_1 for job 3ffd409fa6f1f2208fd774f371adfd5c from the resource manager.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [flink-akka.actor.default-dispatcher-4] [112] [INFO ] FileChannelManager removed spill file directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-io-6d5799a4-e9cb-4c29-a9d4-8a15a2ccaf77
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.io.network.NettyShuffleEnvironment] [flink-akka.actor.default-dispatcher-4] [304] [INFO ] Shutting down the network environment and its components.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [flink-akka.actor.default-dispatcher-4] [112] [INFO ] FileChannelManager removed spill file directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-netty-shuffle-3af051a0-c656-46c5-abad-63416a0e6de1
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.KvStateService] [flink-akka.actor.default-dispatcher-4] [119] [INFO ] Shutting down the kvState service and its components.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-4] [142] [INFO ] Stop job leader service.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.filecache.FileCache] [flink-akka.actor.default-dispatcher-4] [153] [INFO ] removed file cache directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-dist-cache-95a23438-b58b-44d1-8a7f-c9dd67ea8388
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [359] [INFO ] Stopped TaskExecutor akka://flink/user/taskmanager_0.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.webmonitor.WebMonitorEndpoint] [ForkJoinPool.commonPool-worker-1] [687] [INFO ] Removing cache directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-web-ui
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.rest.RestServerEndpoint] [ForkJoinPool.commonPool-worker-1] [299] [INFO ] Shut down complete.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [499] [INFO ] Shut down cluster because application is in CANCELED, diagnostics DispatcherResourceManagerComponent has been closed..
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-3] [220] [INFO ] Stopping dispatcher akka://flink/user/dispatcher.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl] [flink-akka.actor.default-dispatcher-5] [280] [INFO ] Closing the SlotManager.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-3] [697] [INFO ] Stopping all currently running jobs of dispatcher akka://flink/user/dispatcher.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl] [flink-akka.actor.default-dispatcher-5] [243] [INFO ] Suspending the SlotManager.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.rest.handler.legacy.backpressure.StackTraceSampleCoordinator] [flink-akka.actor.default-dispatcher-3] [220] [INFO ] Shutting down stack trace sample coordinator.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-3] [229] [INFO ] Stopped dispatcher akka://flink/user/dispatcher.
[2019-11-28 00:15:57.057] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [flink-akka.actor.default-dispatcher-3] [335] [INFO ] Stopping Akka RPC service.
[2019-11-28 00:15:57.057] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-2] [83] [INFO ] Shutting down remote daemon.
[2019-11-28 00:15:57.057] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-2] [83] [INFO ] Remote daemon shut down; proceeding with flushing remote transports.
[2019-11-28 00:15:58.058] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-2] [83] [INFO ] Remoting shut down.
[2019-11-28 00:15:58.058] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [flink-metrics-2] [335] [INFO ] Stopping Akka RPC service.
[2019-11-28 00:15:58.058] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [flink-metrics-2] [354] [INFO ] Stopped Akka RPC service.
[2019-11-28 00:15:58.058] [org.apache.flink.runtime.blob.AbstractBlobCache] [flink-akka.actor.default-dispatcher-4] [247] [INFO ] Shutting down BLOB cache
[2019-11-28 00:15:58.058] [org.apache.flink.runtime.blob.AbstractBlobCache] [flink-akka.actor.default-dispatcher-4] [247] [INFO ] Shutting down BLOB cache
[2019-11-28 00:15:58.058] [org.apache.flink.runtime.blob.BlobServer] [flink-akka.actor.default-dispatcher-4] [340] [INFO ] Stopped BLOB server at 0.0.0.0:51904
[2019-11-28 00:15:58.058] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [flink-akka.actor.default-dispatcher-4] [354] [INFO ] Stopped Akka RPC service.
[2019-11-28 00:16:38.038] [org.apache.flink.streaming.api.environment.LocalStreamEnvironment] [main] [108] [INFO ] Running job on local embedded Flink mini cluster
[2019-11-28 00:16:38.038] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [254] [INFO ] Starting Flink Mini Cluster
[2019-11-28 00:16:38.038] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [263] [INFO ] Starting Metrics Registry
[2019-11-28 00:16:38.038] [org.apache.flink.runtime.metrics.MetricRegistryImpl] [main] [114] [INFO ] No metrics reporter configured, no metrics will be exposed/reported.
[2019-11-28 00:16:38.038] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [267] [INFO ] Starting RPC Service(s)
[2019-11-28 00:16:38.038] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1] [flink-akka.actor.default-dispatcher-3] [92] [INFO ] Slf4jLogger started
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.clusterframework.BootstrapTools] [main] [244] [INFO ] Trying to start actor system at :0
[2019-11-28 00:16:39.039] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1] [flink-metrics-2] [92] [INFO ] Slf4jLogger started
[2019-11-28 00:16:39.039] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-2] [83] [INFO ] Starting remoting
[2019-11-28 00:16:39.039] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-2] [83] [INFO ] Remoting started; listening on addresses :[akka.tcp://flink-metrics@192.168.1.14:51917]
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.clusterframework.BootstrapTools] [main] [256] [INFO ] Actor system started at akka.tcp://flink-metrics@192.168.1.14:51917
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [398] [INFO ] Starting high-availability services
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.blob.BlobServer] [main] [141] [INFO ] Created BLOB server storage directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/blobStore-9d5076ee-9c40-443d-ae4f-b5400e9ea256
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.blob.BlobServer] [main] [203] [INFO ] Started BLOB server at 0.0.0.0:51918 - max concurrent requests: 50 - max backlog: 1000
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.blob.AbstractBlobCache] [main] [107] [INFO ] Created BLOB cache storage directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/blobStore-dde6412d-93f8-44c3-a4e8-0ad7d29ce73a
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.blob.AbstractBlobCache] [main] [107] [INFO ] Created BLOB cache storage directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/blobStore-84faff3b-353e-46ea-bdb1-598d08f5bd04
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [480] [INFO ] Starting 1 TaskManger(s)
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.taskexecutor.TaskManagerRunner] [main] [351] [INFO ] Starting TaskManager with ResourceID: 3a610323-f3d2-47f6-bc54-d294c2188d7c
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.taskexecutor.TaskManagerServices] [main] [519] [INFO ] Temporary file directory '/var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T': total 233 GB, usable 170 GB (72.96% usable)
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [main] [76] [INFO ] FileChannelManager uses directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-io-899014cc-7f8b-4819-981a-6177cc8045dd for spill files.
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [main] [76] [INFO ] FileChannelManager uses directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-netty-shuffle-e782e667-e762-48a3-88bb-850e81ff132e for spill files.
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.io.network.buffer.NetworkBufferPool] [main] [140] [INFO ] Allocated 202 MB for network buffer pool (number of memory segments: 6472, bytes per segment: 32768).
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.io.network.NettyShuffleEnvironment] [main] [283] [INFO ] Starting the network environment and its components.
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.taskexecutor.KvStateService] [main] [89] [INFO ] Starting the kvState service and its components.
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.taskexecutor.TaskManagerServices] [main] [364] [INFO ] Limiting managed memory to 0.7 of the currently free heap space (1267 MB), memory will be allocated lazily.
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.taskexecutor.TaskManagerConfiguration] [main] [197] [INFO ] Messages have a max timeout of 10000 ms
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-3] [125] [INFO ] Start job leader service.
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.filecache.FileCache] [flink-akka.actor.default-dispatcher-3] [107] [INFO ] User file cache uses directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-dist-cache-52301fdd-169b-4f63-a912-f7526327e563
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.rest.RestServerEndpoint] [main] [136] [INFO ] Starting rest endpoint.
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.webmonitor.WebMonitorUtils$LogFileLocation] [main] [87] [WARN ] Log file environment variable 'log.file' is not set.
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.webmonitor.WebMonitorUtils$LogFileLocation] [main] [93] [WARN ] JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] [main] [114] [INFO ] Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.rest.RestServerEndpoint] [main] [233] [INFO ] Rest endpoint listening at localhost:51919
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [main] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@1ad8df52 @ http://localhost:51919
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.webmonitor.WebMonitorEndpoint] [mini-cluster-io-thread-1] [711] [INFO ] http://localhost:51919 was granted leadership with leaderSessionID=094a6b7c-00f7-461f-86c1-e9f048ba1600
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [mini-cluster-io-thread-1] [250] [INFO ] Received confirmation of leadership for leader http://localhost:51919 , session=094a6b7c-00f7-461f-86c1-e9f048ba1600
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-3] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@1b1548e8 @ akka://flink/user/resourcemanager
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-2] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@54f01dea @ akka://flink/user/dispatcher
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-2] [885] [INFO ] Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token 713a4023-5df1-41b8-84a8-21a4a473c1fe
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [919] [INFO ] ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token 827e383deb367599fea4104820e042e5
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [363] [INFO ] Flink Mini Cluster started successfully
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-4] [717] [INFO ] Recovering all persisted jobs.
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl] [flink-akka.actor.default-dispatcher-3] [215] [INFO ] Starting the SlotManager.
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-4] [250] [INFO ] Received confirmation of leadership for leader akka://flink/user/dispatcher , session=713a4023-5df1-41b8-84a8-21a4a473c1fe
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-4] [250] [INFO ] Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=fea41048-20e0-42e5-827e-383deb367599
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [982] [INFO ] Connecting to ResourceManager akka://flink/user/resourcemanager(827e383deb367599fea4104820e042e5).
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-4] [155] [INFO ] Resolved ResourceManager address, beginning registration
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-4] [204] [INFO ] Registration at ResourceManager attempt 1 (timeout=100ms)
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-2] [711] [INFO ] Registering TaskManager with ResourceID 3a610323-f3d2-47f6-bc54-d294c2188d7c (akka://flink/user/taskmanager_0) at ResourceManager
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-5] [264] [INFO ] Received JobGraph submission 08ff3bb8572602a312ec0aebd0e317de (Window WordCount).
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.taskexecutor.TaskExecutorToResourceManagerConnection] [flink-akka.actor.default-dispatcher-2] [100] [INFO ] Successful registration at resource manager akka://flink/user/resourcemanager under registration id bc29a5db77c5c1a09aebb5f4c4076a12.
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-5] [321] [INFO ] Submitting job 08ff3bb8572602a312ec0aebd0e317de (Window WordCount).
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [flink-akka.actor.default-dispatcher-2] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-2] [241] [INFO ] Initializing job Window WordCount (08ff3bb8572602a312ec0aebd0e317de).
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.scheduler.LegacyScheduler] [flink-akka.actor.default-dispatcher-2] [171] [INFO ] Using restart strategy NoRestartStrategy for Window WordCount (08ff3bb8572602a312ec0aebd0e317de).
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-2] [516] [INFO ] Job recovers via failover strategy: full graph restart
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.executiongraph.ExecutionGraphBuilder] [flink-akka.actor.default-dispatcher-2] [204] [INFO ] Running initialization on master for job Window WordCount (08ff3bb8572602a312ec0aebd0e317de).
[2019-11-28 00:16:39.039] [org.apache.flink.runtime.executiongraph.ExecutionGraphBuilder] [flink-akka.actor.default-dispatcher-2] [222] [INFO ] Successfully ran initialization on master in 0 ms.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.state.StateBackendLoader] [flink-akka.actor.default-dispatcher-2] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-2] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@118f501 @ akka://flink/user/jobmanager_1
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.jobmaster.JobManagerRunner] [mini-cluster-io-thread-3] [313] [INFO ] JobManager runner for job Window WordCount (08ff3bb8572602a312ec0aebd0e317de) was granted leadership with session id 9158a477-c87b-40b0-93ce-13846840bf28 at akka://flink/user/jobmanager_1.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-3] [709] [INFO ] Starting execution of job Window WordCount (08ff3bb8572602a312ec0aebd0e317de) under job master id 93ce13846840bf289158a477c87b40b0.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-3] [1324] [INFO ] Job Window WordCount (08ff3bb8572602a312ec0aebd0e317de) switched from state CREATED to RUNNING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Socket Stream (1/1) (754a6105304abdfaa6a032126146feba) switched from CREATED to SCHEDULED.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-3] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{f7552715e1b6913cd037110b80841aea}]
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Flat Map (1/8) (d2f6d093d9e9ca6952eb7446d67cd00f) switched from CREATED to SCHEDULED.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Flat Map (2/8) (43bc735f996ca31b34c2f780be4c6301) switched from CREATED to SCHEDULED.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Flat Map (3/8) (37ee8093d6ca7763fb4c10e2969d5fea) switched from CREATED to SCHEDULED.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Flat Map (4/8) (eb394d2ff728a1d877e399878c77d605) switched from CREATED to SCHEDULED.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Flat Map (5/8) (24f0b2872c534cd5fe46f8fafaecb3f2) switched from CREATED to SCHEDULED.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Flat Map (6/8) (0454c4c167f626f94be3ffbd1464d036) switched from CREATED to SCHEDULED.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Flat Map (7/8) (e346d959848727a8065991c1869881b8) switched from CREATED to SCHEDULED.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Flat Map (8/8) (6f28dda142156387187320f3efb1c846) switched from CREATED to SCHEDULED.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8) (516c7ce93f7d8fc61d62b538b7284242) switched from CREATED to SCHEDULED.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8) (94e0fd39896df1041428f7ae895b050e) switched from CREATED to SCHEDULED.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8) (77dd9ab95b4aa2f153ee6c4e049fd66c) switched from CREATED to SCHEDULED.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8) (c23b989c8448dccb476f534284bc4325) switched from CREATED to SCHEDULED.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8) (767e9546eb94b5e0414eed285190612d) switched from CREATED to SCHEDULED.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8) (4c258b957d702e5260de4e7630a91004) switched from CREATED to SCHEDULED.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8) (24fa15760c33801acfb87636e30b5b5e) switched from CREATED to SCHEDULED.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8) (7e78c3c12812fc4e587c9bff2980e405) switched from CREATED to SCHEDULED.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [jobmanager-future-thread-1] [250] [INFO ] Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=9158a477-c87b-40b0-93ce-13846840bf28
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-3] [940] [INFO ] Connecting to ResourceManager akka://flink/user/resourcemanager(827e383deb367599fea4104820e042e5)
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-3] [155] [INFO ] Resolved ResourceManager address, beginning registration
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-3] [204] [INFO ] Registration at ResourceManager attempt 1 (timeout=100ms)
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [302] [INFO ] Registering job manager 93ce13846840bf289158a477c87b40b0@akka://flink/user/jobmanager_1 for job 08ff3bb8572602a312ec0aebd0e317de.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-4] [657] [INFO ] Registered job manager 93ce13846840bf289158a477c87b40b0@akka://flink/user/jobmanager_1 for job 08ff3bb8572602a312ec0aebd0e317de.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-3] [962] [INFO ] JobManager successfully registered at ResourceManager, leader id: 827e383deb367599fea4104820e042e5.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-3] [319] [INFO ] Requesting new slot [SlotRequestId{f7552715e1b6913cd037110b80841aea}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-4] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 08ff3bb8572602a312ec0aebd0e317de with allocation id 0e96d91cd2bb0eca7edd5e28041cb7a2.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [816] [INFO ] Receive slot request 0e96d91cd2bb0eca7edd5e28041cb7a2 for job 08ff3bb8572602a312ec0aebd0e317de from resource manager with leader id 827e383deb367599fea4104820e042e5.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [828] [INFO ] Allocated slot for 0e96d91cd2bb0eca7edd5e28041cb7a2.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-3] [193] [INFO ] Add job 08ff3bb8572602a312ec0aebd0e317de for job leader monitoring.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-7] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 9158a477-c87b-40b0-93ce-13846840bf28.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-3] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-3] [204] [INFO ] Registration at JobManager attempt 1 (timeout=100ms)
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener$JobManagerRegisteredRpcConnection] [flink-akka.actor.default-dispatcher-3] [382] [INFO ] Successful registration at job manager akka://flink/user/jobmanager_1 for job 08ff3bb8572602a312ec0aebd0e317de.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [1220] [INFO ] Establish JobManager connection for job 08ff3bb8572602a312ec0aebd0e317de.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [1121] [INFO ] Offer reserved slots to the leader of job 08ff3bb8572602a312ec0aebd0e317de.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{d0477ed8609c80e53d7dcfcc981b669f}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{d39d6baa3dba5cf161100fa7fd834053}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 08ff3bb8572602a312ec0aebd0e317de with allocation id e40ab2f37e0b704d8ab9babde38c4c8f.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{3b61156c73158f7d7a0961d9de2372cd}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request e40ab2f37e0b704d8ab9babde38c4c8f for job 08ff3bb8572602a312ec0aebd0e317de from resource manager with leader id 827e383deb367599fea4104820e042e5.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 08ff3bb8572602a312ec0aebd0e317de with allocation id 3eb090f1d6d1c53c0ca7ef6a14f6aecc.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for e40ab2f37e0b704d8ab9babde38c4c8f.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{9f088d2eaf568bfb329bf17fa1de4095}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [1121] [INFO ] Offer reserved slots to the leader of job 08ff3bb8572602a312ec0aebd0e317de.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 08ff3bb8572602a312ec0aebd0e317de with allocation id bde2cb7faa9e2bcdfaf7f0ad434074ab.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 08ff3bb8572602a312ec0aebd0e317de with allocation id 345042374ec0c4223b09ea384e60a482.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request 3eb090f1d6d1c53c0ca7ef6a14f6aecc for job 08ff3bb8572602a312ec0aebd0e317de from resource manager with leader id 827e383deb367599fea4104820e042e5.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{73e91df802dacac71ac443cccb9e2b9b}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for 3eb090f1d6d1c53c0ca7ef6a14f6aecc.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-5] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 08ff3bb8572602a312ec0aebd0e317de with allocation id 669fe00b90d34c917564557a5d463296.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [1121] [INFO ] Offer reserved slots to the leader of job 08ff3bb8572602a312ec0aebd0e317de.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{59cf6ec10753a978f2830067fac2ec60}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request bde2cb7faa9e2bcdfaf7f0ad434074ab for job 08ff3bb8572602a312ec0aebd0e317de from resource manager with leader id 827e383deb367599fea4104820e042e5.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-5] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 08ff3bb8572602a312ec0aebd0e317de with allocation id d59480ce1e7f3f72a3e3f17cc7c431c5.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for bde2cb7faa9e2bcdfaf7f0ad434074ab.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{eedac3ad3c0d1966c5d70b086b708163}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [1121] [INFO ] Offer reserved slots to the leader of job 08ff3bb8572602a312ec0aebd0e317de.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 08ff3bb8572602a312ec0aebd0e317de with allocation id ec809de27f3f47289a6cf40309f2e476.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request 345042374ec0c4223b09ea384e60a482 for job 08ff3bb8572602a312ec0aebd0e317de from resource manager with leader id 827e383deb367599fea4104820e042e5.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for 345042374ec0c4223b09ea384e60a482.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [1121] [INFO ] Offer reserved slots to the leader of job 08ff3bb8572602a312ec0aebd0e317de.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [0e96d91cd2bb0eca7edd5e28041cb7a2]. Ignoring.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request 669fe00b90d34c917564557a5d463296 for job 08ff3bb8572602a312ec0aebd0e317de from resource manager with leader id 827e383deb367599fea4104820e042e5.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [0e96d91cd2bb0eca7edd5e28041cb7a2]. Ignoring.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for 669fe00b90d34c917564557a5d463296.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [e40ab2f37e0b704d8ab9babde38c4c8f]. Ignoring.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [1121] [INFO ] Offer reserved slots to the leader of job 08ff3bb8572602a312ec0aebd0e317de.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [0e96d91cd2bb0eca7edd5e28041cb7a2]. Ignoring.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request d59480ce1e7f3f72a3e3f17cc7c431c5 for job 08ff3bb8572602a312ec0aebd0e317de from resource manager with leader id 827e383deb367599fea4104820e042e5.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [e40ab2f37e0b704d8ab9babde38c4c8f]. Ignoring.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for d59480ce1e7f3f72a3e3f17cc7c431c5.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [3eb090f1d6d1c53c0ca7ef6a14f6aecc]. Ignoring.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [1121] [INFO ] Offer reserved slots to the leader of job 08ff3bb8572602a312ec0aebd0e317de.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [0e96d91cd2bb0eca7edd5e28041cb7a2]. Ignoring.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [e40ab2f37e0b704d8ab9babde38c4c8f]. Ignoring.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [3eb090f1d6d1c53c0ca7ef6a14f6aecc]. Ignoring.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request ec809de27f3f47289a6cf40309f2e476 for job 08ff3bb8572602a312ec0aebd0e317de from resource manager with leader id 827e383deb367599fea4104820e042e5.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [bde2cb7faa9e2bcdfaf7f0ad434074ab]. Ignoring.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for ec809de27f3f47289a6cf40309f2e476.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [0e96d91cd2bb0eca7edd5e28041cb7a2]. Ignoring.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [1121] [INFO ] Offer reserved slots to the leader of job 08ff3bb8572602a312ec0aebd0e317de.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [e40ab2f37e0b704d8ab9babde38c4c8f]. Ignoring.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 0e96d91cd2bb0eca7edd5e28041cb7a2.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [3eb090f1d6d1c53c0ca7ef6a14f6aecc]. Ignoring.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 0e96d91cd2bb0eca7edd5e28041cb7a2.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [345042374ec0c4223b09ea384e60a482]. Ignoring.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot e40ab2f37e0b704d8ab9babde38c4c8f.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [bde2cb7faa9e2bcdfaf7f0ad434074ab]. Ignoring.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 0e96d91cd2bb0eca7edd5e28041cb7a2.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [0e96d91cd2bb0eca7edd5e28041cb7a2]. Ignoring.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot e40ab2f37e0b704d8ab9babde38c4c8f.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [345042374ec0c4223b09ea384e60a482]. Ignoring.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 3eb090f1d6d1c53c0ca7ef6a14f6aecc.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [e40ab2f37e0b704d8ab9babde38c4c8f]. Ignoring.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 0e96d91cd2bb0eca7edd5e28041cb7a2.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [669fe00b90d34c917564557a5d463296]. Ignoring.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot e40ab2f37e0b704d8ab9babde38c4c8f.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [3eb090f1d6d1c53c0ca7ef6a14f6aecc]. Ignoring.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 3eb090f1d6d1c53c0ca7ef6a14f6aecc.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [bde2cb7faa9e2bcdfaf7f0ad434074ab]. Ignoring.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot bde2cb7faa9e2bcdfaf7f0ad434074ab.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [0e96d91cd2bb0eca7edd5e28041cb7a2]. Ignoring.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 0e96d91cd2bb0eca7edd5e28041cb7a2.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [345042374ec0c4223b09ea384e60a482]. Ignoring.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot e40ab2f37e0b704d8ab9babde38c4c8f.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [e40ab2f37e0b704d8ab9babde38c4c8f]. Ignoring.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 3eb090f1d6d1c53c0ca7ef6a14f6aecc.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [669fe00b90d34c917564557a5d463296]. Ignoring.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 345042374ec0c4223b09ea384e60a482.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [d59480ce1e7f3f72a3e3f17cc7c431c5]. Ignoring.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot bde2cb7faa9e2bcdfaf7f0ad434074ab.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [3eb090f1d6d1c53c0ca7ef6a14f6aecc]. Ignoring.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 0e96d91cd2bb0eca7edd5e28041cb7a2.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot e40ab2f37e0b704d8ab9babde38c4c8f.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 669fe00b90d34c917564557a5d463296.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 3eb090f1d6d1c53c0ca7ef6a14f6aecc.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 345042374ec0c4223b09ea384e60a482.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot bde2cb7faa9e2bcdfaf7f0ad434074ab.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 0e96d91cd2bb0eca7edd5e28041cb7a2.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 345042374ec0c4223b09ea384e60a482.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot e40ab2f37e0b704d8ab9babde38c4c8f.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 669fe00b90d34c917564557a5d463296.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot d59480ce1e7f3f72a3e3f17cc7c431c5.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 3eb090f1d6d1c53c0ca7ef6a14f6aecc.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot bde2cb7faa9e2bcdfaf7f0ad434074ab.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Socket Stream (1/1) (754a6105304abdfaa6a032126146feba) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Source: Socket Stream (1/1) (attempt #0) to 3a610323-f3d2-47f6-bc54-d294c2188d7c @ localhost (dataPort=-1)
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Flat Map (1/8) (d2f6d093d9e9ca6952eb7446d67cd00f) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Flat Map (1/8) (attempt #0) to 3a610323-f3d2-47f6-bc54-d294c2188d7c @ localhost (dataPort=-1)
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Flat Map (2/8) (43bc735f996ca31b34c2f780be4c6301) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Flat Map (2/8) (attempt #0) to 3a610323-f3d2-47f6-bc54-d294c2188d7c @ localhost (dataPort=-1)
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Flat Map (3/8) (37ee8093d6ca7763fb4c10e2969d5fea) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Flat Map (3/8) (attempt #0) to 3a610323-f3d2-47f6-bc54-d294c2188d7c @ localhost (dataPort=-1)
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Flat Map (4/8) (eb394d2ff728a1d877e399878c77d605) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Flat Map (4/8) (attempt #0) to 3a610323-f3d2-47f6-bc54-d294c2188d7c @ localhost (dataPort=-1)
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Flat Map (5/8) (24f0b2872c534cd5fe46f8fafaecb3f2) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Flat Map (5/8) (attempt #0) to 3a610323-f3d2-47f6-bc54-d294c2188d7c @ localhost (dataPort=-1)
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Flat Map (6/8) (0454c4c167f626f94be3ffbd1464d036) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Flat Map (6/8) (attempt #0) to 3a610323-f3d2-47f6-bc54-d294c2188d7c @ localhost (dataPort=-1)
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Flat Map (7/8) (e346d959848727a8065991c1869881b8) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Flat Map (7/8) (attempt #0) to 3a610323-f3d2-47f6-bc54-d294c2188d7c @ localhost (dataPort=-1)
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Flat Map (8/8) (6f28dda142156387187320f3efb1c846) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Flat Map (8/8) (attempt #0) to 3a610323-f3d2-47f6-bc54-d294c2188d7c @ localhost (dataPort=-1)
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8) (516c7ce93f7d8fc61d62b538b7284242) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8) (attempt #0) to 3a610323-f3d2-47f6-bc54-d294c2188d7c @ localhost (dataPort=-1)
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8) (94e0fd39896df1041428f7ae895b050e) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8) (attempt #0) to 3a610323-f3d2-47f6-bc54-d294c2188d7c @ localhost (dataPort=-1)
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8) (77dd9ab95b4aa2f153ee6c4e049fd66c) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8) (attempt #0) to 3a610323-f3d2-47f6-bc54-d294c2188d7c @ localhost (dataPort=-1)
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8) (c23b989c8448dccb476f534284bc4325) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8) (attempt #0) to 3a610323-f3d2-47f6-bc54-d294c2188d7c @ localhost (dataPort=-1)
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8) (767e9546eb94b5e0414eed285190612d) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8) (attempt #0) to 3a610323-f3d2-47f6-bc54-d294c2188d7c @ localhost (dataPort=-1)
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8) (4c258b957d702e5260de4e7630a91004) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8) (attempt #0) to 3a610323-f3d2-47f6-bc54-d294c2188d7c @ localhost (dataPort=-1)
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8) (24fa15760c33801acfb87636e30b5b5e) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8) (attempt #0) to 3a610323-f3d2-47f6-bc54-d294c2188d7c @ localhost (dataPort=-1)
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8) (7e78c3c12812fc4e587c9bff2980e405) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8) (attempt #0) to 3a610323-f3d2-47f6-bc54-d294c2188d7c @ localhost (dataPort=-1)
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [bde2cb7faa9e2bcdfaf7f0ad434074ab]. Ignoring.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Source: Socket Stream (1/1).
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Source: Socket Stream (1/1)] [958] [INFO ] Source: Socket Stream (1/1) (754a6105304abdfaa6a032126146feba) switched from CREATED to DEPLOYING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Source: Socket Stream (1/1)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Socket Stream (1/1) (754a6105304abdfaa6a032126146feba) [DEPLOYING]
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Source: Socket Stream (1/1)] [593] [INFO ] Loading JAR files for task Source: Socket Stream (1/1) (754a6105304abdfaa6a032126146feba) [DEPLOYING].
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Source: Socket Stream (1/1)] [619] [INFO ] Registering task at network: Source: Socket Stream (1/1) (754a6105304abdfaa6a032126146feba) [DEPLOYING].
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Flat Map (1/8).
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (1/8)] [958] [INFO ] Flat Map (1/8) (d2f6d093d9e9ca6952eb7446d67cd00f) switched from CREATED to DEPLOYING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (1/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Flat Map (1/8) (d2f6d093d9e9ca6952eb7446d67cd00f) [DEPLOYING]
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (1/8)] [593] [INFO ] Loading JAR files for task Flat Map (1/8) (d2f6d093d9e9ca6952eb7446d67cd00f) [DEPLOYING].
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (1/8)] [619] [INFO ] Registering task at network: Flat Map (1/8) (d2f6d093d9e9ca6952eb7446d67cd00f) [DEPLOYING].
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Flat Map (2/8).
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (2/8)] [958] [INFO ] Flat Map (2/8) (43bc735f996ca31b34c2f780be4c6301) switched from CREATED to DEPLOYING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (2/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Flat Map (2/8) (43bc735f996ca31b34c2f780be4c6301) [DEPLOYING]
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (2/8)] [593] [INFO ] Loading JAR files for task Flat Map (2/8) (43bc735f996ca31b34c2f780be4c6301) [DEPLOYING].
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (2/8)] [619] [INFO ] Registering task at network: Flat Map (2/8) (43bc735f996ca31b34c2f780be4c6301) [DEPLOYING].
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Flat Map (3/8).
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (3/8)] [958] [INFO ] Flat Map (3/8) (37ee8093d6ca7763fb4c10e2969d5fea) switched from CREATED to DEPLOYING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (3/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Flat Map (3/8) (37ee8093d6ca7763fb4c10e2969d5fea) [DEPLOYING]
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (3/8)] [593] [INFO ] Loading JAR files for task Flat Map (3/8) (37ee8093d6ca7763fb4c10e2969d5fea) [DEPLOYING].
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (3/8)] [619] [INFO ] Registering task at network: Flat Map (3/8) (37ee8093d6ca7763fb4c10e2969d5fea) [DEPLOYING].
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Flat Map (4/8).
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (4/8)] [958] [INFO ] Flat Map (4/8) (eb394d2ff728a1d877e399878c77d605) switched from CREATED to DEPLOYING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (4/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Flat Map (4/8) (eb394d2ff728a1d877e399878c77d605) [DEPLOYING]
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (4/8)] [593] [INFO ] Loading JAR files for task Flat Map (4/8) (eb394d2ff728a1d877e399878c77d605) [DEPLOYING].
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (4/8)] [619] [INFO ] Registering task at network: Flat Map (4/8) (eb394d2ff728a1d877e399878c77d605) [DEPLOYING].
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Flat Map (5/8).
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (5/8)] [958] [INFO ] Flat Map (5/8) (24f0b2872c534cd5fe46f8fafaecb3f2) switched from CREATED to DEPLOYING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (5/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Flat Map (5/8) (24f0b2872c534cd5fe46f8fafaecb3f2) [DEPLOYING]
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (1/8)] [958] [INFO ] Flat Map (1/8) (d2f6d093d9e9ca6952eb7446d67cd00f) switched from DEPLOYING to RUNNING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (4/8)] [958] [INFO ] Flat Map (4/8) (eb394d2ff728a1d877e399878c77d605) switched from DEPLOYING to RUNNING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (3/8)] [958] [INFO ] Flat Map (3/8) (37ee8093d6ca7763fb4c10e2969d5fea) switched from DEPLOYING to RUNNING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (2/8)] [958] [INFO ] Flat Map (2/8) (43bc735f996ca31b34c2f780be4c6301) switched from DEPLOYING to RUNNING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Source: Socket Stream (1/1)] [958] [INFO ] Source: Socket Stream (1/1) (754a6105304abdfaa6a032126146feba) switched from DEPLOYING to RUNNING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (5/8)] [593] [INFO ] Loading JAR files for task Flat Map (5/8) (24f0b2872c534cd5fe46f8fafaecb3f2) [DEPLOYING].
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Flat Map (4/8) (eb394d2ff728a1d877e399878c77d605) switched from DEPLOYING to RUNNING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Flat Map (1/8) (d2f6d093d9e9ca6952eb7446d67cd00f) switched from DEPLOYING to RUNNING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Socket Stream (1/1)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.state.StateBackendLoader] [Flat Map (3/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.state.StateBackendLoader] [Flat Map (2/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (5/8)] [619] [INFO ] Registering task at network: Flat Map (5/8) (24f0b2872c534cd5fe46f8fafaecb3f2) [DEPLOYING].
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.state.StateBackendLoader] [Flat Map (1/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.state.StateBackendLoader] [Flat Map (4/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Flat Map (3/8) (37ee8093d6ca7763fb4c10e2969d5fea) switched from DEPLOYING to RUNNING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Flat Map (6/8).
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Flat Map (2/8) (43bc735f996ca31b34c2f780be4c6301) switched from DEPLOYING to RUNNING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (6/8)] [958] [INFO ] Flat Map (6/8) (0454c4c167f626f94be3ffbd1464d036) switched from CREATED to DEPLOYING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Socket Stream (1/1) (754a6105304abdfaa6a032126146feba) switched from DEPLOYING to RUNNING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (6/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Flat Map (6/8) (0454c4c167f626f94be3ffbd1464d036) [DEPLOYING]
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (6/8)] [593] [INFO ] Loading JAR files for task Flat Map (6/8) (0454c4c167f626f94be3ffbd1464d036) [DEPLOYING].
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (5/8)] [958] [INFO ] Flat Map (5/8) (24f0b2872c534cd5fe46f8fafaecb3f2) switched from DEPLOYING to RUNNING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.state.StateBackendLoader] [Flat Map (5/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Flat Map (5/8) (24f0b2872c534cd5fe46f8fafaecb3f2) switched from DEPLOYING to RUNNING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (6/8)] [619] [INFO ] Registering task at network: Flat Map (6/8) (0454c4c167f626f94be3ffbd1464d036) [DEPLOYING].
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Flat Map (7/8).
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (7/8)] [958] [INFO ] Flat Map (7/8) (e346d959848727a8065991c1869881b8) switched from CREATED to DEPLOYING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (7/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Flat Map (7/8) (e346d959848727a8065991c1869881b8) [DEPLOYING]
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (7/8)] [593] [INFO ] Loading JAR files for task Flat Map (7/8) (e346d959848727a8065991c1869881b8) [DEPLOYING].
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (7/8)] [619] [INFO ] Registering task at network: Flat Map (7/8) (e346d959848727a8065991c1869881b8) [DEPLOYING].
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (6/8)] [958] [INFO ] Flat Map (6/8) (0454c4c167f626f94be3ffbd1464d036) switched from DEPLOYING to RUNNING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.state.StateBackendLoader] [Flat Map (6/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Flat Map (6/8) (0454c4c167f626f94be3ffbd1464d036) switched from DEPLOYING to RUNNING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (7/8)] [958] [INFO ] Flat Map (7/8) (e346d959848727a8065991c1869881b8) switched from DEPLOYING to RUNNING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.state.StateBackendLoader] [Flat Map (7/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Flat Map (8/8).
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Flat Map (7/8) (e346d959848727a8065991c1869881b8) switched from DEPLOYING to RUNNING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (8/8)] [958] [INFO ] Flat Map (8/8) (6f28dda142156387187320f3efb1c846) switched from CREATED to DEPLOYING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (8/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Flat Map (8/8) (6f28dda142156387187320f3efb1c846) [DEPLOYING]
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (8/8)] [593] [INFO ] Loading JAR files for task Flat Map (8/8) (6f28dda142156387187320f3efb1c846) [DEPLOYING].
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (8/8)] [619] [INFO ] Registering task at network: Flat Map (8/8) (6f28dda142156387187320f3efb1c846) [DEPLOYING].
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Flat Map (8/8)] [958] [INFO ] Flat Map (8/8) (6f28dda142156387187320f3efb1c846) switched from DEPLOYING to RUNNING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8).
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.state.StateBackendLoader] [Flat Map (8/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Flat Map (8/8) (6f28dda142156387187320f3efb1c846) switched from DEPLOYING to RUNNING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8)] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8) (516c7ce93f7d8fc61d62b538b7284242) switched from CREATED to DEPLOYING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8) (516c7ce93f7d8fc61d62b538b7284242) [DEPLOYING]
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8)] [593] [INFO ] Loading JAR files for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8) (516c7ce93f7d8fc61d62b538b7284242) [DEPLOYING].
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8).
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8)] [619] [INFO ] Registering task at network: Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8) (516c7ce93f7d8fc61d62b538b7284242) [DEPLOYING].
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8)] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8) (94e0fd39896df1041428f7ae895b050e) switched from CREATED to DEPLOYING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8)] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8) (516c7ce93f7d8fc61d62b538b7284242) switched from DEPLOYING to RUNNING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8) (94e0fd39896df1041428f7ae895b050e) [DEPLOYING]
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.state.StateBackendLoader] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8) (516c7ce93f7d8fc61d62b538b7284242) switched from DEPLOYING to RUNNING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8)] [593] [INFO ] Loading JAR files for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8) (94e0fd39896df1041428f7ae895b050e) [DEPLOYING].
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8).
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8)] [619] [INFO ] Registering task at network: Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8) (94e0fd39896df1041428f7ae895b050e) [DEPLOYING].
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8)] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8) (94e0fd39896df1041428f7ae895b050e) switched from DEPLOYING to RUNNING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.state.StateBackendLoader] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8)] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8) (77dd9ab95b4aa2f153ee6c4e049fd66c) switched from CREATED to DEPLOYING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8) (94e0fd39896df1041428f7ae895b050e) switched from DEPLOYING to RUNNING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8) (77dd9ab95b4aa2f153ee6c4e049fd66c) [DEPLOYING]
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8)] [593] [INFO ] Loading JAR files for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8) (77dd9ab95b4aa2f153ee6c4e049fd66c) [DEPLOYING].
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8).
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8)] [619] [INFO ] Registering task at network: Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8) (77dd9ab95b4aa2f153ee6c4e049fd66c) [DEPLOYING].
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8)] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8) (77dd9ab95b4aa2f153ee6c4e049fd66c) switched from DEPLOYING to RUNNING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.state.StateBackendLoader] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8)] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8) (c23b989c8448dccb476f534284bc4325) switched from CREATED to DEPLOYING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8) (c23b989c8448dccb476f534284bc4325) [DEPLOYING]
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8)] [593] [INFO ] Loading JAR files for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8) (c23b989c8448dccb476f534284bc4325) [DEPLOYING].
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.metrics.groups.TaskMetricGroup] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8)] [143] [WARN ] The operator name Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) exceeded the 80 characters length limit and was truncated.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8) (77dd9ab95b4aa2f153ee6c4e049fd66c) switched from DEPLOYING to RUNNING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.metrics.groups.TaskMetricGroup] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8)] [143] [WARN ] The operator name Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) exceeded the 80 characters length limit and was truncated.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8)] [619] [INFO ] Registering task at network: Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8) (c23b989c8448dccb476f534284bc4325) [DEPLOYING].
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.metrics.groups.TaskMetricGroup] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8)] [143] [WARN ] The operator name Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) exceeded the 80 characters length limit and was truncated.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8).
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8)] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8) (c23b989c8448dccb476f534284bc4325) switched from DEPLOYING to RUNNING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8)] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8) (767e9546eb94b5e0414eed285190612d) switched from CREATED to DEPLOYING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.state.StateBackendLoader] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8) (c23b989c8448dccb476f534284bc4325) switched from DEPLOYING to RUNNING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8) (767e9546eb94b5e0414eed285190612d) [DEPLOYING]
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8)] [593] [INFO ] Loading JAR files for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8) (767e9546eb94b5e0414eed285190612d) [DEPLOYING].
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8).
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8)] [619] [INFO ] Registering task at network: Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8) (767e9546eb94b5e0414eed285190612d) [DEPLOYING].
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8)] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8) (4c258b957d702e5260de4e7630a91004) switched from CREATED to DEPLOYING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8)] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8) (767e9546eb94b5e0414eed285190612d) switched from DEPLOYING to RUNNING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8) (4c258b957d702e5260de4e7630a91004) [DEPLOYING]
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.metrics.groups.TaskMetricGroup] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8)] [143] [WARN ] The operator name Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) exceeded the 80 characters length limit and was truncated.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.state.StateBackendLoader] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8)] [593] [INFO ] Loading JAR files for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8) (4c258b957d702e5260de4e7630a91004) [DEPLOYING].
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8) (767e9546eb94b5e0414eed285190612d) switched from DEPLOYING to RUNNING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [587] [INFO ] Received task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8).
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8)] [619] [INFO ] Registering task at network: Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8) (4c258b957d702e5260de4e7630a91004) [DEPLOYING].
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.metrics.groups.TaskMetricGroup] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8)] [143] [WARN ] The operator name Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) exceeded the 80 characters length limit and was truncated.
[2019-11-28 00:16:40.040] [org.apache.flink.streaming.api.functions.source.SocketTextStreamFunction] [Thread-7] [95] [INFO ] Connecting to server socket localhost:9999
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8)] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8) (4c258b957d702e5260de4e7630a91004) switched from DEPLOYING to RUNNING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8)] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8) (24fa15760c33801acfb87636e30b5b5e) switched from CREATED to DEPLOYING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.state.StateBackendLoader] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [587] [INFO ] Received task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8).
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8) (4c258b957d702e5260de4e7630a91004) switched from DEPLOYING to RUNNING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8) (24fa15760c33801acfb87636e30b5b5e) [DEPLOYING]
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8)] [593] [INFO ] Loading JAR files for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8) (24fa15760c33801acfb87636e30b5b5e) [DEPLOYING].
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot 0e96d91cd2bb0eca7edd5e28041cb7a2.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot 345042374ec0c4223b09ea384e60a482.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot e40ab2f37e0b704d8ab9babde38c4c8f.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8)] [619] [INFO ] Registering task at network: Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8) (24fa15760c33801acfb87636e30b5b5e) [DEPLOYING].
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot 669fe00b90d34c917564557a5d463296.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.metrics.groups.TaskMetricGroup] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8)] [143] [WARN ] The operator name Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) exceeded the 80 characters length limit and was truncated.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8)] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8) (7e78c3c12812fc4e587c9bff2980e405) switched from CREATED to DEPLOYING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8)] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8) (24fa15760c33801acfb87636e30b5b5e) switched from DEPLOYING to RUNNING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot d59480ce1e7f3f72a3e3f17cc7c431c5.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8) (7e78c3c12812fc4e587c9bff2980e405) [DEPLOYING]
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot 3eb090f1d6d1c53c0ca7ef6a14f6aecc.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.state.StateBackendLoader] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8) (24fa15760c33801acfb87636e30b5b5e) switched from DEPLOYING to RUNNING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8)] [593] [INFO ] Loading JAR files for task Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8) (7e78c3c12812fc4e587c9bff2980e405) [DEPLOYING].
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot ec809de27f3f47289a6cf40309f2e476.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot bde2cb7faa9e2bcdfaf7f0ad434074ab.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8)] [619] [INFO ] Registering task at network: Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8) (7e78c3c12812fc4e587c9bff2980e405) [DEPLOYING].
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.taskmanager.Task] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8)] [958] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8) (7e78c3c12812fc4e587c9bff2980e405) switched from DEPLOYING to RUNNING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8) (7e78c3c12812fc4e587c9bff2980e405) switched from DEPLOYING to RUNNING.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.metrics.groups.TaskMetricGroup] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8)] [143] [WARN ] The operator name Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) exceeded the 80 characters length limit and was truncated.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.state.StateBackendLoader] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.metrics.groups.TaskMetricGroup] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8)] [143] [WARN ] The operator name Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) exceeded the 80 characters length limit and was truncated.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.state.heap.HeapKeyedStateBackend] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (6/8)] [140] [INFO ] Initializing heap keyed state backend with stream factory.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.state.heap.HeapKeyedStateBackend] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (5/8)] [140] [INFO ] Initializing heap keyed state backend with stream factory.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.state.heap.HeapKeyedStateBackend] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (8/8)] [140] [INFO ] Initializing heap keyed state backend with stream factory.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.state.heap.HeapKeyedStateBackend] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (2/8)] [140] [INFO ] Initializing heap keyed state backend with stream factory.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.state.heap.HeapKeyedStateBackend] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (4/8)] [140] [INFO ] Initializing heap keyed state backend with stream factory.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.state.heap.HeapKeyedStateBackend] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (7/8)] [140] [INFO ] Initializing heap keyed state backend with stream factory.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.state.heap.HeapKeyedStateBackend] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (3/8)] [140] [INFO ] Initializing heap keyed state backend with stream factory.
[2019-11-28 00:16:40.040] [org.apache.flink.runtime.state.heap.HeapKeyedStateBackend] [Window(TumblingProcessingTimeWindows(5000), ProcessingTimeTrigger, SumAggregator, PassThroughWindowFunction) -> Sink: Print to Std. Out (1/8)] [140] [INFO ] Initializing heap keyed state backend with stream factory.
[2019-11-28 00:18:22.022] [org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager] [TaskExecutorLocalStateStoresManager shutdown hook] [213] [INFO ] Shutting down TaskExecutorLocalStateStoresManager.
[2019-11-28 00:18:22.022] [org.apache.flink.runtime.blob.AbstractBlobCache] [PermanentBlobCache shutdown hook] [247] [INFO ] Shutting down BLOB cache
[2019-11-28 00:18:22.022] [org.apache.flink.runtime.blob.AbstractBlobCache] [TransientBlobCache shutdown hook] [247] [INFO ] Shutting down BLOB cache
[2019-11-28 00:18:22.022] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [IOManagerAsync shutdown hook] [112] [INFO ] FileChannelManager removed spill file directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-io-899014cc-7f8b-4819-981a-6177cc8045dd
[2019-11-28 00:18:22.022] [org.apache.flink.runtime.blob.BlobServer] [BlobServer shutdown hook] [340] [INFO ] Stopped BLOB server at 0.0.0.0:51918
[2019-11-28 00:18:22.022] [org.apache.flink.runtime.filecache.FileCache] [FileCache shutdown hook] [153] [INFO ] removed file cache directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-dist-cache-52301fdd-169b-4f63-a912-f7526327e563
[2019-11-28 00:33:16.016] [org.apache.flink.api.java.typeutils.TypeExtractor] [main] [1815] [INFO ] class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a getter for field _children
[2019-11-28 00:33:16.016] [org.apache.flink.api.java.typeutils.TypeExtractor] [main] [1818] [INFO ] class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a setter for field _children
[2019-11-28 00:33:16.016] [org.apache.flink.api.java.typeutils.TypeExtractor] [main] [1857] [INFO ] Class class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:33:16.016] [org.apache.flink.streaming.api.environment.LocalStreamEnvironment] [main] [108] [INFO ] Running job on local embedded Flink mini cluster
[2019-11-28 00:33:16.016] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [254] [INFO ] Starting Flink Mini Cluster
[2019-11-28 00:33:16.016] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [263] [INFO ] Starting Metrics Registry
[2019-11-28 00:33:16.016] [org.apache.flink.runtime.metrics.MetricRegistryImpl] [main] [114] [INFO ] No metrics reporter configured, no metrics will be exposed/reported.
[2019-11-28 00:33:16.016] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [267] [INFO ] Starting RPC Service(s)
[2019-11-28 00:33:16.016] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1] [flink-akka.actor.default-dispatcher-3] [92] [INFO ] Slf4jLogger started
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.clusterframework.BootstrapTools] [main] [244] [INFO ] Trying to start actor system at :0
[2019-11-28 00:33:17.017] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1] [flink-metrics-2] [92] [INFO ] Slf4jLogger started
[2019-11-28 00:33:17.017] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-2] [83] [INFO ] Starting remoting
[2019-11-28 00:33:17.017] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-2] [83] [INFO ] Remoting started; listening on addresses :[akka.tcp://flink-metrics@192.168.1.14:52665]
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.clusterframework.BootstrapTools] [main] [256] [INFO ] Actor system started at akka.tcp://flink-metrics@192.168.1.14:52665
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [398] [INFO ] Starting high-availability services
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.blob.BlobServer] [main] [141] [INFO ] Created BLOB server storage directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/blobStore-ff5efc3d-746d-41c8-93d4-3aa7ffcc0aaa
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.blob.BlobServer] [main] [203] [INFO ] Started BLOB server at 0.0.0.0:52666 - max concurrent requests: 50 - max backlog: 1000
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.blob.AbstractBlobCache] [main] [107] [INFO ] Created BLOB cache storage directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/blobStore-137a8baf-bf64-4e8c-b9d2-9555d5dbf2d2
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.blob.AbstractBlobCache] [main] [107] [INFO ] Created BLOB cache storage directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/blobStore-e5183efc-9024-4899-abaf-0fa30fdfe814
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [480] [INFO ] Starting 1 TaskManger(s)
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.taskexecutor.TaskManagerRunner] [main] [351] [INFO ] Starting TaskManager with ResourceID: 58732cba-5b4b-4f02-aa4f-7757ab131b6e
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.taskexecutor.TaskManagerServices] [main] [519] [INFO ] Temporary file directory '/var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T': total 233 GB, usable 170 GB (72.96% usable)
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [main] [76] [INFO ] FileChannelManager uses directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-io-bce467db-c819-4b7c-8618-3de4f5b470bf for spill files.
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [main] [76] [INFO ] FileChannelManager uses directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-netty-shuffle-f50a8211-2c9f-4c0a-a5ac-a1f84e137f9b for spill files.
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.io.network.buffer.NetworkBufferPool] [main] [140] [INFO ] Allocated 202 MB for network buffer pool (number of memory segments: 6472, bytes per segment: 32768).
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.io.network.NettyShuffleEnvironment] [main] [283] [INFO ] Starting the network environment and its components.
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.taskexecutor.KvStateService] [main] [89] [INFO ] Starting the kvState service and its components.
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.taskexecutor.TaskManagerServices] [main] [364] [INFO ] Limiting managed memory to 0.7 of the currently free heap space (1267 MB), memory will be allocated lazily.
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.taskexecutor.TaskManagerConfiguration] [main] [197] [INFO ] Messages have a max timeout of 10000 ms
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-2] [125] [INFO ] Start job leader service.
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.filecache.FileCache] [flink-akka.actor.default-dispatcher-2] [107] [INFO ] User file cache uses directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-dist-cache-2a84eb0f-d6c4-470e-bea3-1ce90f7c2428
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.rest.RestServerEndpoint] [main] [136] [INFO ] Starting rest endpoint.
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.webmonitor.WebMonitorUtils$LogFileLocation] [main] [87] [WARN ] Log file environment variable 'log.file' is not set.
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.webmonitor.WebMonitorUtils$LogFileLocation] [main] [93] [WARN ] JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] [main] [114] [INFO ] Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.rest.RestServerEndpoint] [main] [233] [INFO ] Rest endpoint listening at localhost:52667
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [main] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@4a5905d9 @ http://localhost:52667
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.webmonitor.WebMonitorEndpoint] [mini-cluster-io-thread-1] [711] [INFO ] http://localhost:52667 was granted leadership with leaderSessionID=339c8c78-1247-4603-a9d2-f319fec0581b
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [mini-cluster-io-thread-1] [250] [INFO ] Received confirmation of leadership for leader http://localhost:52667 , session=339c8c78-1247-4603-a9d2-f319fec0581b
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-2] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@6cd8f164 @ akka://flink/user/dispatcher
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-3] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@6946e136 @ akka://flink/user/resourcemanager
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-2] [885] [INFO ] Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token abd6f5bc-c1cf-4424-a0d8-3fc86d367504
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [919] [INFO ] ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token 9f56e94172d4ab5002080c22ad284cd8
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [363] [INFO ] Flink Mini Cluster started successfully
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-4] [717] [INFO ] Recovering all persisted jobs.
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl] [flink-akka.actor.default-dispatcher-3] [215] [INFO ] Starting the SlotManager.
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-4] [250] [INFO ] Received confirmation of leadership for leader akka://flink/user/dispatcher , session=abd6f5bc-c1cf-4424-a0d8-3fc86d367504
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-2] [250] [INFO ] Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=02080c22-ad28-4cd8-9f56-e94172d4ab50
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [982] [INFO ] Connecting to ResourceManager akka://flink/user/resourcemanager(9f56e94172d4ab5002080c22ad284cd8).
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-5] [155] [INFO ] Resolved ResourceManager address, beginning registration
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-5] [204] [INFO ] Registration at ResourceManager attempt 1 (timeout=100ms)
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [711] [INFO ] Registering TaskManager with ResourceID 58732cba-5b4b-4f02-aa4f-7757ab131b6e (akka://flink/user/taskmanager_0) at ResourceManager
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-2] [264] [INFO ] Received JobGraph submission 791ab942031414319efcd1167287cb3d (Flink Streaming Job).
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.taskexecutor.TaskExecutorToResourceManagerConnection] [flink-akka.actor.default-dispatcher-3] [100] [INFO ] Successful registration at resource manager akka://flink/user/resourcemanager under registration id 4255a47f22d5d1aef9dff5d77328f774.
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-2] [321] [INFO ] Submitting job 791ab942031414319efcd1167287cb3d (Flink Streaming Job).
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [flink-akka.actor.default-dispatcher-3] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-3] [241] [INFO ] Initializing job Flink Streaming Job (791ab942031414319efcd1167287cb3d).
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.scheduler.LegacyScheduler] [flink-akka.actor.default-dispatcher-3] [171] [INFO ] Using restart strategy NoRestartStrategy for Flink Streaming Job (791ab942031414319efcd1167287cb3d).
[2019-11-28 00:33:17.017] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-3] [516] [INFO ] Job recovers via failover strategy: full graph restart
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.executiongraph.ExecutionGraphBuilder] [flink-akka.actor.default-dispatcher-3] [204] [INFO ] Running initialization on master for job Flink Streaming Job (791ab942031414319efcd1167287cb3d).
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.executiongraph.ExecutionGraphBuilder] [flink-akka.actor.default-dispatcher-3] [222] [INFO ] Successfully ran initialization on master in 0 ms.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.state.StateBackendLoader] [flink-akka.actor.default-dispatcher-3] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-3] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@2de46ff0 @ akka://flink/user/jobmanager_1
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.jobmaster.JobManagerRunner] [mini-cluster-io-thread-2] [313] [INFO ] JobManager runner for job Flink Streaming Job (791ab942031414319efcd1167287cb3d) was granted leadership with session id ce2a143b-31b9-46ea-a5a8-245a1dc53ffa at akka://flink/user/jobmanager_1.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-4] [709] [INFO ] Starting execution of job Flink Streaming Job (791ab942031414319efcd1167287cb3d) under job master id a5a8245a1dc53fface2a143b31b946ea.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-4] [1324] [INFO ] Job Flink Streaming Job (791ab942031414319efcd1167287cb3d) switched from state CREATED to RUNNING.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map (1/8) (2f2155435a95dcd42210d12744c0db83) switched from CREATED to SCHEDULED.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{fcfca0ffdbf328e498ca695ef028a4ce}]
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map (2/8) (6647688e1549bfa301f0a1066c782ee4) switched from CREATED to SCHEDULED.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{e6487d40adef90258820049d553bc276}]
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map (3/8) (29d7b28375f3227126299465eb29333e) switched from CREATED to SCHEDULED.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{b4ec9bee9d7dd9a0fdfc778328cf75e5}]
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map (4/8) (286a783991bed4184b2c7f4d8194c37f) switched from CREATED to SCHEDULED.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{089e4a8923d4d6058b6402f42fdc9fb7}]
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map (5/8) (86b4609e4b4b629ed5f876aabed2d3d2) switched from CREATED to SCHEDULED.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{577a52263520bf5422b88bc23c59942a}]
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map (6/8) (2723d92c15e51aa6f318ccbbc768c031) switched from CREATED to SCHEDULED.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{8d25d802f4509c7e497b2c1dfcdc0e1e}]
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map (7/8) (416982fa043e0a29c35befb0225d703d) switched from CREATED to SCHEDULED.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{f52b1849e875123e5420c94597257153}]
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map (8/8) (ababebfa2e96fa66b0c70e8b854b6451) switched from CREATED to SCHEDULED.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{eb1ee7250db91d36f0fe7968cfec37de}]
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [jobmanager-future-thread-1] [250] [INFO ] Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=ce2a143b-31b9-46ea-a5a8-245a1dc53ffa
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-4] [940] [INFO ] Connecting to ResourceManager akka://flink/user/resourcemanager(9f56e94172d4ab5002080c22ad284cd8)
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-4] [155] [INFO ] Resolved ResourceManager address, beginning registration
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-4] [204] [INFO ] Registration at ResourceManager attempt 1 (timeout=100ms)
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [302] [INFO ] Registering job manager a5a8245a1dc53fface2a143b31b946ea@akka://flink/user/jobmanager_1 for job 791ab942031414319efcd1167287cb3d.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-4] [657] [INFO ] Registered job manager a5a8245a1dc53fface2a143b31b946ea@akka://flink/user/jobmanager_1 for job 791ab942031414319efcd1167287cb3d.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-4] [962] [INFO ] JobManager successfully registered at ResourceManager, leader id: 9f56e94172d4ab5002080c22ad284cd8.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{fcfca0ffdbf328e498ca695ef028a4ce}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 791ab942031414319efcd1167287cb3d with allocation id 8826e3d9fa8debf40227dad0197a38e8.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{e6487d40adef90258820049d553bc276}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{b4ec9bee9d7dd9a0fdfc778328cf75e5}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{089e4a8923d4d6058b6402f42fdc9fb7}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request 8826e3d9fa8debf40227dad0197a38e8 for job 791ab942031414319efcd1167287cb3d from resource manager with leader id 9f56e94172d4ab5002080c22ad284cd8.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{577a52263520bf5422b88bc23c59942a}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{8d25d802f4509c7e497b2c1dfcdc0e1e}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 791ab942031414319efcd1167287cb3d with allocation id e54824030254714dbdf8c5de647ea6ec.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{f52b1849e875123e5420c94597257153}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for 8826e3d9fa8debf40227dad0197a38e8.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 791ab942031414319efcd1167287cb3d with allocation id 416f74fac30f23314e44ba66d99ef3b9.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{eb1ee7250db91d36f0fe7968cfec37de}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-2] [193] [INFO ] Add job 791ab942031414319efcd1167287cb3d for job leader monitoring.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 791ab942031414319efcd1167287cb3d with allocation id 40ac49a18d2afea09028237877bc78a2.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 791ab942031414319efcd1167287cb3d with allocation id 64fa8b298a8a7a486e7315870ee026bb.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 791ab942031414319efcd1167287cb3d with allocation id 107cc5d93232adf6aac552d9d14a3d68.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request e54824030254714dbdf8c5de647ea6ec for job 791ab942031414319efcd1167287cb3d from resource manager with leader id 9f56e94172d4ab5002080c22ad284cd8.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 791ab942031414319efcd1167287cb3d with allocation id 0fa5de0bec5efd49db3bb227f7ae5630.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for e54824030254714dbdf8c5de647ea6ec.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-1] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id ce2a143b-31b9-46ea-a5a8-245a1dc53ffa.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-2] [193] [INFO ] Add job 791ab942031414319efcd1167287cb3d for job leader monitoring.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 791ab942031414319efcd1167287cb3d with allocation id 38da917e471839a87c3acb7f8603d9d6.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-7] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id ce2a143b-31b9-46ea-a5a8-245a1dc53ffa.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request 416f74fac30f23314e44ba66d99ef3b9 for job 791ab942031414319efcd1167287cb3d from resource manager with leader id 9f56e94172d4ab5002080c22ad284cd8.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-5] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for 416f74fac30f23314e44ba66d99ef3b9.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-2] [193] [INFO ] Add job 791ab942031414319efcd1167287cb3d for job leader monitoring.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-5] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-8] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id ce2a143b-31b9-46ea-a5a8-245a1dc53ffa.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request 40ac49a18d2afea09028237877bc78a2 for job 791ab942031414319efcd1167287cb3d from resource manager with leader id 9f56e94172d4ab5002080c22ad284cd8.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for 40ac49a18d2afea09028237877bc78a2.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-2] [193] [INFO ] Add job 791ab942031414319efcd1167287cb3d for job leader monitoring.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-5] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-5] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id ce2a143b-31b9-46ea-a5a8-245a1dc53ffa.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request 64fa8b298a8a7a486e7315870ee026bb for job 791ab942031414319efcd1167287cb3d from resource manager with leader id 9f56e94172d4ab5002080c22ad284cd8.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for 64fa8b298a8a7a486e7315870ee026bb.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-2] [193] [INFO ] Add job 791ab942031414319efcd1167287cb3d for job leader monitoring.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-3] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-6] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id ce2a143b-31b9-46ea-a5a8-245a1dc53ffa.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request 107cc5d93232adf6aac552d9d14a3d68 for job 791ab942031414319efcd1167287cb3d from resource manager with leader id 9f56e94172d4ab5002080c22ad284cd8.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for 107cc5d93232adf6aac552d9d14a3d68.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-2] [193] [INFO ] Add job 791ab942031414319efcd1167287cb3d for job leader monitoring.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-3] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-2] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id ce2a143b-31b9-46ea-a5a8-245a1dc53ffa.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request 0fa5de0bec5efd49db3bb227f7ae5630 for job 791ab942031414319efcd1167287cb3d from resource manager with leader id 9f56e94172d4ab5002080c22ad284cd8.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for 0fa5de0bec5efd49db3bb227f7ae5630.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-2] [193] [INFO ] Add job 791ab942031414319efcd1167287cb3d for job leader monitoring.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-5] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-3] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id ce2a143b-31b9-46ea-a5a8-245a1dc53ffa.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request 38da917e471839a87c3acb7f8603d9d6 for job 791ab942031414319efcd1167287cb3d from resource manager with leader id 9f56e94172d4ab5002080c22ad284cd8.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for 38da917e471839a87c3acb7f8603d9d6.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-2] [193] [INFO ] Add job 791ab942031414319efcd1167287cb3d for job leader monitoring.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-4] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-4] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id ce2a143b-31b9-46ea-a5a8-245a1dc53ffa.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-3] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-3] [204] [INFO ] Registration at JobManager attempt 1 (timeout=100ms)
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener$JobManagerRegisteredRpcConnection] [flink-akka.actor.default-dispatcher-2] [382] [INFO ] Successful registration at job manager akka://flink/user/jobmanager_1 for job 791ab942031414319efcd1167287cb3d.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [1220] [INFO ] Establish JobManager connection for job 791ab942031414319efcd1167287cb3d.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [1121] [INFO ] Offer reserved slots to the leader of job 791ab942031414319efcd1167287cb3d.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map (1/8) (2f2155435a95dcd42210d12744c0db83) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Source: Custom Source -> Map (1/8) (attempt #0) to 58732cba-5b4b-4f02-aa4f-7757ab131b6e @ localhost (dataPort=-1)
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map (2/8) (6647688e1549bfa301f0a1066c782ee4) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Source: Custom Source -> Map (2/8) (attempt #0) to 58732cba-5b4b-4f02-aa4f-7757ab131b6e @ localhost (dataPort=-1)
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map (3/8) (29d7b28375f3227126299465eb29333e) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Source: Custom Source -> Map (3/8) (attempt #0) to 58732cba-5b4b-4f02-aa4f-7757ab131b6e @ localhost (dataPort=-1)
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map (4/8) (286a783991bed4184b2c7f4d8194c37f) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Source: Custom Source -> Map (4/8) (attempt #0) to 58732cba-5b4b-4f02-aa4f-7757ab131b6e @ localhost (dataPort=-1)
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map (5/8) (86b4609e4b4b629ed5f876aabed2d3d2) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Source: Custom Source -> Map (5/8) (attempt #0) to 58732cba-5b4b-4f02-aa4f-7757ab131b6e @ localhost (dataPort=-1)
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map (6/8) (2723d92c15e51aa6f318ccbbc768c031) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Source: Custom Source -> Map (6/8) (attempt #0) to 58732cba-5b4b-4f02-aa4f-7757ab131b6e @ localhost (dataPort=-1)
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map (7/8) (416982fa043e0a29c35befb0225d703d) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Source: Custom Source -> Map (7/8) (attempt #0) to 58732cba-5b4b-4f02-aa4f-7757ab131b6e @ localhost (dataPort=-1)
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map (8/8) (ababebfa2e96fa66b0c70e8b854b6451) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Source: Custom Source -> Map (8/8) (attempt #0) to 58732cba-5b4b-4f02-aa4f-7757ab131b6e @ localhost (dataPort=-1)
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Source: Custom Source -> Map (1/8).
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (1/8)] [958] [INFO ] Source: Custom Source -> Map (1/8) (2f2155435a95dcd42210d12744c0db83) switched from CREATED to DEPLOYING.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (1/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (1/8) (2f2155435a95dcd42210d12744c0db83) [DEPLOYING]
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (1/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map (1/8) (2f2155435a95dcd42210d12744c0db83) [DEPLOYING].
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (1/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map (1/8) (2f2155435a95dcd42210d12744c0db83) [DEPLOYING].
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Source: Custom Source -> Map (2/8).
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (2/8)] [958] [INFO ] Source: Custom Source -> Map (2/8) (6647688e1549bfa301f0a1066c782ee4) switched from CREATED to DEPLOYING.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (2/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (2/8) (6647688e1549bfa301f0a1066c782ee4) [DEPLOYING]
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (2/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map (2/8) (6647688e1549bfa301f0a1066c782ee4) [DEPLOYING].
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (2/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map (2/8) (6647688e1549bfa301f0a1066c782ee4) [DEPLOYING].
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Source: Custom Source -> Map (3/8).
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (3/8)] [958] [INFO ] Source: Custom Source -> Map (3/8) (29d7b28375f3227126299465eb29333e) switched from CREATED to DEPLOYING.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (3/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (3/8) (29d7b28375f3227126299465eb29333e) [DEPLOYING]
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (3/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map (3/8) (29d7b28375f3227126299465eb29333e) [DEPLOYING].
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (3/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map (3/8) (29d7b28375f3227126299465eb29333e) [DEPLOYING].
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Source: Custom Source -> Map (4/8).
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (4/8)] [958] [INFO ] Source: Custom Source -> Map (4/8) (286a783991bed4184b2c7f4d8194c37f) switched from CREATED to DEPLOYING.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (4/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (4/8) (286a783991bed4184b2c7f4d8194c37f) [DEPLOYING]
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (4/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map (4/8) (286a783991bed4184b2c7f4d8194c37f) [DEPLOYING].
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (4/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map (4/8) (286a783991bed4184b2c7f4d8194c37f) [DEPLOYING].
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Source: Custom Source -> Map (5/8).
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (5/8)] [958] [INFO ] Source: Custom Source -> Map (5/8) (86b4609e4b4b629ed5f876aabed2d3d2) switched from CREATED to DEPLOYING.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (5/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (5/8) (86b4609e4b4b629ed5f876aabed2d3d2) [DEPLOYING]
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (3/8)] [958] [INFO ] Source: Custom Source -> Map (3/8) (29d7b28375f3227126299465eb29333e) switched from DEPLOYING to RUNNING.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (4/8)] [958] [INFO ] Source: Custom Source -> Map (4/8) (286a783991bed4184b2c7f4d8194c37f) switched from DEPLOYING to RUNNING.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (5/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map (5/8) (86b4609e4b4b629ed5f876aabed2d3d2) [DEPLOYING].
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (1/8)] [958] [INFO ] Source: Custom Source -> Map (1/8) (2f2155435a95dcd42210d12744c0db83) switched from DEPLOYING to RUNNING.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (2/8)] [958] [INFO ] Source: Custom Source -> Map (2/8) (6647688e1549bfa301f0a1066c782ee4) switched from DEPLOYING to RUNNING.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map (3/8) (29d7b28375f3227126299465eb29333e) switched from DEPLOYING to RUNNING.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (5/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map (5/8) (86b4609e4b4b629ed5f876aabed2d3d2) [DEPLOYING].
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map (1/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map (4/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map (2/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map (4/8) (286a783991bed4184b2c7f4d8194c37f) switched from DEPLOYING to RUNNING.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map (3/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Source: Custom Source -> Map (6/8).
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map (1/8) (2f2155435a95dcd42210d12744c0db83) switched from DEPLOYING to RUNNING.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (5/8)] [958] [INFO ] Source: Custom Source -> Map (5/8) (86b4609e4b4b629ed5f876aabed2d3d2) switched from DEPLOYING to RUNNING.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (6/8)] [958] [INFO ] Source: Custom Source -> Map (6/8) (2723d92c15e51aa6f318ccbbc768c031) switched from CREATED to DEPLOYING.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map (2/8) (6647688e1549bfa301f0a1066c782ee4) switched from DEPLOYING to RUNNING.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map (5/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (6/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (6/8) (2723d92c15e51aa6f318ccbbc768c031) [DEPLOYING]
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map (5/8) (86b4609e4b4b629ed5f876aabed2d3d2) switched from DEPLOYING to RUNNING.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (6/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map (6/8) (2723d92c15e51aa6f318ccbbc768c031) [DEPLOYING].
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Source: Custom Source -> Map (7/8).
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (6/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map (6/8) (2723d92c15e51aa6f318ccbbc768c031) [DEPLOYING].
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 8826e3d9fa8debf40227dad0197a38e8.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (6/8)] [958] [INFO ] Source: Custom Source -> Map (6/8) (2723d92c15e51aa6f318ccbbc768c031) switched from DEPLOYING to RUNNING.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 38da917e471839a87c3acb7f8603d9d6.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map (6/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot e54824030254714dbdf8c5de647ea6ec.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (7/8)] [958] [INFO ] Source: Custom Source -> Map (7/8) (416982fa043e0a29c35befb0225d703d) switched from CREATED to DEPLOYING.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map (6/8) (2723d92c15e51aa6f318ccbbc768c031) switched from DEPLOYING to RUNNING.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 40ac49a18d2afea09028237877bc78a2.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (7/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (7/8) (416982fa043e0a29c35befb0225d703d) [DEPLOYING]
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 0fa5de0bec5efd49db3bb227f7ae5630.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (7/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map (7/8) (416982fa043e0a29c35befb0225d703d) [DEPLOYING].
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 416f74fac30f23314e44ba66d99ef3b9.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 64fa8b298a8a7a486e7315870ee026bb.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 107cc5d93232adf6aac552d9d14a3d68.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (7/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map (7/8) (416982fa043e0a29c35befb0225d703d) [DEPLOYING].
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (7/8)] [958] [INFO ] Source: Custom Source -> Map (7/8) (416982fa043e0a29c35befb0225d703d) switched from DEPLOYING to RUNNING.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map (7/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map (7/8) (416982fa043e0a29c35befb0225d703d) switched from DEPLOYING to RUNNING.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Source: Custom Source -> Map (8/8).
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (8/8)] [958] [INFO ] Source: Custom Source -> Map (8/8) (ababebfa2e96fa66b0c70e8b854b6451) switched from CREATED to DEPLOYING.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (8/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (8/8) (ababebfa2e96fa66b0c70e8b854b6451) [DEPLOYING]
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (8/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map (8/8) (ababebfa2e96fa66b0c70e8b854b6451) [DEPLOYING].
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (8/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map (8/8) (ababebfa2e96fa66b0c70e8b854b6451) [DEPLOYING].
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (8/8)] [958] [INFO ] Source: Custom Source -> Map (8/8) (ababebfa2e96fa66b0c70e8b854b6451) switched from DEPLOYING to RUNNING.
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map (8/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:33:18.018] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map (8/8) (ababebfa2e96fa66b0c70e8b854b6451) switched from DEPLOYING to RUNNING.
[2019-11-28 00:33:18.018] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (3/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:33:18.018] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (5/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:33:18.018] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (8/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:33:18.018] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (7/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:33:18.018] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (4/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:33:18.018] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (2/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:33:18.018] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (6/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:33:18.018] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (1/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:33:18.018] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (3/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:33:18.018] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (5/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:33:18.018] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (8/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:33:18.018] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (7/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:33:18.018] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (4/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:33:18.018] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (2/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:33:18.018] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (6/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:33:18.018] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (1/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:33:18.018] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (2/8)] [886] [INFO ] Consumer subtask 1 has no restore state.
[2019-11-28 00:33:18.018] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (1/8)] [886] [INFO ] Consumer subtask 0 has no restore state.
[2019-11-28 00:33:18.018] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (5/8)] [886] [INFO ] Consumer subtask 4 has no restore state.
[2019-11-28 00:33:18.018] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (6/8)] [886] [INFO ] Consumer subtask 5 has no restore state.
[2019-11-28 00:33:18.018] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (7/8)] [886] [INFO ] Consumer subtask 6 has no restore state.
[2019-11-28 00:33:18.018] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (3/8)] [886] [INFO ] Consumer subtask 2 has no restore state.
[2019-11-28 00:33:18.018] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (8/8)] [886] [INFO ] Consumer subtask 7 has no restore state.
[2019-11-28 00:33:18.018] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (4/8)] [886] [INFO ] Consumer subtask 3 has no restore state.
[2019-11-28 00:33:18.018] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (4/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:33:18.018] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (3/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:33:18.018] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (6/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:33:18.018] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (2/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:33:18.018] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (7/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:33:18.018] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (1/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:33:18.018] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (8/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:33:18.018] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (5/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:33:18.018] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (7/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:33:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (7/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:33:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (7/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:33:18.018] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (4/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:33:18.018] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (5/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:33:18.018] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (1/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:33:18.018] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (6/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:33:18.018] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (3/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:33:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (3/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:33:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (3/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:33:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (6/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:33:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (6/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:33:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (1/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:33:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (1/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:33:18.018] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (2/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:33:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (5/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:33:18.018] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (8/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:33:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (5/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:33:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (4/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:33:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (4/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:33:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (8/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:33:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (8/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:33:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (2/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:33:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (2/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:33:18.018] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map (1/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:33:18.018] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map (2/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:33:18.018] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map (3/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:33:18.018] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map (5/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:33:18.018] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map (8/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:33:18.018] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map (4/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:33:18.018] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map (6/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:33:18.018] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map (7/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:33:18.018] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (7/8)] [651] [INFO ] Consumer subtask 6 initially has no partitions to read from.
[2019-11-28 00:33:18.018] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (3/8)] [651] [INFO ] Consumer subtask 2 initially has no partitions to read from.
[2019-11-28 00:33:18.018] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (4/8)] [651] [INFO ] Consumer subtask 3 initially has no partitions to read from.
[2019-11-28 00:33:18.018] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (6/8)] [651] [INFO ] Consumer subtask 5 initially has no partitions to read from.
[2019-11-28 00:33:18.018] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (5/8)] [645] [INFO ] Consumer subtask 4 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='ota', partition=0}]
[2019-11-28 00:33:18.018] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (8/8)] [651] [INFO ] Consumer subtask 7 initially has no partitions to read from.
[2019-11-28 00:33:18.018] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (1/8)] [651] [INFO ] Consumer subtask 0 initially has no partitions to read from.
[2019-11-28 00:33:18.018] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (2/8)] [651] [INFO ] Consumer subtask 1 initially has no partitions to read from.
[2019-11-28 00:33:18.018] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-9] [688] [INFO ] Consumer subtask 1 creating fetcher with offsets {}.
[2019-11-28 00:33:18.018] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-12] [688] [INFO ] Consumer subtask 5 creating fetcher with offsets {}.
[2019-11-28 00:33:18.018] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-13] [688] [INFO ] Consumer subtask 6 creating fetcher with offsets {}.
[2019-11-28 00:33:18.018] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-14] [688] [INFO ] Consumer subtask 7 creating fetcher with offsets {}.
[2019-11-28 00:33:18.018] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-10] [688] [INFO ] Consumer subtask 0 creating fetcher with offsets {}.
[2019-11-28 00:33:18.018] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-8] [688] [INFO ] Consumer subtask 3 creating fetcher with offsets {}.
[2019-11-28 00:33:18.018] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-11] [688] [INFO ] Consumer subtask 4 creating fetcher with offsets {KafkaTopicPartition{topic='ota', partition=0}=-915623761773}.
[2019-11-28 00:33:18.018] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-7] [688] [INFO ] Consumer subtask 2 creating fetcher with offsets {}.
[2019-11-28 00:33:18.018] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (8/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:33:18.018] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (7/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:33:18.018] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (3/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:33:18.018] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (2/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:33:18.018] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (5/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:33:18.018] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (4/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:33:18.018] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (6/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:33:18.018] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (1/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:33:18.018] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (5/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:33:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (5/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:33:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (5/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:33:18.018] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (4/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:33:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (4/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:33:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (4/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:33:18.018] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (1/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:33:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (1/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:33:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (1/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:33:18.018] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (2/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:33:18.018] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (7/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:33:18.018] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (3/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:33:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (2/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:33:18.018] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (6/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:33:18.018] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (8/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:33:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (2/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:33:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (8/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:33:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (8/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:33:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (6/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:33:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (6/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:33:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (7/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:33:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (7/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:33:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (3/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:33:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (3/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:33:18.018] [org.apache.kafka.clients.consumer.KafkaConsumer] [Kafka Fetcher for Source: Custom Source -> Map (5/8)] [1090] [INFO ] [Consumer clientId=consumer-13, groupId=test] Subscribed to partition(s): ota-0
[2019-11-28 00:33:18.018] [org.apache.kafka.clients.Metadata] [Kafka Fetcher for Source: Custom Source -> Map (5/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:33:19.019] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler] [Kafka Fetcher for Source: Custom Source -> Map (5/8)] [675] [INFO ] [Consumer clientId=consumer-13, groupId=test] Discovered group coordinator 192.168.1.14:9092 (id: 2147483647 rack: null)
[2019-11-28 00:33:19.019] [org.apache.kafka.clients.consumer.internals.Fetcher] [Kafka Fetcher for Source: Custom Source -> Map (5/8)] [584] [INFO ] [Consumer clientId=consumer-13, groupId=test] Resetting offset for partition ota-0 to offset 1.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (5/8)] [960] [INFO ] Source: Custom Source -> Map (5/8) (86b4609e4b4b629ed5f876aabed2d3d2) switched from RUNNING to FAILED.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException: No content to map due to end-of-input
 at [Source: (byte[])""; line: 1, column: 0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:212) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.performDefaultAction(SourceStreamTask.java:132) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:298) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:403) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) [flink-runtime_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) [flink-runtime_2.11-1.9.0.jar:1.9.0]
	at java.lang.Thread.run(Thread.java:748) [na:1.8.0_131]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException: No content to map due to end-of-input
 at [Source: (byte[])""; line: 1, column: 0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException.from(MismatchedInputException.java:59) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:4145) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4000) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:202) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (5/8)] [804] [INFO ] Freeing task resources for Source: Custom Source -> Map (5/8) (86b4609e4b4b629ed5f876aabed2d3d2).
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (5/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map (5/8) (86b4609e4b4b629ed5f876aabed2d3d2) [FAILED]
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-12] [1438] [INFO ] Un-registering task and sending final execution state FAILED to JobManager for task Source: Custom Source -> Map 86b4609e4b4b629ed5f876aabed2d3d2.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-15] [1493] [INFO ] Source: Custom Source -> Map (5/8) (86b4609e4b4b629ed5f876aabed2d3d2) switched from RUNNING to FAILED.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException: No content to map due to end-of-input
 at [Source: (byte[])""; line: 1, column: 0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:212) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.performDefaultAction(SourceStreamTask.java:132) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:298) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:403) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_131]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException: No content to map due to end-of-input
 at [Source: (byte[])""; line: 1, column: 0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException.from(MismatchedInputException.java:59) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:4145) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4000) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:202) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-15] [1324] [INFO ] Job Flink Streaming Job (791ab942031414319efcd1167287cb3d) switched from state RUNNING to FAILING.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException: No content to map due to end-of-input
 at [Source: (byte[])""; line: 1, column: 0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:212) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.performDefaultAction(SourceStreamTask.java:132) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:298) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:403) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_131]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException: No content to map due to end-of-input
 at [Source: (byte[])""; line: 1, column: 0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException.from(MismatchedInputException.java:59) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:4145) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4000) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:202) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-15] [1491] [INFO ] Source: Custom Source -> Map (1/8) (2f2155435a95dcd42210d12744c0db83) switched from RUNNING to CANCELING.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-12] [982] [INFO ] Attempting to cancel task Source: Custom Source -> Map (1/8) (2f2155435a95dcd42210d12744c0db83).
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-12] [958] [INFO ] Source: Custom Source -> Map (1/8) (2f2155435a95dcd42210d12744c0db83) switched from RUNNING to CANCELING.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-12] [1031] [INFO ] Triggering cancellation of task code Source: Custom Source -> Map (1/8) (2f2155435a95dcd42210d12744c0db83).
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-15] [1491] [INFO ] Source: Custom Source -> Map (2/8) (6647688e1549bfa301f0a1066c782ee4) switched from RUNNING to CANCELING.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-15] [1491] [INFO ] Source: Custom Source -> Map (3/8) (29d7b28375f3227126299465eb29333e) switched from RUNNING to CANCELING.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-15] [1491] [INFO ] Source: Custom Source -> Map (4/8) (286a783991bed4184b2c7f4d8194c37f) switched from RUNNING to CANCELING.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-12] [982] [INFO ] Attempting to cancel task Source: Custom Source -> Map (2/8) (6647688e1549bfa301f0a1066c782ee4).
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-12] [958] [INFO ] Source: Custom Source -> Map (2/8) (6647688e1549bfa301f0a1066c782ee4) switched from RUNNING to CANCELING.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-15] [1491] [INFO ] Source: Custom Source -> Map (6/8) (2723d92c15e51aa6f318ccbbc768c031) switched from RUNNING to CANCELING.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-12] [1031] [INFO ] Triggering cancellation of task code Source: Custom Source -> Map (2/8) (6647688e1549bfa301f0a1066c782ee4).
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-15] [1491] [INFO ] Source: Custom Source -> Map (7/8) (416982fa043e0a29c35befb0225d703d) switched from RUNNING to CANCELING.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-15] [1491] [INFO ] Source: Custom Source -> Map (8/8) (ababebfa2e96fa66b0c70e8b854b6451) switched from RUNNING to CANCELING.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-12] [982] [INFO ] Attempting to cancel task Source: Custom Source -> Map (3/8) (29d7b28375f3227126299465eb29333e).
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-12] [958] [INFO ] Source: Custom Source -> Map (3/8) (29d7b28375f3227126299465eb29333e) switched from RUNNING to CANCELING.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-12] [1031] [INFO ] Triggering cancellation of task code Source: Custom Source -> Map (3/8) (29d7b28375f3227126299465eb29333e).
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-12] [982] [INFO ] Attempting to cancel task Source: Custom Source -> Map (4/8) (286a783991bed4184b2c7f4d8194c37f).
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-12] [958] [INFO ] Source: Custom Source -> Map (4/8) (286a783991bed4184b2c7f4d8194c37f) switched from RUNNING to CANCELING.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-12] [1031] [INFO ] Triggering cancellation of task code Source: Custom Source -> Map (4/8) (286a783991bed4184b2c7f4d8194c37f).
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-12] [982] [INFO ] Attempting to cancel task Source: Custom Source -> Map (6/8) (2723d92c15e51aa6f318ccbbc768c031).
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-12] [958] [INFO ] Source: Custom Source -> Map (6/8) (2723d92c15e51aa6f318ccbbc768c031) switched from RUNNING to CANCELING.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-12] [1031] [INFO ] Triggering cancellation of task code Source: Custom Source -> Map (6/8) (2723d92c15e51aa6f318ccbbc768c031).
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-12] [982] [INFO ] Attempting to cancel task Source: Custom Source -> Map (7/8) (416982fa043e0a29c35befb0225d703d).
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-12] [958] [INFO ] Source: Custom Source -> Map (7/8) (416982fa043e0a29c35befb0225d703d) switched from RUNNING to CANCELING.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-12] [1031] [INFO ] Triggering cancellation of task code Source: Custom Source -> Map (7/8) (416982fa043e0a29c35befb0225d703d).
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-12] [982] [INFO ] Attempting to cancel task Source: Custom Source -> Map (8/8) (ababebfa2e96fa66b0c70e8b854b6451).
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-12] [958] [INFO ] Source: Custom Source -> Map (8/8) (ababebfa2e96fa66b0c70e8b854b6451) switched from RUNNING to CANCELING.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-12] [1031] [INFO ] Triggering cancellation of task code Source: Custom Source -> Map (8/8) (ababebfa2e96fa66b0c70e8b854b6451).
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (1/8)] [958] [INFO ] Source: Custom Source -> Map (1/8) (2f2155435a95dcd42210d12744c0db83) switched from CANCELING to CANCELED.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (1/8)] [804] [INFO ] Freeing task resources for Source: Custom Source -> Map (1/8) (2f2155435a95dcd42210d12744c0db83).
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (1/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map (1/8) (2f2155435a95dcd42210d12744c0db83) [CANCELED]
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-14] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map 2f2155435a95dcd42210d12744c0db83.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-14] [1491] [INFO ] Source: Custom Source -> Map (1/8) (2f2155435a95dcd42210d12744c0db83) switched from CANCELING to CANCELED.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (4/8)] [958] [INFO ] Source: Custom Source -> Map (4/8) (286a783991bed4184b2c7f4d8194c37f) switched from CANCELING to CANCELED.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (4/8)] [804] [INFO ] Freeing task resources for Source: Custom Source -> Map (4/8) (286a783991bed4184b2c7f4d8194c37f).
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (4/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map (4/8) (286a783991bed4184b2c7f4d8194c37f) [CANCELED]
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-15] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map 286a783991bed4184b2c7f4d8194c37f.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (6/8)] [958] [INFO ] Source: Custom Source -> Map (6/8) (2723d92c15e51aa6f318ccbbc768c031) switched from CANCELING to CANCELED.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-14] [1491] [INFO ] Source: Custom Source -> Map (4/8) (286a783991bed4184b2c7f4d8194c37f) switched from CANCELING to CANCELED.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (8/8)] [958] [INFO ] Source: Custom Source -> Map (8/8) (ababebfa2e96fa66b0c70e8b854b6451) switched from CANCELING to CANCELED.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (6/8)] [804] [INFO ] Freeing task resources for Source: Custom Source -> Map (6/8) (2723d92c15e51aa6f318ccbbc768c031).
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (8/8)] [804] [INFO ] Freeing task resources for Source: Custom Source -> Map (8/8) (ababebfa2e96fa66b0c70e8b854b6451).
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (6/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map (6/8) (2723d92c15e51aa6f318ccbbc768c031) [CANCELED]
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (8/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map (8/8) (ababebfa2e96fa66b0c70e8b854b6451) [CANCELED]
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-14] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map 2723d92c15e51aa6f318ccbbc768c031.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (7/8)] [958] [INFO ] Source: Custom Source -> Map (7/8) (416982fa043e0a29c35befb0225d703d) switched from CANCELING to CANCELED.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-14] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map ababebfa2e96fa66b0c70e8b854b6451.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (7/8)] [804] [INFO ] Freeing task resources for Source: Custom Source -> Map (7/8) (416982fa043e0a29c35befb0225d703d).
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (2/8)] [958] [INFO ] Source: Custom Source -> Map (2/8) (6647688e1549bfa301f0a1066c782ee4) switched from CANCELING to CANCELED.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-15] [1491] [INFO ] Source: Custom Source -> Map (6/8) (2723d92c15e51aa6f318ccbbc768c031) switched from CANCELING to CANCELED.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (7/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map (7/8) (416982fa043e0a29c35befb0225d703d) [CANCELED]
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (2/8)] [804] [INFO ] Freeing task resources for Source: Custom Source -> Map (2/8) (6647688e1549bfa301f0a1066c782ee4).
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (3/8)] [958] [INFO ] Source: Custom Source -> Map (3/8) (29d7b28375f3227126299465eb29333e) switched from CANCELING to CANCELED.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-14] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map 416982fa043e0a29c35befb0225d703d.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (2/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map (2/8) (6647688e1549bfa301f0a1066c782ee4) [CANCELED]
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (3/8)] [804] [INFO ] Freeing task resources for Source: Custom Source -> Map (3/8) (29d7b28375f3227126299465eb29333e).
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-15] [1491] [INFO ] Source: Custom Source -> Map (8/8) (ababebfa2e96fa66b0c70e8b854b6451) switched from CANCELING to CANCELED.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-14] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map 6647688e1549bfa301f0a1066c782ee4.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (3/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map (3/8) (29d7b28375f3227126299465eb29333e) [CANCELED]
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-15] [1491] [INFO ] Source: Custom Source -> Map (7/8) (416982fa043e0a29c35befb0225d703d) switched from CANCELING to CANCELED.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-14] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map 29d7b28375f3227126299465eb29333e.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-15] [1491] [INFO ] Source: Custom Source -> Map (2/8) (6647688e1549bfa301f0a1066c782ee4) switched from CANCELING to CANCELED.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-15] [1491] [INFO ] Source: Custom Source -> Map (3/8) (29d7b28375f3227126299465eb29333e) switched from CANCELING to CANCELED.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-15] [1446] [INFO ] Try to restart or fail the job Flink Streaming Job (791ab942031414319efcd1167287cb3d) if no longer possible.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-15] [1324] [INFO ] Job Flink Streaming Job (791ab942031414319efcd1167287cb3d) switched from state FAILING to FAILED.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException: No content to map due to end-of-input
 at [Source: (byte[])""; line: 1, column: 0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:212) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.performDefaultAction(SourceStreamTask.java:132) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:298) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:403) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_131]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException: No content to map due to end-of-input
 at [Source: (byte[])""; line: 1, column: 0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException.from(MismatchedInputException.java:59) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:4145) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4000) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:202) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-15] [1472] [INFO ] Could not restart the job Flink Streaming Job (791ab942031414319efcd1167287cb3d) because the restart strategy prevented it.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException: No content to map due to end-of-input
 at [Source: (byte[])""; line: 1, column: 0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:212) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.performDefaultAction(SourceStreamTask.java:132) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:298) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:403) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_131]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException: No content to map due to end-of-input
 at [Source: (byte[])""; line: 1, column: 0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException.from(MismatchedInputException.java:59) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:4145) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4000) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:202) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.checkpoint.CheckpointCoordinator] [flink-akka.actor.default-dispatcher-15] [329] [INFO ] Stopping checkpoint coordinator for job 791ab942031414319efcd1167287cb3d.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore] [flink-akka.actor.default-dispatcher-15] [97] [INFO ] Shutting down
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-12] [775] [INFO ] Job 791ab942031414319efcd1167287cb3d reached globally terminal state FAILED.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [417] [INFO ] Shutting down Flink Mini Cluster
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-14] [334] [INFO ] Stopping TaskExecutor akka://flink/user/taskmanager_0.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.rest.RestServerEndpoint] [main] [290] [INFO ] Shutting down rest endpoint.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-15] [335] [INFO ] Stopping the JobMaster for job Flink Streaming Job(791ab942031414319efcd1167287cb3d).
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-14] [142] [INFO ] Stop job leader service.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager] [flink-akka.actor.default-dispatcher-14] [213] [INFO ] Shutting down TaskExecutorLocalStateStoresManager.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-15] [228] [INFO ] Suspending SlotPool.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-15] [1010] [INFO ] Close ResourceManager connection 3a54be7fba75a9e670adf6ebafdb456a: JobManager is shutting down..
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-15] [249] [INFO ] Stopping SlotPool.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-12] [774] [INFO ] Disconnect job manager a5a8245a1dc53fface2a143b31b946ea@akka://flink/user/jobmanager_1 for job 791ab942031414319efcd1167287cb3d from the resource manager.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [flink-akka.actor.default-dispatcher-14] [112] [INFO ] FileChannelManager removed spill file directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-io-bce467db-c819-4b7c-8618-3de4f5b470bf
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.io.network.NettyShuffleEnvironment] [flink-akka.actor.default-dispatcher-14] [304] [INFO ] Shutting down the network environment and its components.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [flink-akka.actor.default-dispatcher-14] [112] [INFO ] FileChannelManager removed spill file directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-netty-shuffle-f50a8211-2c9f-4c0a-a5ac-a1f84e137f9b
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskexecutor.KvStateService] [flink-akka.actor.default-dispatcher-14] [119] [INFO ] Shutting down the kvState service and its components.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-14] [142] [INFO ] Stop job leader service.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.filecache.FileCache] [flink-akka.actor.default-dispatcher-14] [153] [INFO ] removed file cache directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-dist-cache-2a84eb0f-d6c4-470e-bea3-1ce90f7c2428
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-14] [359] [INFO ] Stopped TaskExecutor akka://flink/user/taskmanager_0.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.webmonitor.WebMonitorEndpoint] [ForkJoinPool.commonPool-worker-1] [687] [INFO ] Removing cache directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-web-ui
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.rest.RestServerEndpoint] [main] [299] [INFO ] Shut down complete.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-12] [499] [INFO ] Shut down cluster because application is in CANCELED, diagnostics DispatcherResourceManagerComponent has been closed..
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-12] [220] [INFO ] Stopping dispatcher akka://flink/user/dispatcher.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl] [flink-akka.actor.default-dispatcher-14] [280] [INFO ] Closing the SlotManager.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-12] [697] [INFO ] Stopping all currently running jobs of dispatcher akka://flink/user/dispatcher.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl] [flink-akka.actor.default-dispatcher-14] [243] [INFO ] Suspending the SlotManager.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.rest.handler.legacy.backpressure.StackTraceSampleCoordinator] [flink-akka.actor.default-dispatcher-12] [220] [INFO ] Shutting down stack trace sample coordinator.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-12] [229] [INFO ] Stopped dispatcher akka://flink/user/dispatcher.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [flink-akka.actor.default-dispatcher-12] [335] [INFO ] Stopping Akka RPC service.
[2019-11-28 00:34:10.010] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-2] [83] [INFO ] Shutting down remote daemon.
[2019-11-28 00:34:10.010] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-2] [83] [INFO ] Remote daemon shut down; proceeding with flushing remote transports.
[2019-11-28 00:34:10.010] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-2] [83] [INFO ] Remoting shut down.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [flink-metrics-2] [335] [INFO ] Stopping Akka RPC service.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [flink-metrics-2] [354] [INFO ] Stopped Akka RPC service.
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.blob.AbstractBlobCache] [flink-akka.actor.default-dispatcher-14] [247] [INFO ] Shutting down BLOB cache
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.blob.AbstractBlobCache] [flink-akka.actor.default-dispatcher-14] [247] [INFO ] Shutting down BLOB cache
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.blob.BlobServer] [flink-akka.actor.default-dispatcher-14] [340] [INFO ] Stopped BLOB server at 0.0.0.0:52666
[2019-11-28 00:34:10.010] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [flink-akka.actor.default-dispatcher-14] [354] [INFO ] Stopped Akka RPC service.
[2019-11-28 00:35:31.031] [org.apache.flink.api.java.typeutils.TypeExtractor] [main] [1815] [INFO ] class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a getter for field _children
[2019-11-28 00:35:31.031] [org.apache.flink.api.java.typeutils.TypeExtractor] [main] [1818] [INFO ] class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a setter for field _children
[2019-11-28 00:35:31.031] [org.apache.flink.api.java.typeutils.TypeExtractor] [main] [1857] [INFO ] Class class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:35:31.031] [org.apache.flink.streaming.api.environment.LocalStreamEnvironment] [main] [108] [INFO ] Running job on local embedded Flink mini cluster
[2019-11-28 00:35:31.031] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [254] [INFO ] Starting Flink Mini Cluster
[2019-11-28 00:35:31.031] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [263] [INFO ] Starting Metrics Registry
[2019-11-28 00:35:31.031] [org.apache.flink.runtime.metrics.MetricRegistryImpl] [main] [114] [INFO ] No metrics reporter configured, no metrics will be exposed/reported.
[2019-11-28 00:35:31.031] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [267] [INFO ] Starting RPC Service(s)
[2019-11-28 00:35:31.031] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1] [flink-akka.actor.default-dispatcher-3] [92] [INFO ] Slf4jLogger started
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.clusterframework.BootstrapTools] [main] [244] [INFO ] Trying to start actor system at :0
[2019-11-28 00:35:32.032] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1] [flink-metrics-2] [92] [INFO ] Slf4jLogger started
[2019-11-28 00:35:32.032] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-2] [83] [INFO ] Starting remoting
[2019-11-28 00:35:32.032] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-2] [83] [INFO ] Remoting started; listening on addresses :[akka.tcp://flink-metrics@192.168.1.14:52713]
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.clusterframework.BootstrapTools] [main] [256] [INFO ] Actor system started at akka.tcp://flink-metrics@192.168.1.14:52713
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [398] [INFO ] Starting high-availability services
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.blob.BlobServer] [main] [141] [INFO ] Created BLOB server storage directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/blobStore-ab2e4718-c59e-49d1-9616-f24546d06d8d
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.blob.BlobServer] [main] [203] [INFO ] Started BLOB server at 0.0.0.0:52714 - max concurrent requests: 50 - max backlog: 1000
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.blob.AbstractBlobCache] [main] [107] [INFO ] Created BLOB cache storage directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/blobStore-af35ddd4-791d-44ab-869e-e7a8065c8c4f
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.blob.AbstractBlobCache] [main] [107] [INFO ] Created BLOB cache storage directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/blobStore-968aa289-8db1-48bd-98be-afe2f508b307
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [480] [INFO ] Starting 1 TaskManger(s)
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.taskexecutor.TaskManagerRunner] [main] [351] [INFO ] Starting TaskManager with ResourceID: bba305da-1957-4e84-9313-3563de4f942d
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.taskexecutor.TaskManagerServices] [main] [519] [INFO ] Temporary file directory '/var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T': total 233 GB, usable 170 GB (72.96% usable)
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [main] [76] [INFO ] FileChannelManager uses directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-io-11c78b2a-9c85-4489-86a6-f9b959ade375 for spill files.
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [main] [76] [INFO ] FileChannelManager uses directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-netty-shuffle-03fde738-3f33-4706-8b78-755d93b39ab3 for spill files.
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.io.network.buffer.NetworkBufferPool] [main] [140] [INFO ] Allocated 202 MB for network buffer pool (number of memory segments: 6472, bytes per segment: 32768).
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.io.network.NettyShuffleEnvironment] [main] [283] [INFO ] Starting the network environment and its components.
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.taskexecutor.KvStateService] [main] [89] [INFO ] Starting the kvState service and its components.
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.taskexecutor.TaskManagerServices] [main] [364] [INFO ] Limiting managed memory to 0.7 of the currently free heap space (1267 MB), memory will be allocated lazily.
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.taskexecutor.TaskManagerConfiguration] [main] [197] [INFO ] Messages have a max timeout of 10000 ms
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-2] [125] [INFO ] Start job leader service.
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.filecache.FileCache] [flink-akka.actor.default-dispatcher-2] [107] [INFO ] User file cache uses directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-dist-cache-cc7f68c4-b716-4868-8a53-51911fb747ac
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.rest.RestServerEndpoint] [main] [136] [INFO ] Starting rest endpoint.
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.webmonitor.WebMonitorUtils$LogFileLocation] [main] [87] [WARN ] Log file environment variable 'log.file' is not set.
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.webmonitor.WebMonitorUtils$LogFileLocation] [main] [93] [WARN ] JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] [main] [114] [INFO ] Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.rest.RestServerEndpoint] [main] [233] [INFO ] Rest endpoint listening at localhost:52715
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [main] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@4a5905d9 @ http://localhost:52715
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.webmonitor.WebMonitorEndpoint] [mini-cluster-io-thread-1] [711] [INFO ] http://localhost:52715 was granted leadership with leaderSessionID=cb6a2036-072d-467e-9182-a2bcf398fd23
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [mini-cluster-io-thread-1] [250] [INFO ] Received confirmation of leadership for leader http://localhost:52715 , session=cb6a2036-072d-467e-9182-a2bcf398fd23
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-2] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@650b80cb @ akka://flink/user/resourcemanager
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-3] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@6ee5ee7b @ akka://flink/user/dispatcher
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-3] [885] [INFO ] Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token b90f4225-d7eb-4fd6-819e-f0fb43c08a0e
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [363] [INFO ] Flink Mini Cluster started successfully
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-2] [919] [INFO ] ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token 94d9c9ad527a4353ba079e9ccaa5433f
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-4] [717] [INFO ] Recovering all persisted jobs.
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl] [flink-akka.actor.default-dispatcher-2] [215] [INFO ] Starting the SlotManager.
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-3] [250] [INFO ] Received confirmation of leadership for leader akka://flink/user/dispatcher , session=b90f4225-d7eb-4fd6-819e-f0fb43c08a0e
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-4] [250] [INFO ] Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=ba079e9c-caa5-433f-94d9-c9ad527a4353
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [982] [INFO ] Connecting to ResourceManager akka://flink/user/resourcemanager(94d9c9ad527a4353ba079e9ccaa5433f).
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-3] [155] [INFO ] Resolved ResourceManager address, beginning registration
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-3] [204] [INFO ] Registration at ResourceManager attempt 1 (timeout=100ms)
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-4] [711] [INFO ] Registering TaskManager with ResourceID bba305da-1957-4e84-9313-3563de4f942d (akka://flink/user/taskmanager_0) at ResourceManager
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-2] [264] [INFO ] Received JobGraph submission 77edbd2969d906323b1c8d0a587fc981 (Flink Streaming Job).
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.taskexecutor.TaskExecutorToResourceManagerConnection] [flink-akka.actor.default-dispatcher-5] [100] [INFO ] Successful registration at resource manager akka://flink/user/resourcemanager under registration id d8f2534710a2f0df5700bf85a8196b13.
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-2] [321] [INFO ] Submitting job 77edbd2969d906323b1c8d0a587fc981 (Flink Streaming Job).
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [flink-akka.actor.default-dispatcher-5] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-5] [241] [INFO ] Initializing job Flink Streaming Job (77edbd2969d906323b1c8d0a587fc981).
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.scheduler.LegacyScheduler] [flink-akka.actor.default-dispatcher-5] [171] [INFO ] Using restart strategy NoRestartStrategy for Flink Streaming Job (77edbd2969d906323b1c8d0a587fc981).
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-5] [516] [INFO ] Job recovers via failover strategy: full graph restart
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.executiongraph.ExecutionGraphBuilder] [flink-akka.actor.default-dispatcher-5] [204] [INFO ] Running initialization on master for job Flink Streaming Job (77edbd2969d906323b1c8d0a587fc981).
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.executiongraph.ExecutionGraphBuilder] [flink-akka.actor.default-dispatcher-5] [222] [INFO ] Successfully ran initialization on master in 0 ms.
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.state.StateBackendLoader] [flink-akka.actor.default-dispatcher-5] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-5] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@598f6177 @ akka://flink/user/jobmanager_1
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.jobmaster.JobManagerRunner] [mini-cluster-io-thread-3] [313] [INFO ] JobManager runner for job Flink Streaming Job (77edbd2969d906323b1c8d0a587fc981) was granted leadership with session id 52d8a817-c202-4780-8d15-461b1b7ec04a at akka://flink/user/jobmanager_1.
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-3] [709] [INFO ] Starting execution of job Flink Streaming Job (77edbd2969d906323b1c8d0a587fc981) under job master id 8d15461b1b7ec04a52d8a817c2024780.
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-3] [1324] [INFO ] Job Flink Streaming Job (77edbd2969d906323b1c8d0a587fc981) switched from state CREATED to RUNNING.
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map (1/8) (0d69998bef3c5efa9bfdde62fcc2a26f) switched from CREATED to SCHEDULED.
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-3] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{36801cef673f5a7142093d176d3b7d43}]
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map (2/8) (dcec4b2da911fc566109b7ba0eca5874) switched from CREATED to SCHEDULED.
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-3] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{d2f373390f6f40827d7c6b2e836acc86}]
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map (3/8) (c5fda8305e3b546ad0353bbfdc7a90ca) switched from CREATED to SCHEDULED.
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-3] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{db587edb425e27a7faeb3cef3b0252bb}]
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map (4/8) (c5762d6aa521c600a12d946a04627d97) switched from CREATED to SCHEDULED.
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-3] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{7d39118f4321dc805e1685389c8fadbb}]
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map (5/8) (429d2e3bab85d7adf60f126d4616bd82) switched from CREATED to SCHEDULED.
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-3] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{fee1cfdb9cf26e21b87b873762fe66c9}]
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map (6/8) (f02c5088f2169d8d1a2b32e010c31a85) switched from CREATED to SCHEDULED.
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-3] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{79ddab631fad887425401783417f9a4c}]
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map (7/8) (35404502172d4632dd76db1e6918e207) switched from CREATED to SCHEDULED.
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-3] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{40960b65d2857fd15df8b5984e49d2cc}]
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map (8/8) (c1663fa88c8002d9d645eef110422a29) switched from CREATED to SCHEDULED.
[2019-11-28 00:35:32.032] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-3] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{f18c4f9a4b1149db58db29785a5eb32f}]
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [jobmanager-future-thread-1] [250] [INFO ] Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=52d8a817-c202-4780-8d15-461b1b7ec04a
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-3] [940] [INFO ] Connecting to ResourceManager akka://flink/user/resourcemanager(94d9c9ad527a4353ba079e9ccaa5433f)
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-3] [155] [INFO ] Resolved ResourceManager address, beginning registration
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-3] [204] [INFO ] Registration at ResourceManager attempt 1 (timeout=100ms)
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [302] [INFO ] Registering job manager 8d15461b1b7ec04a52d8a817c2024780@akka://flink/user/jobmanager_1 for job 77edbd2969d906323b1c8d0a587fc981.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-2] [657] [INFO ] Registered job manager 8d15461b1b7ec04a52d8a817c2024780@akka://flink/user/jobmanager_1 for job 77edbd2969d906323b1c8d0a587fc981.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-2] [962] [INFO ] JobManager successfully registered at ResourceManager, leader id: 94d9c9ad527a4353ba079e9ccaa5433f.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [319] [INFO ] Requesting new slot [SlotRequestId{36801cef673f5a7142093d176d3b7d43}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 77edbd2969d906323b1c8d0a587fc981 with allocation id c5f59bbc20a693764e7d52a10115f018.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [319] [INFO ] Requesting new slot [SlotRequestId{d2f373390f6f40827d7c6b2e836acc86}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [319] [INFO ] Requesting new slot [SlotRequestId{db587edb425e27a7faeb3cef3b0252bb}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [319] [INFO ] Requesting new slot [SlotRequestId{7d39118f4321dc805e1685389c8fadbb}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [816] [INFO ] Receive slot request c5f59bbc20a693764e7d52a10115f018 for job 77edbd2969d906323b1c8d0a587fc981 from resource manager with leader id 94d9c9ad527a4353ba079e9ccaa5433f.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [319] [INFO ] Requesting new slot [SlotRequestId{fee1cfdb9cf26e21b87b873762fe66c9}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [319] [INFO ] Requesting new slot [SlotRequestId{79ddab631fad887425401783417f9a4c}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 77edbd2969d906323b1c8d0a587fc981 with allocation id 1c41992ee1addf9ece2a719eb5d14c35.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [828] [INFO ] Allocated slot for c5f59bbc20a693764e7d52a10115f018.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [319] [INFO ] Requesting new slot [SlotRequestId{40960b65d2857fd15df8b5984e49d2cc}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-5] [193] [INFO ] Add job 77edbd2969d906323b1c8d0a587fc981 for job leader monitoring.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 77edbd2969d906323b1c8d0a587fc981 with allocation id 144408cf6f1a4690b4bbc22b9d064b3a.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [319] [INFO ] Requesting new slot [SlotRequestId{f18c4f9a4b1149db58db29785a5eb32f}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 77edbd2969d906323b1c8d0a587fc981 with allocation id aabdb7bc7fc005be7e4a2bc66ccc0234.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 77edbd2969d906323b1c8d0a587fc981 with allocation id bf8e061c6df8c4e61ecf0d28b9d13931.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [816] [INFO ] Receive slot request 1c41992ee1addf9ece2a719eb5d14c35 for job 77edbd2969d906323b1c8d0a587fc981 from resource manager with leader id 94d9c9ad527a4353ba079e9ccaa5433f.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [828] [INFO ] Allocated slot for 1c41992ee1addf9ece2a719eb5d14c35.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 77edbd2969d906323b1c8d0a587fc981 with allocation id 9ea5ab1bcecca3ccfadec9f4453c1217.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-8] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 52d8a817-c202-4780-8d15-461b1b7ec04a.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-5] [193] [INFO ] Add job 77edbd2969d906323b1c8d0a587fc981 for job leader monitoring.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 77edbd2969d906323b1c8d0a587fc981 with allocation id bb933534beb1ef293acc0e8c5fdcc8b1.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [816] [INFO ] Receive slot request 144408cf6f1a4690b4bbc22b9d064b3a for job 77edbd2969d906323b1c8d0a587fc981 from resource manager with leader id 94d9c9ad527a4353ba079e9ccaa5433f.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-1] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 52d8a817-c202-4780-8d15-461b1b7ec04a.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-2] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 77edbd2969d906323b1c8d0a587fc981 with allocation id f120caafa45eb0e30d60ee3ea543e00a.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [828] [INFO ] Allocated slot for 144408cf6f1a4690b4bbc22b9d064b3a.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-5] [193] [INFO ] Add job 77edbd2969d906323b1c8d0a587fc981 for job leader monitoring.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-4] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [816] [INFO ] Receive slot request aabdb7bc7fc005be7e4a2bc66ccc0234 for job 77edbd2969d906323b1c8d0a587fc981 from resource manager with leader id 94d9c9ad527a4353ba079e9ccaa5433f.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-6] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 52d8a817-c202-4780-8d15-461b1b7ec04a.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [828] [INFO ] Allocated slot for aabdb7bc7fc005be7e4a2bc66ccc0234.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-5] [193] [INFO ] Add job 77edbd2969d906323b1c8d0a587fc981 for job leader monitoring.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-5] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 52d8a817-c202-4780-8d15-461b1b7ec04a.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [816] [INFO ] Receive slot request bf8e061c6df8c4e61ecf0d28b9d13931 for job 77edbd2969d906323b1c8d0a587fc981 from resource manager with leader id 94d9c9ad527a4353ba079e9ccaa5433f.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-3] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [828] [INFO ] Allocated slot for bf8e061c6df8c4e61ecf0d28b9d13931.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-5] [193] [INFO ] Add job 77edbd2969d906323b1c8d0a587fc981 for job leader monitoring.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-3] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-7] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 52d8a817-c202-4780-8d15-461b1b7ec04a.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [816] [INFO ] Receive slot request 9ea5ab1bcecca3ccfadec9f4453c1217 for job 77edbd2969d906323b1c8d0a587fc981 from resource manager with leader id 94d9c9ad527a4353ba079e9ccaa5433f.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [828] [INFO ] Allocated slot for 9ea5ab1bcecca3ccfadec9f4453c1217.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-5] [193] [INFO ] Add job 77edbd2969d906323b1c8d0a587fc981 for job leader monitoring.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-3] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 52d8a817-c202-4780-8d15-461b1b7ec04a.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-3] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [816] [INFO ] Receive slot request bb933534beb1ef293acc0e8c5fdcc8b1 for job 77edbd2969d906323b1c8d0a587fc981 from resource manager with leader id 94d9c9ad527a4353ba079e9ccaa5433f.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [828] [INFO ] Allocated slot for bb933534beb1ef293acc0e8c5fdcc8b1.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-2] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-5] [193] [INFO ] Add job 77edbd2969d906323b1c8d0a587fc981 for job leader monitoring.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-2] [204] [INFO ] Registration at JobManager attempt 1 (timeout=100ms)
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-2] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 52d8a817-c202-4780-8d15-461b1b7ec04a.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [816] [INFO ] Receive slot request f120caafa45eb0e30d60ee3ea543e00a for job 77edbd2969d906323b1c8d0a587fc981 from resource manager with leader id 94d9c9ad527a4353ba079e9ccaa5433f.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [828] [INFO ] Allocated slot for f120caafa45eb0e30d60ee3ea543e00a.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-5] [193] [INFO ] Add job 77edbd2969d906323b1c8d0a587fc981 for job leader monitoring.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-4] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 52d8a817-c202-4780-8d15-461b1b7ec04a.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-4] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-2] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-2] [204] [INFO ] Registration at JobManager attempt 1 (timeout=100ms)
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener$JobManagerRegisteredRpcConnection] [flink-akka.actor.default-dispatcher-4] [382] [INFO ] Successful registration at job manager akka://flink/user/jobmanager_1 for job 77edbd2969d906323b1c8d0a587fc981.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [1220] [INFO ] Establish JobManager connection for job 77edbd2969d906323b1c8d0a587fc981.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [1121] [INFO ] Offer reserved slots to the leader of job 77edbd2969d906323b1c8d0a587fc981.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map (1/8) (0d69998bef3c5efa9bfdde62fcc2a26f) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [712] [INFO ] Deploying Source: Custom Source -> Map (1/8) (attempt #0) to bba305da-1957-4e84-9313-3563de4f942d @ localhost (dataPort=-1)
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map (2/8) (dcec4b2da911fc566109b7ba0eca5874) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [712] [INFO ] Deploying Source: Custom Source -> Map (2/8) (attempt #0) to bba305da-1957-4e84-9313-3563de4f942d @ localhost (dataPort=-1)
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map (3/8) (c5fda8305e3b546ad0353bbfdc7a90ca) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [712] [INFO ] Deploying Source: Custom Source -> Map (3/8) (attempt #0) to bba305da-1957-4e84-9313-3563de4f942d @ localhost (dataPort=-1)
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map (4/8) (c5762d6aa521c600a12d946a04627d97) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [712] [INFO ] Deploying Source: Custom Source -> Map (4/8) (attempt #0) to bba305da-1957-4e84-9313-3563de4f942d @ localhost (dataPort=-1)
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map (5/8) (429d2e3bab85d7adf60f126d4616bd82) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [712] [INFO ] Deploying Source: Custom Source -> Map (5/8) (attempt #0) to bba305da-1957-4e84-9313-3563de4f942d @ localhost (dataPort=-1)
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map (6/8) (f02c5088f2169d8d1a2b32e010c31a85) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [712] [INFO ] Deploying Source: Custom Source -> Map (6/8) (attempt #0) to bba305da-1957-4e84-9313-3563de4f942d @ localhost (dataPort=-1)
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map (7/8) (35404502172d4632dd76db1e6918e207) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [712] [INFO ] Deploying Source: Custom Source -> Map (7/8) (attempt #0) to bba305da-1957-4e84-9313-3563de4f942d @ localhost (dataPort=-1)
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map (8/8) (c1663fa88c8002d9d645eef110422a29) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [712] [INFO ] Deploying Source: Custom Source -> Map (8/8) (attempt #0) to bba305da-1957-4e84-9313-3563de4f942d @ localhost (dataPort=-1)
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [587] [INFO ] Received task Source: Custom Source -> Map (1/8).
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (1/8)] [958] [INFO ] Source: Custom Source -> Map (1/8) (0d69998bef3c5efa9bfdde62fcc2a26f) switched from CREATED to DEPLOYING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (1/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (1/8) (0d69998bef3c5efa9bfdde62fcc2a26f) [DEPLOYING]
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (1/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map (1/8) (0d69998bef3c5efa9bfdde62fcc2a26f) [DEPLOYING].
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [587] [INFO ] Received task Source: Custom Source -> Map (2/8).
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (2/8)] [958] [INFO ] Source: Custom Source -> Map (2/8) (dcec4b2da911fc566109b7ba0eca5874) switched from CREATED to DEPLOYING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (2/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (2/8) (dcec4b2da911fc566109b7ba0eca5874) [DEPLOYING]
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (2/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map (2/8) (dcec4b2da911fc566109b7ba0eca5874) [DEPLOYING].
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (1/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map (1/8) (0d69998bef3c5efa9bfdde62fcc2a26f) [DEPLOYING].
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (2/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map (2/8) (dcec4b2da911fc566109b7ba0eca5874) [DEPLOYING].
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [587] [INFO ] Received task Source: Custom Source -> Map (3/8).
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (3/8)] [958] [INFO ] Source: Custom Source -> Map (3/8) (c5fda8305e3b546ad0353bbfdc7a90ca) switched from CREATED to DEPLOYING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (3/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (3/8) (c5fda8305e3b546ad0353bbfdc7a90ca) [DEPLOYING]
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (3/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map (3/8) (c5fda8305e3b546ad0353bbfdc7a90ca) [DEPLOYING].
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (3/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map (3/8) (c5fda8305e3b546ad0353bbfdc7a90ca) [DEPLOYING].
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [587] [INFO ] Received task Source: Custom Source -> Map (4/8).
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (4/8)] [958] [INFO ] Source: Custom Source -> Map (4/8) (c5762d6aa521c600a12d946a04627d97) switched from CREATED to DEPLOYING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (4/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (4/8) (c5762d6aa521c600a12d946a04627d97) [DEPLOYING]
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (4/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map (4/8) (c5762d6aa521c600a12d946a04627d97) [DEPLOYING].
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (4/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map (4/8) (c5762d6aa521c600a12d946a04627d97) [DEPLOYING].
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [587] [INFO ] Received task Source: Custom Source -> Map (5/8).
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (5/8)] [958] [INFO ] Source: Custom Source -> Map (5/8) (429d2e3bab85d7adf60f126d4616bd82) switched from CREATED to DEPLOYING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (5/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (5/8) (429d2e3bab85d7adf60f126d4616bd82) [DEPLOYING]
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (5/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map (5/8) (429d2e3bab85d7adf60f126d4616bd82) [DEPLOYING].
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (5/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map (5/8) (429d2e3bab85d7adf60f126d4616bd82) [DEPLOYING].
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [587] [INFO ] Received task Source: Custom Source -> Map (6/8).
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (6/8)] [958] [INFO ] Source: Custom Source -> Map (6/8) (f02c5088f2169d8d1a2b32e010c31a85) switched from CREATED to DEPLOYING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (6/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (6/8) (f02c5088f2169d8d1a2b32e010c31a85) [DEPLOYING]
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (2/8)] [958] [INFO ] Source: Custom Source -> Map (2/8) (dcec4b2da911fc566109b7ba0eca5874) switched from DEPLOYING to RUNNING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (4/8)] [958] [INFO ] Source: Custom Source -> Map (4/8) (c5762d6aa521c600a12d946a04627d97) switched from DEPLOYING to RUNNING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (3/8)] [958] [INFO ] Source: Custom Source -> Map (3/8) (c5fda8305e3b546ad0353bbfdc7a90ca) switched from DEPLOYING to RUNNING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (5/8)] [958] [INFO ] Source: Custom Source -> Map (5/8) (429d2e3bab85d7adf60f126d4616bd82) switched from DEPLOYING to RUNNING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (6/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map (6/8) (f02c5088f2169d8d1a2b32e010c31a85) [DEPLOYING].
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (1/8)] [958] [INFO ] Source: Custom Source -> Map (1/8) (0d69998bef3c5efa9bfdde62fcc2a26f) switched from DEPLOYING to RUNNING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map (2/8) (dcec4b2da911fc566109b7ba0eca5874) switched from DEPLOYING to RUNNING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [587] [INFO ] Received task Source: Custom Source -> Map (7/8).
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (6/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map (6/8) (f02c5088f2169d8d1a2b32e010c31a85) [DEPLOYING].
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map (4/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map (1/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map (5/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map (3/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map (2/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map (4/8) (c5762d6aa521c600a12d946a04627d97) switched from DEPLOYING to RUNNING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (7/8)] [958] [INFO ] Source: Custom Source -> Map (7/8) (35404502172d4632dd76db1e6918e207) switched from CREATED to DEPLOYING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (6/8)] [958] [INFO ] Source: Custom Source -> Map (6/8) (f02c5088f2169d8d1a2b32e010c31a85) switched from DEPLOYING to RUNNING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map (3/8) (c5fda8305e3b546ad0353bbfdc7a90ca) switched from DEPLOYING to RUNNING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (7/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (7/8) (35404502172d4632dd76db1e6918e207) [DEPLOYING]
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map (6/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map (5/8) (429d2e3bab85d7adf60f126d4616bd82) switched from DEPLOYING to RUNNING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (7/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map (7/8) (35404502172d4632dd76db1e6918e207) [DEPLOYING].
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [587] [INFO ] Received task Source: Custom Source -> Map (8/8).
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map (1/8) (0d69998bef3c5efa9bfdde62fcc2a26f) switched from DEPLOYING to RUNNING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map (6/8) (f02c5088f2169d8d1a2b32e010c31a85) switched from DEPLOYING to RUNNING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot bb933534beb1ef293acc0e8c5fdcc8b1.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (8/8)] [958] [INFO ] Source: Custom Source -> Map (8/8) (c1663fa88c8002d9d645eef110422a29) switched from CREATED to DEPLOYING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot f120caafa45eb0e30d60ee3ea543e00a.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (7/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map (7/8) (35404502172d4632dd76db1e6918e207) [DEPLOYING].
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (8/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (8/8) (c1663fa88c8002d9d645eef110422a29) [DEPLOYING]
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot c5f59bbc20a693764e7d52a10115f018.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (8/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map (8/8) (c1663fa88c8002d9d645eef110422a29) [DEPLOYING].
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (7/8)] [958] [INFO ] Source: Custom Source -> Map (7/8) (35404502172d4632dd76db1e6918e207) switched from DEPLOYING to RUNNING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot aabdb7bc7fc005be7e4a2bc66ccc0234.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (8/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map (8/8) (c1663fa88c8002d9d645eef110422a29) [DEPLOYING].
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map (7/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map (7/8) (35404502172d4632dd76db1e6918e207) switched from DEPLOYING to RUNNING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot bf8e061c6df8c4e61ecf0d28b9d13931.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (8/8)] [958] [INFO ] Source: Custom Source -> Map (8/8) (c1663fa88c8002d9d645eef110422a29) switched from DEPLOYING to RUNNING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot 1c41992ee1addf9ece2a719eb5d14c35.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map (8/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Source: Custom Source -> Map (8/8) (c1663fa88c8002d9d645eef110422a29) switched from DEPLOYING to RUNNING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot 144408cf6f1a4690b4bbc22b9d064b3a.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot 9ea5ab1bcecca3ccfadec9f4453c1217.
[2019-11-28 00:35:33.033] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (7/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:35:33.033] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (3/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:35:33.033] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (5/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:35:33.033] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (8/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:35:33.033] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (1/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:35:33.033] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (6/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:35:33.033] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (2/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:35:33.033] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (4/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:35:33.033] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (7/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:35:33.033] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (3/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:35:33.033] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (5/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:35:33.033] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (8/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:35:33.033] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (1/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:35:33.033] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (6/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:35:33.033] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (2/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:35:33.033] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (4/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:35:33.033] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (4/8)] [886] [INFO ] Consumer subtask 3 has no restore state.
[2019-11-28 00:35:33.033] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (5/8)] [886] [INFO ] Consumer subtask 4 has no restore state.
[2019-11-28 00:35:33.033] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (6/8)] [886] [INFO ] Consumer subtask 5 has no restore state.
[2019-11-28 00:35:33.033] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (2/8)] [886] [INFO ] Consumer subtask 1 has no restore state.
[2019-11-28 00:35:33.033] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (1/8)] [886] [INFO ] Consumer subtask 0 has no restore state.
[2019-11-28 00:35:33.033] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (8/8)] [886] [INFO ] Consumer subtask 7 has no restore state.
[2019-11-28 00:35:33.033] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (3/8)] [886] [INFO ] Consumer subtask 2 has no restore state.
[2019-11-28 00:35:33.033] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (7/8)] [886] [INFO ] Consumer subtask 6 has no restore state.
[2019-11-28 00:35:33.033] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (8/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:35:33.033] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (7/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:35:33.033] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (6/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:35:33.033] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (3/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:35:33.033] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (2/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:35:33.033] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (4/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:35:33.033] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (1/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:35:33.033] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (5/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:35:33.033] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (7/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:35:33.033] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (3/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:35:33.033] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (8/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:35:33.033] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (6/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:35:33.033] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (4/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:35:33.033] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (5/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:35:33.033] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (1/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:35:33.033] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (2/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:35:33.033] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (7/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:35:33.033] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (7/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:35:33.033] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (2/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:35:33.033] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (2/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:35:33.033] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (1/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:35:33.033] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (1/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:35:33.033] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (5/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:35:33.033] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (5/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:35:33.033] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (8/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:35:33.033] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (8/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:35:33.033] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (3/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:35:33.033] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (3/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:35:33.033] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (6/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:35:33.033] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (6/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:35:33.033] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (4/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:35:33.033] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (4/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:35:33.033] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map (4/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:35:33.033] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map (3/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:35:33.033] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map (8/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:35:33.033] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map (1/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:35:33.033] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map (2/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:35:33.033] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map (6/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:35:33.033] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map (5/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:35:33.033] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map (7/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:35:33.033] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (8/8)] [651] [INFO ] Consumer subtask 7 initially has no partitions to read from.
[2019-11-28 00:35:33.033] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (7/8)] [651] [INFO ] Consumer subtask 6 initially has no partitions to read from.
[2019-11-28 00:35:33.033] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (6/8)] [651] [INFO ] Consumer subtask 5 initially has no partitions to read from.
[2019-11-28 00:35:33.033] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (4/8)] [651] [INFO ] Consumer subtask 3 initially has no partitions to read from.
[2019-11-28 00:35:33.033] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (1/8)] [651] [INFO ] Consumer subtask 0 initially has no partitions to read from.
[2019-11-28 00:35:33.033] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (2/8)] [651] [INFO ] Consumer subtask 1 initially has no partitions to read from.
[2019-11-28 00:35:33.033] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (3/8)] [651] [INFO ] Consumer subtask 2 initially has no partitions to read from.
[2019-11-28 00:35:33.033] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (5/8)] [645] [INFO ] Consumer subtask 4 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='ota', partition=0}]
[2019-11-28 00:35:33.033] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-8] [688] [INFO ] Consumer subtask 3 creating fetcher with offsets {}.
[2019-11-28 00:35:33.033] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-12] [688] [INFO ] Consumer subtask 5 creating fetcher with offsets {}.
[2019-11-28 00:35:33.033] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-9] [688] [INFO ] Consumer subtask 2 creating fetcher with offsets {}.
[2019-11-28 00:35:33.033] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-11] [688] [INFO ] Consumer subtask 0 creating fetcher with offsets {}.
[2019-11-28 00:35:33.033] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-13] [688] [INFO ] Consumer subtask 6 creating fetcher with offsets {}.
[2019-11-28 00:35:33.033] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-14] [688] [INFO ] Consumer subtask 7 creating fetcher with offsets {}.
[2019-11-28 00:35:33.033] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-10] [688] [INFO ] Consumer subtask 4 creating fetcher with offsets {KafkaTopicPartition{topic='ota', partition=0}=-915623761773}.
[2019-11-28 00:35:33.033] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-7] [688] [INFO ] Consumer subtask 1 creating fetcher with offsets {}.
[2019-11-28 00:35:33.033] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (4/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:35:33.033] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (2/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:35:33.033] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (7/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:35:33.033] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (5/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:35:33.033] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (8/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:35:33.033] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (1/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:35:33.033] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (3/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:35:33.033] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (6/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:35:33.033] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (1/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:35:33.033] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (1/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:35:33.033] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (1/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:35:33.033] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (7/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:35:33.033] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (7/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:35:33.033] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (5/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:35:33.033] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (7/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:35:33.033] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (6/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:35:33.033] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (4/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:35:33.033] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (4/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:35:33.033] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (3/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:35:33.033] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (4/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:35:33.033] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (6/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:35:33.033] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (2/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:35:33.033] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (6/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:35:33.033] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (8/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:35:33.033] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (5/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:35:33.033] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (5/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:35:33.033] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (8/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:35:33.033] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (8/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:35:33.033] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (2/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:35:33.033] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (2/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:35:33.033] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (3/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:35:33.033] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (3/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:35:33.033] [org.apache.kafka.clients.consumer.KafkaConsumer] [Kafka Fetcher for Source: Custom Source -> Map (5/8)] [1090] [INFO ] [Consumer clientId=consumer-12, groupId=test] Subscribed to partition(s): ota-0
[2019-11-28 00:35:33.033] [org.apache.kafka.clients.Metadata] [Kafka Fetcher for Source: Custom Source -> Map (5/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:35:33.033] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler] [Kafka Fetcher for Source: Custom Source -> Map (5/8)] [675] [INFO ] [Consumer clientId=consumer-12, groupId=test] Discovered group coordinator 192.168.1.14:9092 (id: 2147483647 rack: null)
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (5/8)] [960] [INFO ] Source: Custom Source -> Map (5/8) (429d2e3bab85d7adf60f126d4616bd82) switched from RUNNING to FAILED.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException: No content to map due to end-of-input
 at [Source: (byte[])""; line: 1, column: 0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:212) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.performDefaultAction(SourceStreamTask.java:132) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:298) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:403) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) [flink-runtime_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) [flink-runtime_2.11-1.9.0.jar:1.9.0]
	at java.lang.Thread.run(Thread.java:748) [na:1.8.0_131]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException: No content to map due to end-of-input
 at [Source: (byte[])""; line: 1, column: 0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException.from(MismatchedInputException.java:59) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:4145) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4000) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:202) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (5/8)] [804] [INFO ] Freeing task resources for Source: Custom Source -> Map (5/8) (429d2e3bab85d7adf60f126d4616bd82).
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (5/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map (5/8) (429d2e3bab85d7adf60f126d4616bd82) [FAILED]
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [1438] [INFO ] Un-registering task and sending final execution state FAILED to JobManager for task Source: Custom Source -> Map 429d2e3bab85d7adf60f126d4616bd82.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1493] [INFO ] Source: Custom Source -> Map (5/8) (429d2e3bab85d7adf60f126d4616bd82) switched from RUNNING to FAILED.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException: No content to map due to end-of-input
 at [Source: (byte[])""; line: 1, column: 0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:212) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.performDefaultAction(SourceStreamTask.java:132) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:298) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:403) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_131]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException: No content to map due to end-of-input
 at [Source: (byte[])""; line: 1, column: 0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException.from(MismatchedInputException.java:59) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:4145) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4000) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:202) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-4] [1324] [INFO ] Job Flink Streaming Job (77edbd2969d906323b1c8d0a587fc981) switched from state RUNNING to FAILING.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException: No content to map due to end-of-input
 at [Source: (byte[])""; line: 1, column: 0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:212) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.performDefaultAction(SourceStreamTask.java:132) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:298) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:403) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_131]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException: No content to map due to end-of-input
 at [Source: (byte[])""; line: 1, column: 0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException.from(MismatchedInputException.java:59) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:4145) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4000) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:202) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map (1/8) (0d69998bef3c5efa9bfdde62fcc2a26f) switched from RUNNING to CANCELING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-5] [982] [INFO ] Attempting to cancel task Source: Custom Source -> Map (1/8) (0d69998bef3c5efa9bfdde62fcc2a26f).
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-5] [958] [INFO ] Source: Custom Source -> Map (1/8) (0d69998bef3c5efa9bfdde62fcc2a26f) switched from RUNNING to CANCELING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-5] [1031] [INFO ] Triggering cancellation of task code Source: Custom Source -> Map (1/8) (0d69998bef3c5efa9bfdde62fcc2a26f).
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map (2/8) (dcec4b2da911fc566109b7ba0eca5874) switched from RUNNING to CANCELING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map (3/8) (c5fda8305e3b546ad0353bbfdc7a90ca) switched from RUNNING to CANCELING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map (4/8) (c5762d6aa521c600a12d946a04627d97) switched from RUNNING to CANCELING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-5] [982] [INFO ] Attempting to cancel task Source: Custom Source -> Map (2/8) (dcec4b2da911fc566109b7ba0eca5874).
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map (6/8) (f02c5088f2169d8d1a2b32e010c31a85) switched from RUNNING to CANCELING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-5] [958] [INFO ] Source: Custom Source -> Map (2/8) (dcec4b2da911fc566109b7ba0eca5874) switched from RUNNING to CANCELING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map (7/8) (35404502172d4632dd76db1e6918e207) switched from RUNNING to CANCELING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-5] [1031] [INFO ] Triggering cancellation of task code Source: Custom Source -> Map (2/8) (dcec4b2da911fc566109b7ba0eca5874).
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map (8/8) (c1663fa88c8002d9d645eef110422a29) switched from RUNNING to CANCELING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-5] [982] [INFO ] Attempting to cancel task Source: Custom Source -> Map (3/8) (c5fda8305e3b546ad0353bbfdc7a90ca).
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (1/8)] [958] [INFO ] Source: Custom Source -> Map (1/8) (0d69998bef3c5efa9bfdde62fcc2a26f) switched from CANCELING to CANCELED.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-5] [958] [INFO ] Source: Custom Source -> Map (3/8) (c5fda8305e3b546ad0353bbfdc7a90ca) switched from RUNNING to CANCELING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (1/8)] [804] [INFO ] Freeing task resources for Source: Custom Source -> Map (1/8) (0d69998bef3c5efa9bfdde62fcc2a26f).
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-5] [1031] [INFO ] Triggering cancellation of task code Source: Custom Source -> Map (3/8) (c5fda8305e3b546ad0353bbfdc7a90ca).
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (1/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map (1/8) (0d69998bef3c5efa9bfdde62fcc2a26f) [CANCELED]
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-5] [982] [INFO ] Attempting to cancel task Source: Custom Source -> Map (4/8) (c5762d6aa521c600a12d946a04627d97).
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (2/8)] [958] [INFO ] Source: Custom Source -> Map (2/8) (dcec4b2da911fc566109b7ba0eca5874) switched from CANCELING to CANCELED.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-5] [958] [INFO ] Source: Custom Source -> Map (4/8) (c5762d6aa521c600a12d946a04627d97) switched from RUNNING to CANCELING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (2/8)] [804] [INFO ] Freeing task resources for Source: Custom Source -> Map (2/8) (dcec4b2da911fc566109b7ba0eca5874).
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-5] [1031] [INFO ] Triggering cancellation of task code Source: Custom Source -> Map (4/8) (c5762d6aa521c600a12d946a04627d97).
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (2/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map (2/8) (dcec4b2da911fc566109b7ba0eca5874) [CANCELED]
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-5] [982] [INFO ] Attempting to cancel task Source: Custom Source -> Map (6/8) (f02c5088f2169d8d1a2b32e010c31a85).
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-5] [958] [INFO ] Source: Custom Source -> Map (6/8) (f02c5088f2169d8d1a2b32e010c31a85) switched from RUNNING to CANCELING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-5] [1031] [INFO ] Triggering cancellation of task code Source: Custom Source -> Map (6/8) (f02c5088f2169d8d1a2b32e010c31a85).
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (3/8)] [958] [INFO ] Source: Custom Source -> Map (3/8) (c5fda8305e3b546ad0353bbfdc7a90ca) switched from CANCELING to CANCELED.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (3/8)] [804] [INFO ] Freeing task resources for Source: Custom Source -> Map (3/8) (c5fda8305e3b546ad0353bbfdc7a90ca).
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (3/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map (3/8) (c5fda8305e3b546ad0353bbfdc7a90ca) [CANCELED]
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-5] [982] [INFO ] Attempting to cancel task Source: Custom Source -> Map (7/8) (35404502172d4632dd76db1e6918e207).
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-5] [958] [INFO ] Source: Custom Source -> Map (7/8) (35404502172d4632dd76db1e6918e207) switched from RUNNING to CANCELING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-5] [1031] [INFO ] Triggering cancellation of task code Source: Custom Source -> Map (7/8) (35404502172d4632dd76db1e6918e207).
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-5] [982] [INFO ] Attempting to cancel task Source: Custom Source -> Map (8/8) (c1663fa88c8002d9d645eef110422a29).
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-5] [958] [INFO ] Source: Custom Source -> Map (8/8) (c1663fa88c8002d9d645eef110422a29) switched from RUNNING to CANCELING.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-5] [1031] [INFO ] Triggering cancellation of task code Source: Custom Source -> Map (8/8) (c1663fa88c8002d9d645eef110422a29).
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (4/8)] [958] [INFO ] Source: Custom Source -> Map (4/8) (c5762d6aa521c600a12d946a04627d97) switched from CANCELING to CANCELED.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (4/8)] [804] [INFO ] Freeing task resources for Source: Custom Source -> Map (4/8) (c5762d6aa521c600a12d946a04627d97).
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (4/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map (4/8) (c5762d6aa521c600a12d946a04627d97) [CANCELED]
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map 0d69998bef3c5efa9bfdde62fcc2a26f.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map dcec4b2da911fc566109b7ba0eca5874.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map c5fda8305e3b546ad0353bbfdc7a90ca.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Source: Custom Source -> Map (1/8) (0d69998bef3c5efa9bfdde62fcc2a26f) switched from CANCELING to CANCELED.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map c5762d6aa521c600a12d946a04627d97.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Source: Custom Source -> Map (2/8) (dcec4b2da911fc566109b7ba0eca5874) switched from CANCELING to CANCELED.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (7/8)] [958] [INFO ] Source: Custom Source -> Map (7/8) (35404502172d4632dd76db1e6918e207) switched from CANCELING to CANCELED.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (7/8)] [804] [INFO ] Freeing task resources for Source: Custom Source -> Map (7/8) (35404502172d4632dd76db1e6918e207).
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (7/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map (7/8) (35404502172d4632dd76db1e6918e207) [CANCELED]
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map 35404502172d4632dd76db1e6918e207.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Source: Custom Source -> Map (3/8) (c5fda8305e3b546ad0353bbfdc7a90ca) switched from CANCELING to CANCELED.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (8/8)] [958] [INFO ] Source: Custom Source -> Map (8/8) (c1663fa88c8002d9d645eef110422a29) switched from CANCELING to CANCELED.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (8/8)] [804] [INFO ] Freeing task resources for Source: Custom Source -> Map (8/8) (c1663fa88c8002d9d645eef110422a29).
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (6/8)] [958] [INFO ] Source: Custom Source -> Map (6/8) (f02c5088f2169d8d1a2b32e010c31a85) switched from CANCELING to CANCELED.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (8/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map (8/8) (c1663fa88c8002d9d645eef110422a29) [CANCELED]
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (6/8)] [804] [INFO ] Freeing task resources for Source: Custom Source -> Map (6/8) (f02c5088f2169d8d1a2b32e010c31a85).
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map c1663fa88c8002d9d645eef110422a29.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Source: Custom Source -> Map (4/8) (c5762d6aa521c600a12d946a04627d97) switched from CANCELING to CANCELED.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (6/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map (6/8) (f02c5088f2169d8d1a2b32e010c31a85) [CANCELED]
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map f02c5088f2169d8d1a2b32e010c31a85.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Source: Custom Source -> Map (7/8) (35404502172d4632dd76db1e6918e207) switched from CANCELING to CANCELED.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Source: Custom Source -> Map (8/8) (c1663fa88c8002d9d645eef110422a29) switched from CANCELING to CANCELED.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Source: Custom Source -> Map (6/8) (f02c5088f2169d8d1a2b32e010c31a85) switched from CANCELING to CANCELED.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-2] [1446] [INFO ] Try to restart or fail the job Flink Streaming Job (77edbd2969d906323b1c8d0a587fc981) if no longer possible.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-2] [1324] [INFO ] Job Flink Streaming Job (77edbd2969d906323b1c8d0a587fc981) switched from state FAILING to FAILED.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException: No content to map due to end-of-input
 at [Source: (byte[])""; line: 1, column: 0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:212) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.performDefaultAction(SourceStreamTask.java:132) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:298) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:403) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_131]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException: No content to map due to end-of-input
 at [Source: (byte[])""; line: 1, column: 0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException.from(MismatchedInputException.java:59) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:4145) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4000) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:202) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-2] [1472] [INFO ] Could not restart the job Flink Streaming Job (77edbd2969d906323b1c8d0a587fc981) because the restart strategy prevented it.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException: No content to map due to end-of-input
 at [Source: (byte[])""; line: 1, column: 0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:212) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.performDefaultAction(SourceStreamTask.java:132) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:298) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:403) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_131]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException: No content to map due to end-of-input
 at [Source: (byte[])""; line: 1, column: 0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException.from(MismatchedInputException.java:59) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:4145) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4000) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:202) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.checkpoint.CheckpointCoordinator] [flink-akka.actor.default-dispatcher-2] [329] [INFO ] Stopping checkpoint coordinator for job 77edbd2969d906323b1c8d0a587fc981.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore] [flink-akka.actor.default-dispatcher-2] [97] [INFO ] Shutting down
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-4] [775] [INFO ] Job 77edbd2969d906323b1c8d0a587fc981 reached globally terminal state FAILED.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [417] [INFO ] Shutting down Flink Mini Cluster
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.rest.RestServerEndpoint] [main] [290] [INFO ] Shutting down rest endpoint.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [334] [INFO ] Stopping TaskExecutor akka://flink/user/taskmanager_0.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-5] [142] [INFO ] Stop job leader service.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-2] [335] [INFO ] Stopping the JobMaster for job Flink Streaming Job(77edbd2969d906323b1c8d0a587fc981).
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager] [flink-akka.actor.default-dispatcher-5] [213] [INFO ] Shutting down TaskExecutorLocalStateStoresManager.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [228] [INFO ] Suspending SlotPool.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-2] [1010] [INFO ] Close ResourceManager connection 23d154e42db76bc8b82b9c873cf48003: JobManager is shutting down..
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [249] [INFO ] Stopping SlotPool.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-4] [774] [INFO ] Disconnect job manager 8d15461b1b7ec04a52d8a817c2024780@akka://flink/user/jobmanager_1 for job 77edbd2969d906323b1c8d0a587fc981 from the resource manager.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [flink-akka.actor.default-dispatcher-5] [112] [INFO ] FileChannelManager removed spill file directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-io-11c78b2a-9c85-4489-86a6-f9b959ade375
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.io.network.NettyShuffleEnvironment] [flink-akka.actor.default-dispatcher-5] [304] [INFO ] Shutting down the network environment and its components.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.webmonitor.WebMonitorEndpoint] [ForkJoinPool.commonPool-worker-1] [687] [INFO ] Removing cache directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-web-ui
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.rest.RestServerEndpoint] [ForkJoinPool.commonPool-worker-1] [299] [INFO ] Shut down complete.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [flink-akka.actor.default-dispatcher-5] [112] [INFO ] FileChannelManager removed spill file directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-netty-shuffle-03fde738-3f33-4706-8b78-755d93b39ab3
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.KvStateService] [flink-akka.actor.default-dispatcher-5] [119] [INFO ] Shutting down the kvState service and its components.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-5] [142] [INFO ] Stop job leader service.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [499] [INFO ] Shut down cluster because application is in CANCELED, diagnostics DispatcherResourceManagerComponent has been closed..
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.filecache.FileCache] [flink-akka.actor.default-dispatcher-5] [153] [INFO ] removed file cache directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-dist-cache-cc7f68c4-b716-4868-8a53-51911fb747ac
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-3] [220] [INFO ] Stopping dispatcher akka://flink/user/dispatcher.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [359] [INFO ] Stopped TaskExecutor akka://flink/user/taskmanager_0.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-3] [697] [INFO ] Stopping all currently running jobs of dispatcher akka://flink/user/dispatcher.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl] [flink-akka.actor.default-dispatcher-4] [280] [INFO ] Closing the SlotManager.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl] [flink-akka.actor.default-dispatcher-4] [243] [INFO ] Suspending the SlotManager.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.rest.handler.legacy.backpressure.StackTraceSampleCoordinator] [flink-akka.actor.default-dispatcher-3] [220] [INFO ] Shutting down stack trace sample coordinator.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-3] [229] [INFO ] Stopped dispatcher akka://flink/user/dispatcher.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [flink-akka.actor.default-dispatcher-3] [335] [INFO ] Stopping Akka RPC service.
[2019-11-28 00:35:33.033] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-2] [83] [INFO ] Shutting down remote daemon.
[2019-11-28 00:35:33.033] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-2] [83] [INFO ] Remote daemon shut down; proceeding with flushing remote transports.
[2019-11-28 00:35:33.033] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-2] [83] [INFO ] Remoting shut down.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [flink-metrics-2] [335] [INFO ] Stopping Akka RPC service.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [flink-metrics-2] [354] [INFO ] Stopped Akka RPC service.
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.blob.AbstractBlobCache] [flink-akka.actor.default-dispatcher-3] [247] [INFO ] Shutting down BLOB cache
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.blob.AbstractBlobCache] [flink-akka.actor.default-dispatcher-3] [247] [INFO ] Shutting down BLOB cache
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.blob.BlobServer] [flink-akka.actor.default-dispatcher-3] [340] [INFO ] Stopped BLOB server at 0.0.0.0:52714
[2019-11-28 00:35:33.033] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [flink-akka.actor.default-dispatcher-3] [354] [INFO ] Stopped Akka RPC service.
[2019-11-28 00:39:15.015] [org.apache.flink.api.java.typeutils.TypeExtractor] [main] [1815] [INFO ] class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a getter for field _children
[2019-11-28 00:39:15.015] [org.apache.flink.api.java.typeutils.TypeExtractor] [main] [1818] [INFO ] class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a setter for field _children
[2019-11-28 00:39:15.015] [org.apache.flink.api.java.typeutils.TypeExtractor] [main] [1857] [INFO ] Class class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:39:16.016] [org.apache.flink.streaming.api.environment.LocalStreamEnvironment] [main] [108] [INFO ] Running job on local embedded Flink mini cluster
[2019-11-28 00:39:16.016] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [254] [INFO ] Starting Flink Mini Cluster
[2019-11-28 00:39:16.016] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [263] [INFO ] Starting Metrics Registry
[2019-11-28 00:39:16.016] [org.apache.flink.runtime.metrics.MetricRegistryImpl] [main] [114] [INFO ] No metrics reporter configured, no metrics will be exposed/reported.
[2019-11-28 00:39:16.016] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [267] [INFO ] Starting RPC Service(s)
[2019-11-28 00:39:16.016] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1] [flink-akka.actor.default-dispatcher-2] [92] [INFO ] Slf4jLogger started
[2019-11-28 00:39:16.016] [org.apache.flink.runtime.clusterframework.BootstrapTools] [main] [244] [INFO ] Trying to start actor system at :0
[2019-11-28 00:39:16.016] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1] [flink-metrics-2] [92] [INFO ] Slf4jLogger started
[2019-11-28 00:39:16.016] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-2] [83] [INFO ] Starting remoting
[2019-11-28 00:39:17.017] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-2] [83] [INFO ] Remoting started; listening on addresses :[akka.tcp://flink-metrics@192.168.1.14:52804]
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.clusterframework.BootstrapTools] [main] [256] [INFO ] Actor system started at akka.tcp://flink-metrics@192.168.1.14:52804
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [398] [INFO ] Starting high-availability services
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.blob.BlobServer] [main] [141] [INFO ] Created BLOB server storage directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/blobStore-1c5ef651-1f8d-42c7-b0cf-e0d1b8a0baf9
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.blob.BlobServer] [main] [203] [INFO ] Started BLOB server at 0.0.0.0:52805 - max concurrent requests: 50 - max backlog: 1000
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.blob.AbstractBlobCache] [main] [107] [INFO ] Created BLOB cache storage directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/blobStore-9d52c1b4-8b43-4451-b08e-e77d1b6c282b
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.blob.AbstractBlobCache] [main] [107] [INFO ] Created BLOB cache storage directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/blobStore-b6621f32-3e90-4a13-84cf-1c7ffcbcdcaf
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [480] [INFO ] Starting 1 TaskManger(s)
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.TaskManagerRunner] [main] [351] [INFO ] Starting TaskManager with ResourceID: 901a15e9-3b26-44ad-8bdc-7a60a7224e95
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.TaskManagerServices] [main] [519] [INFO ] Temporary file directory '/var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T': total 233 GB, usable 170 GB (72.96% usable)
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [main] [76] [INFO ] FileChannelManager uses directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-io-948a9283-999f-44d2-bfa3-bc3a4172fb5b for spill files.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [main] [76] [INFO ] FileChannelManager uses directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-netty-shuffle-5b905916-6bb0-41ac-97c1-979d6ccf0b8c for spill files.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.io.network.buffer.NetworkBufferPool] [main] [140] [INFO ] Allocated 202 MB for network buffer pool (number of memory segments: 6472, bytes per segment: 32768).
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.io.network.NettyShuffleEnvironment] [main] [283] [INFO ] Starting the network environment and its components.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.KvStateService] [main] [89] [INFO ] Starting the kvState service and its components.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.TaskManagerServices] [main] [364] [INFO ] Limiting managed memory to 0.7 of the currently free heap space (1267 MB), memory will be allocated lazily.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.TaskManagerConfiguration] [main] [197] [INFO ] Messages have a max timeout of 10000 ms
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-3] [125] [INFO ] Start job leader service.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.filecache.FileCache] [flink-akka.actor.default-dispatcher-3] [107] [INFO ] User file cache uses directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-dist-cache-54a94c4d-977b-4673-b713-c071fe2ceec1
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.rest.RestServerEndpoint] [main] [136] [INFO ] Starting rest endpoint.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.webmonitor.WebMonitorUtils$LogFileLocation] [main] [87] [WARN ] Log file environment variable 'log.file' is not set.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.webmonitor.WebMonitorUtils$LogFileLocation] [main] [93] [WARN ] JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] [main] [114] [INFO ] Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.rest.RestServerEndpoint] [main] [233] [INFO ] Rest endpoint listening at localhost:52806
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [main] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@4a5905d9 @ http://localhost:52806
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.webmonitor.WebMonitorEndpoint] [mini-cluster-io-thread-1] [711] [INFO ] http://localhost:52806 was granted leadership with leaderSessionID=67948532-0afb-48c8-bd1b-d2d82296061c
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [mini-cluster-io-thread-1] [250] [INFO ] Received confirmation of leadership for leader http://localhost:52806 , session=67948532-0afb-48c8-bd1b-d2d82296061c
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-3] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@4a051ce @ akka://flink/user/resourcemanager
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-2] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@1e322d71 @ akka://flink/user/dispatcher
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-2] [885] [INFO ] Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token ea23b5ac-467a-45bb-be57-9dca4a28b1fd
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [363] [INFO ] Flink Mini Cluster started successfully
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [919] [INFO ] ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token 807f63e3e69844702f0183cace194667
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-4] [717] [INFO ] Recovering all persisted jobs.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl] [flink-akka.actor.default-dispatcher-3] [215] [INFO ] Starting the SlotManager.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-4] [250] [INFO ] Received confirmation of leadership for leader akka://flink/user/dispatcher , session=ea23b5ac-467a-45bb-be57-9dca4a28b1fd
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-2] [250] [INFO ] Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=2f0183ca-ce19-4667-807f-63e3e6984470
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [982] [INFO ] Connecting to ResourceManager akka://flink/user/resourcemanager(807f63e3e69844702f0183cace194667).
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-4] [155] [INFO ] Resolved ResourceManager address, beginning registration
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-4] [204] [INFO ] Registration at ResourceManager attempt 1 (timeout=100ms)
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-4] [711] [INFO ] Registering TaskManager with ResourceID 901a15e9-3b26-44ad-8bdc-7a60a7224e95 (akka://flink/user/taskmanager_0) at ResourceManager
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-5] [264] [INFO ] Received JobGraph submission 73cbde45abaa0aa1fb999355b5e3f27c (Flink Streaming Job).
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.TaskExecutorToResourceManagerConnection] [flink-akka.actor.default-dispatcher-4] [100] [INFO ] Successful registration at resource manager akka://flink/user/resourcemanager under registration id c8a1a6085a0ff031fc95809855961449.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-5] [321] [INFO ] Submitting job 73cbde45abaa0aa1fb999355b5e3f27c (Flink Streaming Job).
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [flink-akka.actor.default-dispatcher-4] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-4] [241] [INFO ] Initializing job Flink Streaming Job (73cbde45abaa0aa1fb999355b5e3f27c).
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.scheduler.LegacyScheduler] [flink-akka.actor.default-dispatcher-4] [171] [INFO ] Using restart strategy NoRestartStrategy for Flink Streaming Job (73cbde45abaa0aa1fb999355b5e3f27c).
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-4] [516] [INFO ] Job recovers via failover strategy: full graph restart
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.executiongraph.ExecutionGraphBuilder] [flink-akka.actor.default-dispatcher-4] [204] [INFO ] Running initialization on master for job Flink Streaming Job (73cbde45abaa0aa1fb999355b5e3f27c).
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.executiongraph.ExecutionGraphBuilder] [flink-akka.actor.default-dispatcher-4] [222] [INFO ] Successfully ran initialization on master in 0 ms.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.state.StateBackendLoader] [flink-akka.actor.default-dispatcher-4] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-4] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@1efa6e18 @ akka://flink/user/jobmanager_1
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.jobmaster.JobManagerRunner] [mini-cluster-io-thread-3] [313] [INFO ] JobManager runner for job Flink Streaming Job (73cbde45abaa0aa1fb999355b5e3f27c) was granted leadership with session id 2e6298de-4d69-4e90-9e41-6ca36ceee746 at akka://flink/user/jobmanager_1.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-3] [709] [INFO ] Starting execution of job Flink Streaming Job (73cbde45abaa0aa1fb999355b5e3f27c) under job master id 9e416ca36ceee7462e6298de4d694e90.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-3] [1324] [INFO ] Job Flink Streaming Job (73cbde45abaa0aa1fb999355b5e3f27c) switched from state CREATED to RUNNING.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map (1/8) (bef75a3fdc7693e69e6b7a6ca1a143df) switched from CREATED to SCHEDULED.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-3] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{f49c6a79e088c1df1b9be3450d7720ed}]
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map (2/8) (e65da8095a14411e5cb1c615e03c7df4) switched from CREATED to SCHEDULED.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-3] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{5386e953bc52fb84f9538e1c0af47d36}]
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map (3/8) (643637abf78ce5a6af9c41d0c61298a0) switched from CREATED to SCHEDULED.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-3] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{18d351ac7d29edebd5cfdbfbbee6d178}]
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map (4/8) (b916a8c8a817977bf059426106650bba) switched from CREATED to SCHEDULED.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-3] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{3cab004a94c3e37d68963f95a8873572}]
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map (5/8) (42cee5fbb5867b6371a58473d7fa1cec) switched from CREATED to SCHEDULED.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-3] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{e5abf49b4aea77f0fa15176c5880287b}]
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map (6/8) (431e950a2646430dfa1939f463550475) switched from CREATED to SCHEDULED.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-3] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{4bbeb2817a476af52aafe90cd1aab210}]
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map (7/8) (1b54d655bd54e977d1a8189d57c51a2a) switched from CREATED to SCHEDULED.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-3] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{72a93d76d464b3241157778f76535c9c}]
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map (8/8) (5de8079966bd518f79fb3dcf0bcc4ebd) switched from CREATED to SCHEDULED.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-3] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{5a57e8ecb8afdd24b40ad151fad3f687}]
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [jobmanager-future-thread-1] [250] [INFO ] Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=2e6298de-4d69-4e90-9e41-6ca36ceee746
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-3] [940] [INFO ] Connecting to ResourceManager akka://flink/user/resourcemanager(807f63e3e69844702f0183cace194667)
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-3] [155] [INFO ] Resolved ResourceManager address, beginning registration
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-3] [204] [INFO ] Registration at ResourceManager attempt 1 (timeout=100ms)
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-4] [302] [INFO ] Registering job manager 9e416ca36ceee7462e6298de4d694e90@akka://flink/user/jobmanager_1 for job 73cbde45abaa0aa1fb999355b5e3f27c.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-4] [657] [INFO ] Registered job manager 9e416ca36ceee7462e6298de4d694e90@akka://flink/user/jobmanager_1 for job 73cbde45abaa0aa1fb999355b5e3f27c.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-4] [962] [INFO ] JobManager successfully registered at ResourceManager, leader id: 807f63e3e69844702f0183cace194667.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{f49c6a79e088c1df1b9be3450d7720ed}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-5] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 73cbde45abaa0aa1fb999355b5e3f27c with allocation id c2c45eedf94e14a796b6290e6dc6cd0d.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{5386e953bc52fb84f9538e1c0af47d36}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{18d351ac7d29edebd5cfdbfbbee6d178}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{3cab004a94c3e37d68963f95a8873572}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [816] [INFO ] Receive slot request c2c45eedf94e14a796b6290e6dc6cd0d for job 73cbde45abaa0aa1fb999355b5e3f27c from resource manager with leader id 807f63e3e69844702f0183cace194667.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{e5abf49b4aea77f0fa15176c5880287b}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-5] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 73cbde45abaa0aa1fb999355b5e3f27c with allocation id 1a37f9e08b13031f14d3b0f29c7b4581.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{4bbeb2817a476af52aafe90cd1aab210}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [828] [INFO ] Allocated slot for c2c45eedf94e14a796b6290e6dc6cd0d.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-5] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 73cbde45abaa0aa1fb999355b5e3f27c with allocation id 19a99f8da780f056a6b3a6d1316610b0.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-3] [193] [INFO ] Add job 73cbde45abaa0aa1fb999355b5e3f27c for job leader monitoring.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{72a93d76d464b3241157778f76535c9c}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-5] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 73cbde45abaa0aa1fb999355b5e3f27c with allocation id 8a658b41764828d4197ec75334a1543a.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{5a57e8ecb8afdd24b40ad151fad3f687}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-5] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 73cbde45abaa0aa1fb999355b5e3f27c with allocation id 3aff55bc4fe3e8651401cd8ebe341811.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [816] [INFO ] Receive slot request 1a37f9e08b13031f14d3b0f29c7b4581 for job 73cbde45abaa0aa1fb999355b5e3f27c from resource manager with leader id 807f63e3e69844702f0183cace194667.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-5] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 73cbde45abaa0aa1fb999355b5e3f27c with allocation id 0eb60d6ba0e76041f32d6855d067333a.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [828] [INFO ] Allocated slot for 1a37f9e08b13031f14d3b0f29c7b4581.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-7] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 2e6298de-4d69-4e90-9e41-6ca36ceee746.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-3] [193] [INFO ] Add job 73cbde45abaa0aa1fb999355b5e3f27c for job leader monitoring.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-5] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 73cbde45abaa0aa1fb999355b5e3f27c with allocation id 7d051dde61927b6d210fb0cc28f5c0d4.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-8] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 2e6298de-4d69-4e90-9e41-6ca36ceee746.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [816] [INFO ] Receive slot request 19a99f8da780f056a6b3a6d1316610b0 for job 73cbde45abaa0aa1fb999355b5e3f27c from resource manager with leader id 807f63e3e69844702f0183cace194667.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-5] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 73cbde45abaa0aa1fb999355b5e3f27c with allocation id 8417ba7178c405609bd5f63a19616159.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-2] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [828] [INFO ] Allocated slot for 19a99f8da780f056a6b3a6d1316610b0.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-2] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-3] [193] [INFO ] Add job 73cbde45abaa0aa1fb999355b5e3f27c for job leader monitoring.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-2] [204] [INFO ] Registration at JobManager attempt 1 (timeout=100ms)
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-5] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 2e6298de-4d69-4e90-9e41-6ca36ceee746.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [816] [INFO ] Receive slot request 8a658b41764828d4197ec75334a1543a for job 73cbde45abaa0aa1fb999355b5e3f27c from resource manager with leader id 807f63e3e69844702f0183cace194667.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [828] [INFO ] Allocated slot for 8a658b41764828d4197ec75334a1543a.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-3] [193] [INFO ] Add job 73cbde45abaa0aa1fb999355b5e3f27c for job leader monitoring.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-6] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 2e6298de-4d69-4e90-9e41-6ca36ceee746.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [816] [INFO ] Receive slot request 3aff55bc4fe3e8651401cd8ebe341811 for job 73cbde45abaa0aa1fb999355b5e3f27c from resource manager with leader id 807f63e3e69844702f0183cace194667.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [828] [INFO ] Allocated slot for 3aff55bc4fe3e8651401cd8ebe341811.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-3] [193] [INFO ] Add job 73cbde45abaa0aa1fb999355b5e3f27c for job leader monitoring.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-5] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-1] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 2e6298de-4d69-4e90-9e41-6ca36ceee746.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-2] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [816] [INFO ] Receive slot request 0eb60d6ba0e76041f32d6855d067333a for job 73cbde45abaa0aa1fb999355b5e3f27c from resource manager with leader id 807f63e3e69844702f0183cace194667.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [828] [INFO ] Allocated slot for 0eb60d6ba0e76041f32d6855d067333a.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-3] [193] [INFO ] Add job 73cbde45abaa0aa1fb999355b5e3f27c for job leader monitoring.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-2] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-3] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 2e6298de-4d69-4e90-9e41-6ca36ceee746.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [816] [INFO ] Receive slot request 7d051dde61927b6d210fb0cc28f5c0d4 for job 73cbde45abaa0aa1fb999355b5e3f27c from resource manager with leader id 807f63e3e69844702f0183cace194667.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [828] [INFO ] Allocated slot for 7d051dde61927b6d210fb0cc28f5c0d4.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-3] [193] [INFO ] Add job 73cbde45abaa0aa1fb999355b5e3f27c for job leader monitoring.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-5] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-2] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 2e6298de-4d69-4e90-9e41-6ca36ceee746.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [816] [INFO ] Receive slot request 8417ba7178c405609bd5f63a19616159 for job 73cbde45abaa0aa1fb999355b5e3f27c from resource manager with leader id 807f63e3e69844702f0183cace194667.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [828] [INFO ] Allocated slot for 8417ba7178c405609bd5f63a19616159.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-3] [193] [INFO ] Add job 73cbde45abaa0aa1fb999355b5e3f27c for job leader monitoring.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-5] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-4] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 2e6298de-4d69-4e90-9e41-6ca36ceee746.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-3] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-3] [204] [INFO ] Registration at JobManager attempt 1 (timeout=100ms)
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener$JobManagerRegisteredRpcConnection] [flink-akka.actor.default-dispatcher-5] [382] [INFO ] Successful registration at job manager akka://flink/user/jobmanager_1 for job 73cbde45abaa0aa1fb999355b5e3f27c.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [1220] [INFO ] Establish JobManager connection for job 73cbde45abaa0aa1fb999355b5e3f27c.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [1121] [INFO ] Offer reserved slots to the leader of job 73cbde45abaa0aa1fb999355b5e3f27c.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map (1/8) (bef75a3fdc7693e69e6b7a6ca1a143df) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [712] [INFO ] Deploying Source: Custom Source -> Map (1/8) (attempt #0) to 901a15e9-3b26-44ad-8bdc-7a60a7224e95 @ localhost (dataPort=-1)
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map (2/8) (e65da8095a14411e5cb1c615e03c7df4) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [712] [INFO ] Deploying Source: Custom Source -> Map (2/8) (attempt #0) to 901a15e9-3b26-44ad-8bdc-7a60a7224e95 @ localhost (dataPort=-1)
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map (3/8) (643637abf78ce5a6af9c41d0c61298a0) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [712] [INFO ] Deploying Source: Custom Source -> Map (3/8) (attempt #0) to 901a15e9-3b26-44ad-8bdc-7a60a7224e95 @ localhost (dataPort=-1)
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map (4/8) (b916a8c8a817977bf059426106650bba) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [712] [INFO ] Deploying Source: Custom Source -> Map (4/8) (attempt #0) to 901a15e9-3b26-44ad-8bdc-7a60a7224e95 @ localhost (dataPort=-1)
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map (5/8) (42cee5fbb5867b6371a58473d7fa1cec) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [712] [INFO ] Deploying Source: Custom Source -> Map (5/8) (attempt #0) to 901a15e9-3b26-44ad-8bdc-7a60a7224e95 @ localhost (dataPort=-1)
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map (6/8) (431e950a2646430dfa1939f463550475) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [712] [INFO ] Deploying Source: Custom Source -> Map (6/8) (attempt #0) to 901a15e9-3b26-44ad-8bdc-7a60a7224e95 @ localhost (dataPort=-1)
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map (7/8) (1b54d655bd54e977d1a8189d57c51a2a) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [712] [INFO ] Deploying Source: Custom Source -> Map (7/8) (attempt #0) to 901a15e9-3b26-44ad-8bdc-7a60a7224e95 @ localhost (dataPort=-1)
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map (8/8) (5de8079966bd518f79fb3dcf0bcc4ebd) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [712] [INFO ] Deploying Source: Custom Source -> Map (8/8) (attempt #0) to 901a15e9-3b26-44ad-8bdc-7a60a7224e95 @ localhost (dataPort=-1)
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [587] [INFO ] Received task Source: Custom Source -> Map (1/8).
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (1/8)] [958] [INFO ] Source: Custom Source -> Map (1/8) (bef75a3fdc7693e69e6b7a6ca1a143df) switched from CREATED to DEPLOYING.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (1/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (1/8) (bef75a3fdc7693e69e6b7a6ca1a143df) [DEPLOYING]
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (1/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map (1/8) (bef75a3fdc7693e69e6b7a6ca1a143df) [DEPLOYING].
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [587] [INFO ] Received task Source: Custom Source -> Map (2/8).
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (2/8)] [958] [INFO ] Source: Custom Source -> Map (2/8) (e65da8095a14411e5cb1c615e03c7df4) switched from CREATED to DEPLOYING.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (2/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (2/8) (e65da8095a14411e5cb1c615e03c7df4) [DEPLOYING]
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (1/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map (1/8) (bef75a3fdc7693e69e6b7a6ca1a143df) [DEPLOYING].
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (2/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map (2/8) (e65da8095a14411e5cb1c615e03c7df4) [DEPLOYING].
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (2/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map (2/8) (e65da8095a14411e5cb1c615e03c7df4) [DEPLOYING].
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [587] [INFO ] Received task Source: Custom Source -> Map (3/8).
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (3/8)] [958] [INFO ] Source: Custom Source -> Map (3/8) (643637abf78ce5a6af9c41d0c61298a0) switched from CREATED to DEPLOYING.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (3/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (3/8) (643637abf78ce5a6af9c41d0c61298a0) [DEPLOYING]
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (3/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map (3/8) (643637abf78ce5a6af9c41d0c61298a0) [DEPLOYING].
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (3/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map (3/8) (643637abf78ce5a6af9c41d0c61298a0) [DEPLOYING].
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [587] [INFO ] Received task Source: Custom Source -> Map (4/8).
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (4/8)] [958] [INFO ] Source: Custom Source -> Map (4/8) (b916a8c8a817977bf059426106650bba) switched from CREATED to DEPLOYING.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (4/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (4/8) (b916a8c8a817977bf059426106650bba) [DEPLOYING]
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (4/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map (4/8) (b916a8c8a817977bf059426106650bba) [DEPLOYING].
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (4/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map (4/8) (b916a8c8a817977bf059426106650bba) [DEPLOYING].
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [587] [INFO ] Received task Source: Custom Source -> Map (5/8).
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (2/8)] [958] [INFO ] Source: Custom Source -> Map (2/8) (e65da8095a14411e5cb1c615e03c7df4) switched from DEPLOYING to RUNNING.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (1/8)] [958] [INFO ] Source: Custom Source -> Map (1/8) (bef75a3fdc7693e69e6b7a6ca1a143df) switched from DEPLOYING to RUNNING.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (4/8)] [958] [INFO ] Source: Custom Source -> Map (4/8) (b916a8c8a817977bf059426106650bba) switched from DEPLOYING to RUNNING.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (3/8)] [958] [INFO ] Source: Custom Source -> Map (3/8) (643637abf78ce5a6af9c41d0c61298a0) switched from DEPLOYING to RUNNING.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (5/8)] [958] [INFO ] Source: Custom Source -> Map (5/8) (42cee5fbb5867b6371a58473d7fa1cec) switched from CREATED to DEPLOYING.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (5/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (5/8) (42cee5fbb5867b6371a58473d7fa1cec) [DEPLOYING]
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Source: Custom Source -> Map (2/8) (e65da8095a14411e5cb1c615e03c7df4) switched from DEPLOYING to RUNNING.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (5/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map (5/8) (42cee5fbb5867b6371a58473d7fa1cec) [DEPLOYING].
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Source: Custom Source -> Map (1/8) (bef75a3fdc7693e69e6b7a6ca1a143df) switched from DEPLOYING to RUNNING.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Source: Custom Source -> Map (4/8) (b916a8c8a817977bf059426106650bba) switched from DEPLOYING to RUNNING.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map (4/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map (1/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map (3/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map (2/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Source: Custom Source -> Map (3/8) (643637abf78ce5a6af9c41d0c61298a0) switched from DEPLOYING to RUNNING.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (5/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map (5/8) (42cee5fbb5867b6371a58473d7fa1cec) [DEPLOYING].
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (5/8)] [958] [INFO ] Source: Custom Source -> Map (5/8) (42cee5fbb5867b6371a58473d7fa1cec) switched from DEPLOYING to RUNNING.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Source: Custom Source -> Map (5/8) (42cee5fbb5867b6371a58473d7fa1cec) switched from DEPLOYING to RUNNING.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map (5/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [587] [INFO ] Received task Source: Custom Source -> Map (6/8).
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (6/8)] [958] [INFO ] Source: Custom Source -> Map (6/8) (431e950a2646430dfa1939f463550475) switched from CREATED to DEPLOYING.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (6/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (6/8) (431e950a2646430dfa1939f463550475) [DEPLOYING]
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (6/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map (6/8) (431e950a2646430dfa1939f463550475) [DEPLOYING].
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (6/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map (6/8) (431e950a2646430dfa1939f463550475) [DEPLOYING].
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (6/8)] [958] [INFO ] Source: Custom Source -> Map (6/8) (431e950a2646430dfa1939f463550475) switched from DEPLOYING to RUNNING.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map (6/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map (6/8) (431e950a2646430dfa1939f463550475) switched from DEPLOYING to RUNNING.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [587] [INFO ] Received task Source: Custom Source -> Map (7/8).
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (7/8)] [958] [INFO ] Source: Custom Source -> Map (7/8) (1b54d655bd54e977d1a8189d57c51a2a) switched from CREATED to DEPLOYING.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (7/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (7/8) (1b54d655bd54e977d1a8189d57c51a2a) [DEPLOYING]
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (7/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map (7/8) (1b54d655bd54e977d1a8189d57c51a2a) [DEPLOYING].
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (7/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map (7/8) (1b54d655bd54e977d1a8189d57c51a2a) [DEPLOYING].
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (7/8)] [958] [INFO ] Source: Custom Source -> Map (7/8) (1b54d655bd54e977d1a8189d57c51a2a) switched from DEPLOYING to RUNNING.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map (7/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Source: Custom Source -> Map (7/8) (1b54d655bd54e977d1a8189d57c51a2a) switched from DEPLOYING to RUNNING.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [587] [INFO ] Received task Source: Custom Source -> Map (8/8).
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (8/8)] [958] [INFO ] Source: Custom Source -> Map (8/8) (5de8079966bd518f79fb3dcf0bcc4ebd) switched from CREATED to DEPLOYING.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (8/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (8/8) (5de8079966bd518f79fb3dcf0bcc4ebd) [DEPLOYING]
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (8/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map (8/8) (5de8079966bd518f79fb3dcf0bcc4ebd) [DEPLOYING].
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot 1a37f9e08b13031f14d3b0f29c7b4581.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot c2c45eedf94e14a796b6290e6dc6cd0d.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (8/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map (8/8) (5de8079966bd518f79fb3dcf0bcc4ebd) [DEPLOYING].
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot 8417ba7178c405609bd5f63a19616159.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (8/8)] [958] [INFO ] Source: Custom Source -> Map (8/8) (5de8079966bd518f79fb3dcf0bcc4ebd) switched from DEPLOYING to RUNNING.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Source: Custom Source -> Map (8/8) (5de8079966bd518f79fb3dcf0bcc4ebd) switched from DEPLOYING to RUNNING.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map (8/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot 19a99f8da780f056a6b3a6d1316610b0.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot 7d051dde61927b6d210fb0cc28f5c0d4.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot 8a658b41764828d4197ec75334a1543a.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot 0eb60d6ba0e76041f32d6855d067333a.
[2019-11-28 00:39:17.017] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot 3aff55bc4fe3e8651401cd8ebe341811.
[2019-11-28 00:39:17.017] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (3/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:39:17.017] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (2/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:39:17.017] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (4/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:39:17.017] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (6/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:39:17.017] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (1/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:39:17.017] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (8/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:39:17.017] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (7/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:39:17.017] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (5/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:39:17.017] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (3/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:39:17.017] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (2/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:39:17.017] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (4/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:39:17.017] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (6/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:39:17.017] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (1/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:39:17.017] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (8/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:39:17.017] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (7/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:39:17.017] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (5/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:39:17.017] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (5/8)] [886] [INFO ] Consumer subtask 4 has no restore state.
[2019-11-28 00:39:17.017] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (6/8)] [886] [INFO ] Consumer subtask 5 has no restore state.
[2019-11-28 00:39:17.017] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (7/8)] [886] [INFO ] Consumer subtask 6 has no restore state.
[2019-11-28 00:39:17.017] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (1/8)] [886] [INFO ] Consumer subtask 0 has no restore state.
[2019-11-28 00:39:17.017] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (3/8)] [886] [INFO ] Consumer subtask 2 has no restore state.
[2019-11-28 00:39:17.017] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (2/8)] [886] [INFO ] Consumer subtask 1 has no restore state.
[2019-11-28 00:39:17.017] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (4/8)] [886] [INFO ] Consumer subtask 3 has no restore state.
[2019-11-28 00:39:17.017] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (8/8)] [886] [INFO ] Consumer subtask 7 has no restore state.
[2019-11-28 00:39:17.017] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (1/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:39:17.017] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (6/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:39:17.017] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (2/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:39:17.017] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (5/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:39:17.017] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (3/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:39:17.017] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (7/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:39:17.017] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (8/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:39:17.017] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (4/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:39:18.018] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (4/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:39:18.018] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (2/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:39:18.018] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (3/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:39:18.018] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (5/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:39:18.018] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (8/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:39:18.018] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (7/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:39:18.018] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (1/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:39:18.018] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (6/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:39:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (4/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:39:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (4/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:39:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (6/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:39:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (6/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:39:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (1/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:39:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (1/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:39:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (7/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:39:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (7/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:39:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (2/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:39:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (2/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:39:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (3/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:39:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (3/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:39:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (8/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:39:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (8/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:39:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (5/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:39:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (5/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:39:18.018] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map (5/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:39:18.018] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map (7/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:39:18.018] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map (1/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:39:18.018] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map (6/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:39:18.018] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map (3/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:39:18.018] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map (2/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:39:18.018] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map (8/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:39:18.018] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (3/8)] [651] [INFO ] Consumer subtask 2 initially has no partitions to read from.
[2019-11-28 00:39:18.018] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map (4/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:39:18.018] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (6/8)] [651] [INFO ] Consumer subtask 5 initially has no partitions to read from.
[2019-11-28 00:39:18.018] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (8/8)] [651] [INFO ] Consumer subtask 7 initially has no partitions to read from.
[2019-11-28 00:39:18.018] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (7/8)] [651] [INFO ] Consumer subtask 6 initially has no partitions to read from.
[2019-11-28 00:39:18.018] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (1/8)] [651] [INFO ] Consumer subtask 0 initially has no partitions to read from.
[2019-11-28 00:39:18.018] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (2/8)] [651] [INFO ] Consumer subtask 1 initially has no partitions to read from.
[2019-11-28 00:39:18.018] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (5/8)] [610] [INFO ] Consumer subtask 4 will start reading the following 1 partitions from the latest offsets: [KafkaTopicPartition{topic='ota', partition=0}]
[2019-11-28 00:39:18.018] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (4/8)] [651] [INFO ] Consumer subtask 3 initially has no partitions to read from.
[2019-11-28 00:39:18.018] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-14] [688] [INFO ] Consumer subtask 7 creating fetcher with offsets {}.
[2019-11-28 00:39:18.018] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-9] [688] [INFO ] Consumer subtask 3 creating fetcher with offsets {}.
[2019-11-28 00:39:18.018] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-12] [688] [INFO ] Consumer subtask 5 creating fetcher with offsets {}.
[2019-11-28 00:39:18.018] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-8] [688] [INFO ] Consumer subtask 2 creating fetcher with offsets {}.
[2019-11-28 00:39:18.018] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-10] [688] [INFO ] Consumer subtask 1 creating fetcher with offsets {}.
[2019-11-28 00:39:18.018] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-7] [688] [INFO ] Consumer subtask 0 creating fetcher with offsets {}.
[2019-11-28 00:39:18.018] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-11] [688] [INFO ] Consumer subtask 4 creating fetcher with offsets {KafkaTopicPartition{topic='ota', partition=0}=-915623761774}.
[2019-11-28 00:39:18.018] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-13] [688] [INFO ] Consumer subtask 6 creating fetcher with offsets {}.
[2019-11-28 00:39:18.018] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (3/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:39:18.018] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (2/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:39:18.018] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (6/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:39:18.018] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (7/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:39:18.018] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (5/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:39:18.018] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (4/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:39:18.018] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (8/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:39:18.018] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (1/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:39:18.018] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (4/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:39:18.018] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (1/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:39:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (4/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:39:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (4/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:39:18.018] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (5/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:39:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (5/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:39:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (5/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:39:18.018] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (2/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:39:18.018] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (3/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:39:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (1/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:39:18.018] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (7/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:39:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (1/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:39:18.018] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (6/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:39:18.018] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (8/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:39:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (7/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:39:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (7/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:39:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (3/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:39:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (3/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:39:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (2/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:39:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (2/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:39:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (8/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:39:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (8/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:39:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (6/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:39:18.018] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (6/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:39:18.018] [org.apache.kafka.clients.consumer.KafkaConsumer] [Kafka Fetcher for Source: Custom Source -> Map (5/8)] [1090] [INFO ] [Consumer clientId=consumer-13, groupId=test] Subscribed to partition(s): ota-0
[2019-11-28 00:39:18.018] [org.apache.kafka.clients.Metadata] [Kafka Fetcher for Source: Custom Source -> Map (5/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:39:18.018] [org.apache.kafka.clients.consumer.internals.Fetcher] [Kafka Fetcher for Source: Custom Source -> Map (5/8)] [584] [INFO ] [Consumer clientId=consumer-13, groupId=test] Resetting offset for partition ota-0 to offset 4.
[2019-11-28 00:39:23.023] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler] [Kafka Fetcher for Source: Custom Source -> Map (5/8)] [675] [INFO ] [Consumer clientId=consumer-13, groupId=test] Discovered group coordinator 192.168.1.14:9092 (id: 2147483647 rack: null)
[2019-11-28 00:39:28.028] [org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager] [TaskExecutorLocalStateStoresManager shutdown hook] [213] [INFO ] Shutting down TaskExecutorLocalStateStoresManager.
[2019-11-28 00:39:28.028] [org.apache.flink.runtime.blob.AbstractBlobCache] [PermanentBlobCache shutdown hook] [247] [INFO ] Shutting down BLOB cache
[2019-11-28 00:39:28.028] [org.apache.flink.runtime.blob.AbstractBlobCache] [TransientBlobCache shutdown hook] [247] [INFO ] Shutting down BLOB cache
[2019-11-28 00:39:28.028] [org.apache.flink.runtime.blob.BlobServer] [BlobServer shutdown hook] [340] [INFO ] Stopped BLOB server at 0.0.0.0:52805
[2019-11-28 00:39:28.028] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [IOManagerAsync shutdown hook] [112] [INFO ] FileChannelManager removed spill file directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-io-948a9283-999f-44d2-bfa3-bc3a4172fb5b
[2019-11-28 00:39:28.028] [org.apache.flink.runtime.filecache.FileCache] [FileCache shutdown hook] [153] [INFO ] removed file cache directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-dist-cache-54a94c4d-977b-4673-b713-c071fe2ceec1
[2019-11-28 00:39:38.038] [org.apache.flink.api.java.typeutils.TypeExtractor] [main] [1815] [INFO ] class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a getter for field _children
[2019-11-28 00:39:38.038] [org.apache.flink.api.java.typeutils.TypeExtractor] [main] [1818] [INFO ] class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a setter for field _children
[2019-11-28 00:39:38.038] [org.apache.flink.api.java.typeutils.TypeExtractor] [main] [1857] [INFO ] Class class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:39:38.038] [org.apache.flink.streaming.api.environment.LocalStreamEnvironment] [main] [108] [INFO ] Running job on local embedded Flink mini cluster
[2019-11-28 00:39:39.039] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [254] [INFO ] Starting Flink Mini Cluster
[2019-11-28 00:39:39.039] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [263] [INFO ] Starting Metrics Registry
[2019-11-28 00:39:39.039] [org.apache.flink.runtime.metrics.MetricRegistryImpl] [main] [114] [INFO ] No metrics reporter configured, no metrics will be exposed/reported.
[2019-11-28 00:39:39.039] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [267] [INFO ] Starting RPC Service(s)
[2019-11-28 00:39:39.039] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1] [flink-akka.actor.default-dispatcher-3] [92] [INFO ] Slf4jLogger started
[2019-11-28 00:39:39.039] [org.apache.flink.runtime.clusterframework.BootstrapTools] [main] [244] [INFO ] Trying to start actor system at :0
[2019-11-28 00:39:39.039] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1] [flink-metrics-2] [92] [INFO ] Slf4jLogger started
[2019-11-28 00:39:39.039] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-2] [83] [INFO ] Starting remoting
[2019-11-28 00:39:39.039] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-2] [83] [INFO ] Remoting started; listening on addresses :[akka.tcp://flink-metrics@192.168.1.14:52826]
[2019-11-28 00:39:39.039] [org.apache.flink.runtime.clusterframework.BootstrapTools] [main] [256] [INFO ] Actor system started at akka.tcp://flink-metrics@192.168.1.14:52826
[2019-11-28 00:39:39.039] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
[2019-11-28 00:39:39.039] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [398] [INFO ] Starting high-availability services
[2019-11-28 00:39:39.039] [org.apache.flink.runtime.blob.BlobServer] [main] [141] [INFO ] Created BLOB server storage directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/blobStore-452b99bd-15d3-43da-9962-01e4ee8711eb
[2019-11-28 00:39:39.039] [org.apache.flink.runtime.blob.BlobServer] [main] [203] [INFO ] Started BLOB server at 0.0.0.0:52827 - max concurrent requests: 50 - max backlog: 1000
[2019-11-28 00:39:39.039] [org.apache.flink.runtime.blob.AbstractBlobCache] [main] [107] [INFO ] Created BLOB cache storage directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/blobStore-649c3348-776f-4f1b-85bb-4d25f3305750
[2019-11-28 00:39:39.039] [org.apache.flink.runtime.blob.AbstractBlobCache] [main] [107] [INFO ] Created BLOB cache storage directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/blobStore-522c92cd-0a5a-4521-ad34-a61a990bdc87
[2019-11-28 00:39:39.039] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [480] [INFO ] Starting 1 TaskManger(s)
[2019-11-28 00:39:39.039] [org.apache.flink.runtime.taskexecutor.TaskManagerRunner] [main] [351] [INFO ] Starting TaskManager with ResourceID: 26e99f52-30bd-4db6-b907-e46e0490cb96
[2019-11-28 00:39:39.039] [org.apache.flink.runtime.taskexecutor.TaskManagerServices] [main] [519] [INFO ] Temporary file directory '/var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T': total 233 GB, usable 170 GB (72.96% usable)
[2019-11-28 00:39:39.039] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [main] [76] [INFO ] FileChannelManager uses directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-io-6c0c7ff6-ae97-4c55-8345-0cdc701e0de3 for spill files.
[2019-11-28 00:39:39.039] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [main] [76] [INFO ] FileChannelManager uses directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-netty-shuffle-46e3a34a-8c87-4ea1-b2e5-9b687bafb96d for spill files.
[2019-11-28 00:39:39.039] [org.apache.flink.runtime.io.network.buffer.NetworkBufferPool] [main] [140] [INFO ] Allocated 202 MB for network buffer pool (number of memory segments: 6472, bytes per segment: 32768).
[2019-11-28 00:39:39.039] [org.apache.flink.runtime.io.network.NettyShuffleEnvironment] [main] [283] [INFO ] Starting the network environment and its components.
[2019-11-28 00:39:39.039] [org.apache.flink.runtime.taskexecutor.KvStateService] [main] [89] [INFO ] Starting the kvState service and its components.
[2019-11-28 00:39:39.039] [org.apache.flink.runtime.taskexecutor.TaskManagerServices] [main] [364] [INFO ] Limiting managed memory to 0.7 of the currently free heap space (1267 MB), memory will be allocated lazily.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.TaskManagerConfiguration] [main] [197] [INFO ] Messages have a max timeout of 10000 ms
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-3] [125] [INFO ] Start job leader service.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.filecache.FileCache] [flink-akka.actor.default-dispatcher-3] [107] [INFO ] User file cache uses directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-dist-cache-3789c6af-9d39-4fa3-9528-dc98c12b43c2
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.rest.RestServerEndpoint] [main] [136] [INFO ] Starting rest endpoint.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.webmonitor.WebMonitorUtils$LogFileLocation] [main] [87] [WARN ] Log file environment variable 'log.file' is not set.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.webmonitor.WebMonitorUtils$LogFileLocation] [main] [93] [WARN ] JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] [main] [114] [INFO ] Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.rest.RestServerEndpoint] [main] [233] [INFO ] Rest endpoint listening at localhost:52828
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [main] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@1e6dad8 @ http://localhost:52828
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.webmonitor.WebMonitorEndpoint] [mini-cluster-io-thread-1] [711] [INFO ] http://localhost:52828 was granted leadership with leaderSessionID=5b9a2790-372e-4d00-aeb4-ae7d7fa5d96b
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [mini-cluster-io-thread-1] [250] [INFO ] Received confirmation of leadership for leader http://localhost:52828 , session=5b9a2790-372e-4d00-aeb4-ae7d7fa5d96b
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-3] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@46a62ba3 @ akka://flink/user/resourcemanager
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-2] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@456f627c @ akka://flink/user/dispatcher
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-2] [885] [INFO ] Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token 9b0cd1f4-6abf-4b68-9838-18df9580c310
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [919] [INFO ] ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token 8de5680d01c8d0d6b121adc921f94324
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [363] [INFO ] Flink Mini Cluster started successfully
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-4] [717] [INFO ] Recovering all persisted jobs.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl] [flink-akka.actor.default-dispatcher-3] [215] [INFO ] Starting the SlotManager.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-4] [250] [INFO ] Received confirmation of leadership for leader akka://flink/user/dispatcher , session=9b0cd1f4-6abf-4b68-9838-18df9580c310
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-4] [250] [INFO ] Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=b121adc9-21f9-4324-8de5-680d01c8d0d6
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [982] [INFO ] Connecting to ResourceManager akka://flink/user/resourcemanager(8de5680d01c8d0d6b121adc921f94324).
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-2] [155] [INFO ] Resolved ResourceManager address, beginning registration
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-2] [204] [INFO ] Registration at ResourceManager attempt 1 (timeout=100ms)
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-4] [711] [INFO ] Registering TaskManager with ResourceID 26e99f52-30bd-4db6-b907-e46e0490cb96 (akka://flink/user/taskmanager_0) at ResourceManager
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-3] [264] [INFO ] Received JobGraph submission 7b0e20ac15c3f095c80069ff796953c1 (Flink Streaming Job).
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutorToResourceManagerConnection] [flink-akka.actor.default-dispatcher-4] [100] [INFO ] Successful registration at resource manager akka://flink/user/resourcemanager under registration id f013273abe478b18bf9d8b91fb2e53d3.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-3] [321] [INFO ] Submitting job 7b0e20ac15c3f095c80069ff796953c1 (Flink Streaming Job).
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [flink-akka.actor.default-dispatcher-4] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-4] [241] [INFO ] Initializing job Flink Streaming Job (7b0e20ac15c3f095c80069ff796953c1).
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.scheduler.LegacyScheduler] [flink-akka.actor.default-dispatcher-4] [171] [INFO ] Using restart strategy NoRestartStrategy for Flink Streaming Job (7b0e20ac15c3f095c80069ff796953c1).
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-4] [516] [INFO ] Job recovers via failover strategy: full graph restart
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.executiongraph.ExecutionGraphBuilder] [flink-akka.actor.default-dispatcher-4] [204] [INFO ] Running initialization on master for job Flink Streaming Job (7b0e20ac15c3f095c80069ff796953c1).
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.executiongraph.ExecutionGraphBuilder] [flink-akka.actor.default-dispatcher-4] [222] [INFO ] Successfully ran initialization on master in 0 ms.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.state.StateBackendLoader] [flink-akka.actor.default-dispatcher-4] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-4] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@38bac7ed @ akka://flink/user/jobmanager_1
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.jobmaster.JobManagerRunner] [mini-cluster-io-thread-3] [313] [INFO ] JobManager runner for job Flink Streaming Job (7b0e20ac15c3f095c80069ff796953c1) was granted leadership with session id 0634d9b6-c3c8-4e82-878a-64ce972b567d at akka://flink/user/jobmanager_1.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-5] [709] [INFO ] Starting execution of job Flink Streaming Job (7b0e20ac15c3f095c80069ff796953c1) under job master id 878a64ce972b567d0634d9b6c3c84e82.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-5] [1324] [INFO ] Job Flink Streaming Job (7b0e20ac15c3f095c80069ff796953c1) switched from state CREATED to RUNNING.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source (1/1) (8302b7b1fb2f23fe3b01e339b96dca54) switched from CREATED to SCHEDULED.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{50974aad2549bf7066a803611ee8ada1}]
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Map (1/8) (e14ea32038800ad08cd9a653bc86ef4e) switched from CREATED to SCHEDULED.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Map (2/8) (6de94421516b7df7f894df08ffadc902) switched from CREATED to SCHEDULED.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Map (3/8) (1969298be4abeaf9e78403d6aab60de0) switched from CREATED to SCHEDULED.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Map (4/8) (759754ab3a0905f2cd58fd000c7f1cd4) switched from CREATED to SCHEDULED.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Map (5/8) (7f9e252e9d3f786ff61d73a1d64fa0cb) switched from CREATED to SCHEDULED.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Map (6/8) (70a690636c7a1a9d7e567e0385496874) switched from CREATED to SCHEDULED.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Map (7/8) (98b517a398c31aa2b4c63d3091dc764a) switched from CREATED to SCHEDULED.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Map (8/8) (2ebb32106c55b64a53313fcae60c8cd2) switched from CREATED to SCHEDULED.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [jobmanager-future-thread-1] [250] [INFO ] Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=0634d9b6-c3c8-4e82-878a-64ce972b567d
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-5] [940] [INFO ] Connecting to ResourceManager akka://flink/user/resourcemanager(8de5680d01c8d0d6b121adc921f94324)
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-5] [155] [INFO ] Resolved ResourceManager address, beginning registration
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-5] [204] [INFO ] Registration at ResourceManager attempt 1 (timeout=100ms)
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-5] [302] [INFO ] Registering job manager 878a64ce972b567d0634d9b6c3c84e82@akka://flink/user/jobmanager_1 for job 7b0e20ac15c3f095c80069ff796953c1.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-4] [657] [INFO ] Registered job manager 878a64ce972b567d0634d9b6c3c84e82@akka://flink/user/jobmanager_1 for job 7b0e20ac15c3f095c80069ff796953c1.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-2] [962] [INFO ] JobManager successfully registered at ResourceManager, leader id: 8de5680d01c8d0d6b121adc921f94324.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [319] [INFO ] Requesting new slot [SlotRequestId{50974aad2549bf7066a803611ee8ada1}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-4] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 7b0e20ac15c3f095c80069ff796953c1 with allocation id 2ad3fd3d39532a3e0fe6d10069ea965b.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request 2ad3fd3d39532a3e0fe6d10069ea965b for job 7b0e20ac15c3f095c80069ff796953c1 from resource manager with leader id 8de5680d01c8d0d6b121adc921f94324.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for 2ad3fd3d39532a3e0fe6d10069ea965b.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-2] [193] [INFO ] Add job 7b0e20ac15c3f095c80069ff796953c1 for job leader monitoring.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-8] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 0634d9b6-c3c8-4e82-878a-64ce972b567d.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-5] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-5] [204] [INFO ] Registration at JobManager attempt 1 (timeout=100ms)
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener$JobManagerRegisteredRpcConnection] [flink-akka.actor.default-dispatcher-5] [382] [INFO ] Successful registration at job manager akka://flink/user/jobmanager_1 for job 7b0e20ac15c3f095c80069ff796953c1.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [1220] [INFO ] Establish JobManager connection for job 7b0e20ac15c3f095c80069ff796953c1.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [1121] [INFO ] Offer reserved slots to the leader of job 7b0e20ac15c3f095c80069ff796953c1.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{6b7473eddd627a40bac36d169b7af121}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-5] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 7b0e20ac15c3f095c80069ff796953c1 with allocation id f7e7649a7a2022c1a0c57b8ef035c6b6.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{e286d9bc01d4275ea5ec44ed32852c90}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [816] [INFO ] Receive slot request f7e7649a7a2022c1a0c57b8ef035c6b6 for job 7b0e20ac15c3f095c80069ff796953c1 from resource manager with leader id 8de5680d01c8d0d6b121adc921f94324.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 7b0e20ac15c3f095c80069ff796953c1 with allocation id a90c71d57ec05739c78d0e7a66409fa6.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [828] [INFO ] Allocated slot for f7e7649a7a2022c1a0c57b8ef035c6b6.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{213ea321facf584c466752c45dd7b8c7}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [1121] [INFO ] Offer reserved slots to the leader of job 7b0e20ac15c3f095c80069ff796953c1.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [816] [INFO ] Receive slot request a90c71d57ec05739c78d0e7a66409fa6 for job 7b0e20ac15c3f095c80069ff796953c1 from resource manager with leader id 8de5680d01c8d0d6b121adc921f94324.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{26921fee0771fb674c6ff02b129d6795}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [828] [INFO ] Allocated slot for a90c71d57ec05739c78d0e7a66409fa6.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 7b0e20ac15c3f095c80069ff796953c1 with allocation id c90c86a3e27f1434eea5f0c9dd2ca819.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [1121] [INFO ] Offer reserved slots to the leader of job 7b0e20ac15c3f095c80069ff796953c1.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [816] [INFO ] Receive slot request c90c86a3e27f1434eea5f0c9dd2ca819 for job 7b0e20ac15c3f095c80069ff796953c1 from resource manager with leader id 8de5680d01c8d0d6b121adc921f94324.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 7b0e20ac15c3f095c80069ff796953c1 with allocation id a0041e8fbedf5be280f8bef15e702b71.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{57107fa3ecab49daf8ea37b0399cf188}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [828] [INFO ] Allocated slot for c90c86a3e27f1434eea5f0c9dd2ca819.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [1121] [INFO ] Offer reserved slots to the leader of job 7b0e20ac15c3f095c80069ff796953c1.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 7b0e20ac15c3f095c80069ff796953c1 with allocation id 2b5d2000d0faab4e879379d173de5f12.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{e48367167542a313b90179e7af1b2d33}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [816] [INFO ] Receive slot request a0041e8fbedf5be280f8bef15e702b71 for job 7b0e20ac15c3f095c80069ff796953c1 from resource manager with leader id 8de5680d01c8d0d6b121adc921f94324.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [828] [INFO ] Allocated slot for a0041e8fbedf5be280f8bef15e702b71.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [1121] [INFO ] Offer reserved slots to the leader of job 7b0e20ac15c3f095c80069ff796953c1.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{c78b5341250f4c6565a961a1c2b564bf}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-2] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 7b0e20ac15c3f095c80069ff796953c1 with allocation id 591b095407475749902b1f33d624b734.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [816] [INFO ] Receive slot request 2b5d2000d0faab4e879379d173de5f12 for job 7b0e20ac15c3f095c80069ff796953c1 from resource manager with leader id 8de5680d01c8d0d6b121adc921f94324.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [828] [INFO ] Allocated slot for 2b5d2000d0faab4e879379d173de5f12.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-2] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 7b0e20ac15c3f095c80069ff796953c1 with allocation id 4436533ac3b0159692ee9989d44de1e7.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [1121] [INFO ] Offer reserved slots to the leader of job 7b0e20ac15c3f095c80069ff796953c1.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [816] [INFO ] Receive slot request 591b095407475749902b1f33d624b734 for job 7b0e20ac15c3f095c80069ff796953c1 from resource manager with leader id 8de5680d01c8d0d6b121adc921f94324.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [828] [INFO ] Allocated slot for 591b095407475749902b1f33d624b734.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [1121] [INFO ] Offer reserved slots to the leader of job 7b0e20ac15c3f095c80069ff796953c1.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [816] [INFO ] Receive slot request 4436533ac3b0159692ee9989d44de1e7 for job 7b0e20ac15c3f095c80069ff796953c1 from resource manager with leader id 8de5680d01c8d0d6b121adc921f94324.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [828] [INFO ] Allocated slot for 4436533ac3b0159692ee9989d44de1e7.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [1121] [INFO ] Offer reserved slots to the leader of job 7b0e20ac15c3f095c80069ff796953c1.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [2ad3fd3d39532a3e0fe6d10069ea965b]. Ignoring.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-5] [237] [INFO ] Activate slot 2ad3fd3d39532a3e0fe6d10069ea965b.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [2ad3fd3d39532a3e0fe6d10069ea965b]. Ignoring.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-5] [237] [INFO ] Activate slot 2ad3fd3d39532a3e0fe6d10069ea965b.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [f7e7649a7a2022c1a0c57b8ef035c6b6]. Ignoring.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-5] [237] [INFO ] Activate slot f7e7649a7a2022c1a0c57b8ef035c6b6.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [a90c71d57ec05739c78d0e7a66409fa6]. Ignoring.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-5] [237] [INFO ] Activate slot 2ad3fd3d39532a3e0fe6d10069ea965b.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [2ad3fd3d39532a3e0fe6d10069ea965b]. Ignoring.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-5] [237] [INFO ] Activate slot f7e7649a7a2022c1a0c57b8ef035c6b6.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [f7e7649a7a2022c1a0c57b8ef035c6b6]. Ignoring.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-5] [237] [INFO ] Activate slot a90c71d57ec05739c78d0e7a66409fa6.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-5] [237] [INFO ] Activate slot a90c71d57ec05739c78d0e7a66409fa6.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [a90c71d57ec05739c78d0e7a66409fa6]. Ignoring.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-5] [237] [INFO ] Activate slot 2ad3fd3d39532a3e0fe6d10069ea965b.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [2ad3fd3d39532a3e0fe6d10069ea965b]. Ignoring.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-5] [237] [INFO ] Activate slot f7e7649a7a2022c1a0c57b8ef035c6b6.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [f7e7649a7a2022c1a0c57b8ef035c6b6]. Ignoring.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-5] [237] [INFO ] Activate slot c90c86a3e27f1434eea5f0c9dd2ca819.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [c90c86a3e27f1434eea5f0c9dd2ca819]. Ignoring.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [a90c71d57ec05739c78d0e7a66409fa6]. Ignoring.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-5] [237] [INFO ] Activate slot a90c71d57ec05739c78d0e7a66409fa6.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [2ad3fd3d39532a3e0fe6d10069ea965b]. Ignoring.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-5] [237] [INFO ] Activate slot 2ad3fd3d39532a3e0fe6d10069ea965b.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [f7e7649a7a2022c1a0c57b8ef035c6b6]. Ignoring.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-5] [237] [INFO ] Activate slot f7e7649a7a2022c1a0c57b8ef035c6b6.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [c90c86a3e27f1434eea5f0c9dd2ca819]. Ignoring.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-5] [237] [INFO ] Activate slot c90c86a3e27f1434eea5f0c9dd2ca819.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [a0041e8fbedf5be280f8bef15e702b71]. Ignoring.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-5] [237] [INFO ] Activate slot a0041e8fbedf5be280f8bef15e702b71.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [a90c71d57ec05739c78d0e7a66409fa6]. Ignoring.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [2ad3fd3d39532a3e0fe6d10069ea965b]. Ignoring.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot a90c71d57ec05739c78d0e7a66409fa6.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [f7e7649a7a2022c1a0c57b8ef035c6b6]. Ignoring.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot 2ad3fd3d39532a3e0fe6d10069ea965b.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [2b5d2000d0faab4e879379d173de5f12]. Ignoring.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot f7e7649a7a2022c1a0c57b8ef035c6b6.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [c90c86a3e27f1434eea5f0c9dd2ca819]. Ignoring.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot c90c86a3e27f1434eea5f0c9dd2ca819.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [a0041e8fbedf5be280f8bef15e702b71]. Ignoring.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot a0041e8fbedf5be280f8bef15e702b71.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [a90c71d57ec05739c78d0e7a66409fa6]. Ignoring.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot 2b5d2000d0faab4e879379d173de5f12.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [2ad3fd3d39532a3e0fe6d10069ea965b]. Ignoring.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot a90c71d57ec05739c78d0e7a66409fa6.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [f7e7649a7a2022c1a0c57b8ef035c6b6]. Ignoring.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot 2ad3fd3d39532a3e0fe6d10069ea965b.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [2b5d2000d0faab4e879379d173de5f12]. Ignoring.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot f7e7649a7a2022c1a0c57b8ef035c6b6.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source (1/1) (8302b7b1fb2f23fe3b01e339b96dca54) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot 2b5d2000d0faab4e879379d173de5f12.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Source: Custom Source (1/1) (attempt #0) to 26e99f52-30bd-4db6-b907-e46e0490cb96 @ localhost (dataPort=-1)
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot 591b095407475749902b1f33d624b734.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot c90c86a3e27f1434eea5f0c9dd2ca819.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot a0041e8fbedf5be280f8bef15e702b71.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Map (1/8) (e14ea32038800ad08cd9a653bc86ef4e) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Map (1/8) (attempt #0) to 26e99f52-30bd-4db6-b907-e46e0490cb96 @ localhost (dataPort=-1)
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Map (2/8) (6de94421516b7df7f894df08ffadc902) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Map (2/8) (attempt #0) to 26e99f52-30bd-4db6-b907-e46e0490cb96 @ localhost (dataPort=-1)
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Map (3/8) (1969298be4abeaf9e78403d6aab60de0) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Map (3/8) (attempt #0) to 26e99f52-30bd-4db6-b907-e46e0490cb96 @ localhost (dataPort=-1)
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Map (4/8) (759754ab3a0905f2cd58fd000c7f1cd4) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Map (4/8) (attempt #0) to 26e99f52-30bd-4db6-b907-e46e0490cb96 @ localhost (dataPort=-1)
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Map (5/8) (7f9e252e9d3f786ff61d73a1d64fa0cb) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Map (5/8) (attempt #0) to 26e99f52-30bd-4db6-b907-e46e0490cb96 @ localhost (dataPort=-1)
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Map (6/8) (70a690636c7a1a9d7e567e0385496874) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Map (6/8) (attempt #0) to 26e99f52-30bd-4db6-b907-e46e0490cb96 @ localhost (dataPort=-1)
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Map (7/8) (98b517a398c31aa2b4c63d3091dc764a) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Map (7/8) (attempt #0) to 26e99f52-30bd-4db6-b907-e46e0490cb96 @ localhost (dataPort=-1)
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Map (8/8) (2ebb32106c55b64a53313fcae60c8cd2) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Map (8/8) (attempt #0) to 26e99f52-30bd-4db6-b907-e46e0490cb96 @ localhost (dataPort=-1)
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [591b095407475749902b1f33d624b734]. Ignoring.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [c90c86a3e27f1434eea5f0c9dd2ca819]. Ignoring.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [a0041e8fbedf5be280f8bef15e702b71]. Ignoring.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [587] [INFO ] Received task Source: Custom Source (1/1).
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source (1/1)] [958] [INFO ] Source: Custom Source (1/1) (8302b7b1fb2f23fe3b01e339b96dca54) switched from CREATED to DEPLOYING.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source (1/1)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source (1/1) (8302b7b1fb2f23fe3b01e339b96dca54) [DEPLOYING]
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source (1/1)] [593] [INFO ] Loading JAR files for task Source: Custom Source (1/1) (8302b7b1fb2f23fe3b01e339b96dca54) [DEPLOYING].
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source (1/1)] [619] [INFO ] Registering task at network: Source: Custom Source (1/1) (8302b7b1fb2f23fe3b01e339b96dca54) [DEPLOYING].
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [587] [INFO ] Received task Map (1/8).
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Map (1/8)] [958] [INFO ] Map (1/8) (e14ea32038800ad08cd9a653bc86ef4e) switched from CREATED to DEPLOYING.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Map (1/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Map (1/8) (e14ea32038800ad08cd9a653bc86ef4e) [DEPLOYING]
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Map (1/8)] [593] [INFO ] Loading JAR files for task Map (1/8) (e14ea32038800ad08cd9a653bc86ef4e) [DEPLOYING].
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Map (1/8)] [619] [INFO ] Registering task at network: Map (1/8) (e14ea32038800ad08cd9a653bc86ef4e) [DEPLOYING].
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [587] [INFO ] Received task Map (2/8).
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Map (2/8)] [958] [INFO ] Map (2/8) (6de94421516b7df7f894df08ffadc902) switched from CREATED to DEPLOYING.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Map (2/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Map (2/8) (6de94421516b7df7f894df08ffadc902) [DEPLOYING]
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Map (2/8)] [593] [INFO ] Loading JAR files for task Map (2/8) (6de94421516b7df7f894df08ffadc902) [DEPLOYING].
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Map (2/8)] [619] [INFO ] Registering task at network: Map (2/8) (6de94421516b7df7f894df08ffadc902) [DEPLOYING].
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [587] [INFO ] Received task Map (3/8).
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Map (3/8)] [958] [INFO ] Map (3/8) (1969298be4abeaf9e78403d6aab60de0) switched from CREATED to DEPLOYING.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Map (3/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Map (3/8) (1969298be4abeaf9e78403d6aab60de0) [DEPLOYING]
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Map (3/8)] [593] [INFO ] Loading JAR files for task Map (3/8) (1969298be4abeaf9e78403d6aab60de0) [DEPLOYING].
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Map (3/8)] [619] [INFO ] Registering task at network: Map (3/8) (1969298be4abeaf9e78403d6aab60de0) [DEPLOYING].
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [587] [INFO ] Received task Map (4/8).
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Map (4/8)] [958] [INFO ] Map (4/8) (759754ab3a0905f2cd58fd000c7f1cd4) switched from CREATED to DEPLOYING.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Map (4/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Map (4/8) (759754ab3a0905f2cd58fd000c7f1cd4) [DEPLOYING]
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Map (4/8)] [593] [INFO ] Loading JAR files for task Map (4/8) (759754ab3a0905f2cd58fd000c7f1cd4) [DEPLOYING].
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Map (2/8)] [958] [INFO ] Map (2/8) (6de94421516b7df7f894df08ffadc902) switched from DEPLOYING to RUNNING.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Map (3/8)] [958] [INFO ] Map (3/8) (1969298be4abeaf9e78403d6aab60de0) switched from DEPLOYING to RUNNING.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Map (1/8)] [958] [INFO ] Map (1/8) (e14ea32038800ad08cd9a653bc86ef4e) switched from DEPLOYING to RUNNING.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Map (4/8)] [619] [INFO ] Registering task at network: Map (4/8) (759754ab3a0905f2cd58fd000c7f1cd4) [DEPLOYING].
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Map (4/8)] [958] [INFO ] Map (4/8) (759754ab3a0905f2cd58fd000c7f1cd4) switched from DEPLOYING to RUNNING.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [587] [INFO ] Received task Map (5/8).
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Map (5/8)] [958] [INFO ] Map (5/8) (7f9e252e9d3f786ff61d73a1d64fa0cb) switched from CREATED to DEPLOYING.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.state.StateBackendLoader] [Map (2/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.state.StateBackendLoader] [Map (3/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.state.StateBackendLoader] [Map (4/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.state.StateBackendLoader] [Map (1/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Map (5/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Map (5/8) (7f9e252e9d3f786ff61d73a1d64fa0cb) [DEPLOYING]
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Map (2/8) (6de94421516b7df7f894df08ffadc902) switched from DEPLOYING to RUNNING.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Map (5/8)] [593] [INFO ] Loading JAR files for task Map (5/8) (7f9e252e9d3f786ff61d73a1d64fa0cb) [DEPLOYING].
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Map (3/8) (1969298be4abeaf9e78403d6aab60de0) switched from DEPLOYING to RUNNING.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source (1/1)] [958] [INFO ] Source: Custom Source (1/1) (8302b7b1fb2f23fe3b01e339b96dca54) switched from DEPLOYING to RUNNING.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Map (1/8) (e14ea32038800ad08cd9a653bc86ef4e) switched from DEPLOYING to RUNNING.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source (1/1)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Map (5/8)] [619] [INFO ] Registering task at network: Map (5/8) (7f9e252e9d3f786ff61d73a1d64fa0cb) [DEPLOYING].
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [587] [INFO ] Received task Map (6/8).
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Map (5/8)] [958] [INFO ] Map (5/8) (7f9e252e9d3f786ff61d73a1d64fa0cb) switched from DEPLOYING to RUNNING.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Map (4/8) (759754ab3a0905f2cd58fd000c7f1cd4) switched from DEPLOYING to RUNNING.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Map (6/8)] [958] [INFO ] Map (6/8) (70a690636c7a1a9d7e567e0385496874) switched from CREATED to DEPLOYING.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.state.StateBackendLoader] [Map (5/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Map (6/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Map (6/8) (70a690636c7a1a9d7e567e0385496874) [DEPLOYING]
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Map (6/8)] [593] [INFO ] Loading JAR files for task Map (6/8) (70a690636c7a1a9d7e567e0385496874) [DEPLOYING].
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source (1/1) (8302b7b1fb2f23fe3b01e339b96dca54) switched from DEPLOYING to RUNNING.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Map (5/8) (7f9e252e9d3f786ff61d73a1d64fa0cb) switched from DEPLOYING to RUNNING.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Map (6/8)] [619] [INFO ] Registering task at network: Map (6/8) (70a690636c7a1a9d7e567e0385496874) [DEPLOYING].
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [587] [INFO ] Received task Map (7/8).
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Map (6/8)] [958] [INFO ] Map (6/8) (70a690636c7a1a9d7e567e0385496874) switched from DEPLOYING to RUNNING.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Map (7/8)] [958] [INFO ] Map (7/8) (98b517a398c31aa2b4c63d3091dc764a) switched from CREATED to DEPLOYING.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.state.StateBackendLoader] [Map (6/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Map (7/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Map (7/8) (98b517a398c31aa2b4c63d3091dc764a) [DEPLOYING]
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Map (6/8) (70a690636c7a1a9d7e567e0385496874) switched from DEPLOYING to RUNNING.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Map (7/8)] [593] [INFO ] Loading JAR files for task Map (7/8) (98b517a398c31aa2b4c63d3091dc764a) [DEPLOYING].
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Map (7/8)] [619] [INFO ] Registering task at network: Map (7/8) (98b517a398c31aa2b4c63d3091dc764a) [DEPLOYING].
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Map (7/8)] [958] [INFO ] Map (7/8) (98b517a398c31aa2b4c63d3091dc764a) switched from DEPLOYING to RUNNING.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Map (7/8) (98b517a398c31aa2b4c63d3091dc764a) switched from DEPLOYING to RUNNING.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.state.StateBackendLoader] [Map (7/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [587] [INFO ] Received task Map (8/8).
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Map (8/8)] [958] [INFO ] Map (8/8) (2ebb32106c55b64a53313fcae60c8cd2) switched from CREATED to DEPLOYING.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot a90c71d57ec05739c78d0e7a66409fa6.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Map (8/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Map (8/8) (2ebb32106c55b64a53313fcae60c8cd2) [DEPLOYING]
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot 2ad3fd3d39532a3e0fe6d10069ea965b.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Map (8/8)] [593] [INFO ] Loading JAR files for task Map (8/8) (2ebb32106c55b64a53313fcae60c8cd2) [DEPLOYING].
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot f7e7649a7a2022c1a0c57b8ef035c6b6.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot 2b5d2000d0faab4e879379d173de5f12.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot 4436533ac3b0159692ee9989d44de1e7.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot 591b095407475749902b1f33d624b734.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot c90c86a3e27f1434eea5f0c9dd2ca819.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Map (8/8)] [619] [INFO ] Registering task at network: Map (8/8) (2ebb32106c55b64a53313fcae60c8cd2) [DEPLOYING].
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot a0041e8fbedf5be280f8bef15e702b71.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.taskmanager.Task] [Map (8/8)] [958] [INFO ] Map (8/8) (2ebb32106c55b64a53313fcae60c8cd2) switched from DEPLOYING to RUNNING.
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.state.StateBackendLoader] [Map (8/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:39:40.040] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Map (8/8) (2ebb32106c55b64a53313fcae60c8cd2) switched from DEPLOYING to RUNNING.
[2019-11-28 00:39:40.040] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source (1/1)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:39:40.040] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source (1/1)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:39:40.040] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source (1/1)] [886] [INFO ] Consumer subtask 0 has no restore state.
[2019-11-28 00:39:40.040] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source (1/1)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:39:40.040] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source (1/1)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:39:40.040] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source (1/1)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:39:40.040] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source (1/1)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:39:40.040] [org.apache.kafka.clients.Metadata] [Source: Custom Source (1/1)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:39:40.040] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source (1/1)] [610] [INFO ] Consumer subtask 0 will start reading the following 1 partitions from the latest offsets: [KafkaTopicPartition{topic='ota', partition=0}]
[2019-11-28 00:39:40.040] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-7] [688] [INFO ] Consumer subtask 0 creating fetcher with offsets {KafkaTopicPartition{topic='ota', partition=0}=-915623761774}.
[2019-11-28 00:39:40.040] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source (1/1)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:39:40.040] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source (1/1)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:39:40.040] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source (1/1)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:39:40.040] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source (1/1)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:39:40.040] [org.apache.kafka.clients.consumer.KafkaConsumer] [Kafka Fetcher for Source: Custom Source (1/1)] [1090] [INFO ] [Consumer clientId=consumer-2, groupId=test] Subscribed to partition(s): ota-0
[2019-11-28 00:39:40.040] [org.apache.kafka.clients.Metadata] [Kafka Fetcher for Source: Custom Source (1/1)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:39:40.040] [org.apache.kafka.clients.consumer.internals.Fetcher] [Kafka Fetcher for Source: Custom Source (1/1)] [584] [INFO ] [Consumer clientId=consumer-2, groupId=test] Resetting offset for partition ota-0 to offset 4.
[2019-11-28 00:39:45.045] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler] [Kafka Fetcher for Source: Custom Source (1/1)] [675] [INFO ] [Consumer clientId=consumer-2, groupId=test] Discovered group coordinator 192.168.1.14:9092 (id: 2147483647 rack: null)
[2019-11-28 00:40:44.044] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source (1/1)] [960] [INFO ] Source: Custom Source (1/1) (8302b7b1fb2f23fe3b01e339b96dca54) switched from RUNNING to FAILED.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unrecognized token 'is': was expecting ('true', 'false' or 'null')
 at [Source: (byte[])"is"; line: 1, column: 5]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:212) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.performDefaultAction(SourceStreamTask.java:132) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:298) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:403) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) [flink-runtime_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) [flink-runtime_2.11-1.9.0.jar:1.9.0]
	at java.lang.Thread.run(Thread.java:748) [na:1.8.0_131]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unrecognized token 'is': was expecting ('true', 'false' or 'null')
 at [Source: (byte[])"is"; line: 1, column: 5]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1804) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:703) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser._reportInvalidToken(UTF8StreamJsonParser.java:3532) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser._handleUnexpectedValue(UTF8StreamJsonParser.java:2627) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser._nextTokenNotInObject(UTF8StreamJsonParser.java:832) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextToken(UTF8StreamJsonParser.java:729) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:4141) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4000) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:202) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
[2019-11-28 00:40:44.044] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source (1/1)] [804] [INFO ] Freeing task resources for Source: Custom Source (1/1) (8302b7b1fb2f23fe3b01e339b96dca54).
[2019-11-28 00:40:44.044] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source (1/1)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Source: Custom Source (1/1) (8302b7b1fb2f23fe3b01e339b96dca54) [FAILED]
[2019-11-28 00:40:44.044] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-14] [1438] [INFO ] Un-registering task and sending final execution state FAILED to JobManager for task Source: Custom Source 8302b7b1fb2f23fe3b01e339b96dca54.
[2019-11-28 00:40:44.044] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-13] [1493] [INFO ] Source: Custom Source (1/1) (8302b7b1fb2f23fe3b01e339b96dca54) switched from RUNNING to FAILED.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unrecognized token 'is': was expecting ('true', 'false' or 'null')
 at [Source: (byte[])"is"; line: 1, column: 5]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:212) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.performDefaultAction(SourceStreamTask.java:132) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:298) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:403) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_131]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unrecognized token 'is': was expecting ('true', 'false' or 'null')
 at [Source: (byte[])"is"; line: 1, column: 5]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1804) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:703) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser._reportInvalidToken(UTF8StreamJsonParser.java:3532) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser._handleUnexpectedValue(UTF8StreamJsonParser.java:2627) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser._nextTokenNotInObject(UTF8StreamJsonParser.java:832) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextToken(UTF8StreamJsonParser.java:729) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:4141) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4000) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:202) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
[2019-11-28 00:40:44.044] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-13] [1324] [INFO ] Job Flink Streaming Job (7b0e20ac15c3f095c80069ff796953c1) switched from state RUNNING to FAILING.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unrecognized token 'is': was expecting ('true', 'false' or 'null')
 at [Source: (byte[])"is"; line: 1, column: 5]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:212) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.performDefaultAction(SourceStreamTask.java:132) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:298) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:403) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_131]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unrecognized token 'is': was expecting ('true', 'false' or 'null')
 at [Source: (byte[])"is"; line: 1, column: 5]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1804) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:703) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser._reportInvalidToken(UTF8StreamJsonParser.java:3532) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser._handleUnexpectedValue(UTF8StreamJsonParser.java:2627) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser._nextTokenNotInObject(UTF8StreamJsonParser.java:832) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextToken(UTF8StreamJsonParser.java:729) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:4141) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4000) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:202) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
[2019-11-28 00:40:44.044] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-13] [1491] [INFO ] Map (1/8) (e14ea32038800ad08cd9a653bc86ef4e) switched from RUNNING to CANCELING.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-14] [982] [INFO ] Attempting to cancel task Map (1/8) (e14ea32038800ad08cd9a653bc86ef4e).
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-14] [958] [INFO ] Map (1/8) (e14ea32038800ad08cd9a653bc86ef4e) switched from RUNNING to CANCELING.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-14] [1031] [INFO ] Triggering cancellation of task code Map (1/8) (e14ea32038800ad08cd9a653bc86ef4e).
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-13] [1491] [INFO ] Map (2/8) (6de94421516b7df7f894df08ffadc902) switched from RUNNING to CANCELING.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [Map (1/8)] [958] [INFO ] Map (1/8) (e14ea32038800ad08cd9a653bc86ef4e) switched from CANCELING to CANCELED.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [Map (1/8)] [804] [INFO ] Freeing task resources for Map (1/8) (e14ea32038800ad08cd9a653bc86ef4e).
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-13] [1491] [INFO ] Map (3/8) (1969298be4abeaf9e78403d6aab60de0) switched from RUNNING to CANCELING.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [Map (1/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Map (1/8) (e14ea32038800ad08cd9a653bc86ef4e) [CANCELED]
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-14] [982] [INFO ] Attempting to cancel task Map (2/8) (6de94421516b7df7f894df08ffadc902).
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-13] [1491] [INFO ] Map (4/8) (759754ab3a0905f2cd58fd000c7f1cd4) switched from RUNNING to CANCELING.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-14] [958] [INFO ] Map (2/8) (6de94421516b7df7f894df08ffadc902) switched from RUNNING to CANCELING.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-13] [1491] [INFO ] Map (5/8) (7f9e252e9d3f786ff61d73a1d64fa0cb) switched from RUNNING to CANCELING.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-14] [1031] [INFO ] Triggering cancellation of task code Map (2/8) (6de94421516b7df7f894df08ffadc902).
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-13] [1491] [INFO ] Map (6/8) (70a690636c7a1a9d7e567e0385496874) switched from RUNNING to CANCELING.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-13] [1491] [INFO ] Map (7/8) (98b517a398c31aa2b4c63d3091dc764a) switched from RUNNING to CANCELING.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [Map (2/8)] [958] [INFO ] Map (2/8) (6de94421516b7df7f894df08ffadc902) switched from CANCELING to CANCELED.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-14] [982] [INFO ] Attempting to cancel task Map (3/8) (1969298be4abeaf9e78403d6aab60de0).
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [Map (2/8)] [804] [INFO ] Freeing task resources for Map (2/8) (6de94421516b7df7f894df08ffadc902).
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-13] [1491] [INFO ] Map (8/8) (2ebb32106c55b64a53313fcae60c8cd2) switched from RUNNING to CANCELING.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-14] [958] [INFO ] Map (3/8) (1969298be4abeaf9e78403d6aab60de0) switched from RUNNING to CANCELING.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [Map (2/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Map (2/8) (6de94421516b7df7f894df08ffadc902) [CANCELED]
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-14] [1031] [INFO ] Triggering cancellation of task code Map (3/8) (1969298be4abeaf9e78403d6aab60de0).
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-14] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Map e14ea32038800ad08cd9a653bc86ef4e.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [Map (3/8)] [958] [INFO ] Map (3/8) (1969298be4abeaf9e78403d6aab60de0) switched from CANCELING to CANCELED.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [Map (3/8)] [804] [INFO ] Freeing task resources for Map (3/8) (1969298be4abeaf9e78403d6aab60de0).
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [Map (3/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Map (3/8) (1969298be4abeaf9e78403d6aab60de0) [CANCELED]
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-14] [982] [INFO ] Attempting to cancel task Map (4/8) (759754ab3a0905f2cd58fd000c7f1cd4).
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-14] [958] [INFO ] Map (4/8) (759754ab3a0905f2cd58fd000c7f1cd4) switched from RUNNING to CANCELING.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-14] [1031] [INFO ] Triggering cancellation of task code Map (4/8) (759754ab3a0905f2cd58fd000c7f1cd4).
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-14] [982] [INFO ] Attempting to cancel task Map (5/8) (7f9e252e9d3f786ff61d73a1d64fa0cb).
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [Map (4/8)] [958] [INFO ] Map (4/8) (759754ab3a0905f2cd58fd000c7f1cd4) switched from CANCELING to CANCELED.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [Map (4/8)] [804] [INFO ] Freeing task resources for Map (4/8) (759754ab3a0905f2cd58fd000c7f1cd4).
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-14] [958] [INFO ] Map (5/8) (7f9e252e9d3f786ff61d73a1d64fa0cb) switched from RUNNING to CANCELING.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [Map (4/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Map (4/8) (759754ab3a0905f2cd58fd000c7f1cd4) [CANCELED]
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-14] [1031] [INFO ] Triggering cancellation of task code Map (5/8) (7f9e252e9d3f786ff61d73a1d64fa0cb).
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-13] [1491] [INFO ] Map (1/8) (e14ea32038800ad08cd9a653bc86ef4e) switched from CANCELING to CANCELED.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-14] [982] [INFO ] Attempting to cancel task Map (6/8) (70a690636c7a1a9d7e567e0385496874).
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [Map (5/8)] [958] [INFO ] Map (5/8) (7f9e252e9d3f786ff61d73a1d64fa0cb) switched from CANCELING to CANCELED.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-14] [958] [INFO ] Map (6/8) (70a690636c7a1a9d7e567e0385496874) switched from RUNNING to CANCELING.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [Map (5/8)] [804] [INFO ] Freeing task resources for Map (5/8) (7f9e252e9d3f786ff61d73a1d64fa0cb).
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-14] [1031] [INFO ] Triggering cancellation of task code Map (6/8) (70a690636c7a1a9d7e567e0385496874).
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [Map (5/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Map (5/8) (7f9e252e9d3f786ff61d73a1d64fa0cb) [CANCELED]
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-14] [982] [INFO ] Attempting to cancel task Map (7/8) (98b517a398c31aa2b4c63d3091dc764a).
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-14] [958] [INFO ] Map (7/8) (98b517a398c31aa2b4c63d3091dc764a) switched from RUNNING to CANCELING.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [Map (6/8)] [958] [INFO ] Map (6/8) (70a690636c7a1a9d7e567e0385496874) switched from CANCELING to CANCELED.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-14] [1031] [INFO ] Triggering cancellation of task code Map (7/8) (98b517a398c31aa2b4c63d3091dc764a).
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [Map (6/8)] [804] [INFO ] Freeing task resources for Map (6/8) (70a690636c7a1a9d7e567e0385496874).
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [Map (6/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Map (6/8) (70a690636c7a1a9d7e567e0385496874) [CANCELED]
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [Map (7/8)] [958] [INFO ] Map (7/8) (98b517a398c31aa2b4c63d3091dc764a) switched from CANCELING to CANCELED.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-14] [982] [INFO ] Attempting to cancel task Map (8/8) (2ebb32106c55b64a53313fcae60c8cd2).
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [Map (7/8)] [804] [INFO ] Freeing task resources for Map (7/8) (98b517a398c31aa2b4c63d3091dc764a).
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-14] [958] [INFO ] Map (8/8) (2ebb32106c55b64a53313fcae60c8cd2) switched from RUNNING to CANCELING.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [Map (7/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Map (7/8) (98b517a398c31aa2b4c63d3091dc764a) [CANCELED]
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-14] [1031] [INFO ] Triggering cancellation of task code Map (8/8) (2ebb32106c55b64a53313fcae60c8cd2).
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [Map (8/8)] [958] [INFO ] Map (8/8) (2ebb32106c55b64a53313fcae60c8cd2) switched from CANCELING to CANCELED.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-14] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Map 6de94421516b7df7f894df08ffadc902.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [Map (8/8)] [804] [INFO ] Freeing task resources for Map (8/8) (2ebb32106c55b64a53313fcae60c8cd2).
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-14] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Map 1969298be4abeaf9e78403d6aab60de0.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-17] [1491] [INFO ] Map (2/8) (6de94421516b7df7f894df08ffadc902) switched from CANCELING to CANCELED.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskmanager.Task] [Map (8/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Map (8/8) (2ebb32106c55b64a53313fcae60c8cd2) [CANCELED]
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-14] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Map 759754ab3a0905f2cd58fd000c7f1cd4.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-13] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Map 7f9e252e9d3f786ff61d73a1d64fa0cb.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-17] [1491] [INFO ] Map (3/8) (1969298be4abeaf9e78403d6aab60de0) switched from CANCELING to CANCELED.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-13] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Map 70a690636c7a1a9d7e567e0385496874.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-17] [1491] [INFO ] Map (4/8) (759754ab3a0905f2cd58fd000c7f1cd4) switched from CANCELING to CANCELED.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-13] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Map 98b517a398c31aa2b4c63d3091dc764a.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-13] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Map 2ebb32106c55b64a53313fcae60c8cd2.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-17] [1491] [INFO ] Map (5/8) (7f9e252e9d3f786ff61d73a1d64fa0cb) switched from CANCELING to CANCELED.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-17] [1491] [INFO ] Map (6/8) (70a690636c7a1a9d7e567e0385496874) switched from CANCELING to CANCELED.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-17] [1491] [INFO ] Map (7/8) (98b517a398c31aa2b4c63d3091dc764a) switched from CANCELING to CANCELED.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-17] [1491] [INFO ] Map (8/8) (2ebb32106c55b64a53313fcae60c8cd2) switched from CANCELING to CANCELED.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-17] [1446] [INFO ] Try to restart or fail the job Flink Streaming Job (7b0e20ac15c3f095c80069ff796953c1) if no longer possible.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-17] [1324] [INFO ] Job Flink Streaming Job (7b0e20ac15c3f095c80069ff796953c1) switched from state FAILING to FAILED.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unrecognized token 'is': was expecting ('true', 'false' or 'null')
 at [Source: (byte[])"is"; line: 1, column: 5]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:212) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.performDefaultAction(SourceStreamTask.java:132) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:298) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:403) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_131]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unrecognized token 'is': was expecting ('true', 'false' or 'null')
 at [Source: (byte[])"is"; line: 1, column: 5]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1804) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:703) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser._reportInvalidToken(UTF8StreamJsonParser.java:3532) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser._handleUnexpectedValue(UTF8StreamJsonParser.java:2627) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser._nextTokenNotInObject(UTF8StreamJsonParser.java:832) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextToken(UTF8StreamJsonParser.java:729) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:4141) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4000) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:202) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-17] [1472] [INFO ] Could not restart the job Flink Streaming Job (7b0e20ac15c3f095c80069ff796953c1) because the restart strategy prevented it.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unrecognized token 'is': was expecting ('true', 'false' or 'null')
 at [Source: (byte[])"is"; line: 1, column: 5]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:212) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.performDefaultAction(SourceStreamTask.java:132) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:298) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:403) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_131]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unrecognized token 'is': was expecting ('true', 'false' or 'null')
 at [Source: (byte[])"is"; line: 1, column: 5]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1804) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:703) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser._reportInvalidToken(UTF8StreamJsonParser.java:3532) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser._handleUnexpectedValue(UTF8StreamJsonParser.java:2627) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser._nextTokenNotInObject(UTF8StreamJsonParser.java:832) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextToken(UTF8StreamJsonParser.java:729) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:4141) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4000) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:202) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.checkpoint.CheckpointCoordinator] [flink-akka.actor.default-dispatcher-17] [329] [INFO ] Stopping checkpoint coordinator for job 7b0e20ac15c3f095c80069ff796953c1.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore] [flink-akka.actor.default-dispatcher-17] [97] [INFO ] Shutting down
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-13] [775] [INFO ] Job 7b0e20ac15c3f095c80069ff796953c1 reached globally terminal state FAILED.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [417] [INFO ] Shutting down Flink Mini Cluster
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-14] [334] [INFO ] Stopping TaskExecutor akka://flink/user/taskmanager_0.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.rest.RestServerEndpoint] [main] [290] [INFO ] Shutting down rest endpoint.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-14] [142] [INFO ] Stop job leader service.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager] [flink-akka.actor.default-dispatcher-14] [213] [INFO ] Shutting down TaskExecutorLocalStateStoresManager.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-17] [335] [INFO ] Stopping the JobMaster for job Flink Streaming Job(7b0e20ac15c3f095c80069ff796953c1).
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-17] [228] [INFO ] Suspending SlotPool.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-17] [1010] [INFO ] Close ResourceManager connection b04f9260a9cc9690a72ce7a9bd90ce09: JobManager is shutting down..
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-17] [249] [INFO ] Stopping SlotPool.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-13] [774] [INFO ] Disconnect job manager 878a64ce972b567d0634d9b6c3c84e82@akka://flink/user/jobmanager_1 for job 7b0e20ac15c3f095c80069ff796953c1 from the resource manager.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [flink-akka.actor.default-dispatcher-14] [112] [INFO ] FileChannelManager removed spill file directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-io-6c0c7ff6-ae97-4c55-8345-0cdc701e0de3
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.io.network.NettyShuffleEnvironment] [flink-akka.actor.default-dispatcher-14] [304] [INFO ] Shutting down the network environment and its components.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.webmonitor.WebMonitorEndpoint] [ForkJoinPool.commonPool-worker-1] [687] [INFO ] Removing cache directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-web-ui
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.rest.RestServerEndpoint] [ForkJoinPool.commonPool-worker-1] [299] [INFO ] Shut down complete.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [flink-akka.actor.default-dispatcher-14] [112] [INFO ] FileChannelManager removed spill file directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-netty-shuffle-46e3a34a-8c87-4ea1-b2e5-9b687bafb96d
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskexecutor.KvStateService] [flink-akka.actor.default-dispatcher-14] [119] [INFO ] Shutting down the kvState service and its components.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-14] [142] [INFO ] Stop job leader service.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.filecache.FileCache] [flink-akka.actor.default-dispatcher-14] [153] [INFO ] removed file cache directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-dist-cache-3789c6af-9d39-4fa3-9528-dc98c12b43c2
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-14] [359] [INFO ] Stopped TaskExecutor akka://flink/user/taskmanager_0.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-13] [499] [INFO ] Shut down cluster because application is in CANCELED, diagnostics DispatcherResourceManagerComponent has been closed..
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-13] [220] [INFO ] Stopping dispatcher akka://flink/user/dispatcher.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl] [flink-akka.actor.default-dispatcher-14] [280] [INFO ] Closing the SlotManager.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-13] [697] [INFO ] Stopping all currently running jobs of dispatcher akka://flink/user/dispatcher.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl] [flink-akka.actor.default-dispatcher-14] [243] [INFO ] Suspending the SlotManager.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.rest.handler.legacy.backpressure.StackTraceSampleCoordinator] [flink-akka.actor.default-dispatcher-13] [220] [INFO ] Shutting down stack trace sample coordinator.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-13] [229] [INFO ] Stopped dispatcher akka://flink/user/dispatcher.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [flink-akka.actor.default-dispatcher-13] [335] [INFO ] Stopping Akka RPC service.
[2019-11-28 00:40:45.045] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-14] [83] [INFO ] Shutting down remote daemon.
[2019-11-28 00:40:45.045] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-14] [83] [INFO ] Remote daemon shut down; proceeding with flushing remote transports.
[2019-11-28 00:40:45.045] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-14] [83] [INFO ] Remoting shut down.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [flink-metrics-14] [335] [INFO ] Stopping Akka RPC service.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [flink-metrics-14] [354] [INFO ] Stopped Akka RPC service.
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.blob.AbstractBlobCache] [flink-akka.actor.default-dispatcher-17] [247] [INFO ] Shutting down BLOB cache
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.blob.AbstractBlobCache] [flink-akka.actor.default-dispatcher-17] [247] [INFO ] Shutting down BLOB cache
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.blob.BlobServer] [flink-akka.actor.default-dispatcher-17] [340] [INFO ] Stopped BLOB server at 0.0.0.0:52827
[2019-11-28 00:40:45.045] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [flink-akka.actor.default-dispatcher-17] [354] [INFO ] Stopped Akka RPC service.
[2019-11-28 00:41:10.010] [org.apache.flink.api.java.typeutils.TypeExtractor] [main] [1815] [INFO ] class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a getter for field _children
[2019-11-28 00:41:10.010] [org.apache.flink.api.java.typeutils.TypeExtractor] [main] [1818] [INFO ] class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a setter for field _children
[2019-11-28 00:41:10.010] [org.apache.flink.api.java.typeutils.TypeExtractor] [main] [1857] [INFO ] Class class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:41:10.010] [org.apache.flink.streaming.api.environment.LocalStreamEnvironment] [main] [108] [INFO ] Running job on local embedded Flink mini cluster
[2019-11-28 00:41:10.010] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [254] [INFO ] Starting Flink Mini Cluster
[2019-11-28 00:41:10.010] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [263] [INFO ] Starting Metrics Registry
[2019-11-28 00:41:10.010] [org.apache.flink.runtime.metrics.MetricRegistryImpl] [main] [114] [INFO ] No metrics reporter configured, no metrics will be exposed/reported.
[2019-11-28 00:41:10.010] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [267] [INFO ] Starting RPC Service(s)
[2019-11-28 00:41:10.010] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1] [flink-akka.actor.default-dispatcher-2] [92] [INFO ] Slf4jLogger started
[2019-11-28 00:41:10.010] [org.apache.flink.runtime.clusterframework.BootstrapTools] [main] [244] [INFO ] Trying to start actor system at :0
[2019-11-28 00:41:10.010] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1] [flink-metrics-2] [92] [INFO ] Slf4jLogger started
[2019-11-28 00:41:10.010] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-2] [83] [INFO ] Starting remoting
[2019-11-28 00:41:10.010] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-2] [83] [INFO ] Remoting started; listening on addresses :[akka.tcp://flink-metrics@192.168.1.14:52853]
[2019-11-28 00:41:10.010] [org.apache.flink.runtime.clusterframework.BootstrapTools] [main] [256] [INFO ] Actor system started at akka.tcp://flink-metrics@192.168.1.14:52853
[2019-11-28 00:41:10.010] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
[2019-11-28 00:41:10.010] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [398] [INFO ] Starting high-availability services
[2019-11-28 00:41:10.010] [org.apache.flink.runtime.blob.BlobServer] [main] [141] [INFO ] Created BLOB server storage directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/blobStore-262f3544-7f4f-47ab-a385-00c6a3d42fdf
[2019-11-28 00:41:10.010] [org.apache.flink.runtime.blob.BlobServer] [main] [203] [INFO ] Started BLOB server at 0.0.0.0:52854 - max concurrent requests: 50 - max backlog: 1000
[2019-11-28 00:41:10.010] [org.apache.flink.runtime.blob.AbstractBlobCache] [main] [107] [INFO ] Created BLOB cache storage directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/blobStore-f6bfabf4-217f-495e-bc95-0f13825410ec
[2019-11-28 00:41:10.010] [org.apache.flink.runtime.blob.AbstractBlobCache] [main] [107] [INFO ] Created BLOB cache storage directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/blobStore-6cc5a14d-a996-45b8-8ca2-22584ea2d583
[2019-11-28 00:41:10.010] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [480] [INFO ] Starting 1 TaskManger(s)
[2019-11-28 00:41:10.010] [org.apache.flink.runtime.taskexecutor.TaskManagerRunner] [main] [351] [INFO ] Starting TaskManager with ResourceID: ae8185a2-886e-4161-b416-f00507028bb9
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.TaskManagerServices] [main] [519] [INFO ] Temporary file directory '/var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T': total 233 GB, usable 170 GB (72.96% usable)
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [main] [76] [INFO ] FileChannelManager uses directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-io-c874900f-7408-44f4-a229-89ebd03452e8 for spill files.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [main] [76] [INFO ] FileChannelManager uses directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-netty-shuffle-8e4cca95-b42e-408e-ab88-58551cd8d52d for spill files.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.io.network.buffer.NetworkBufferPool] [main] [140] [INFO ] Allocated 202 MB for network buffer pool (number of memory segments: 6472, bytes per segment: 32768).
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.io.network.NettyShuffleEnvironment] [main] [283] [INFO ] Starting the network environment and its components.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.KvStateService] [main] [89] [INFO ] Starting the kvState service and its components.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.TaskManagerServices] [main] [364] [INFO ] Limiting managed memory to 0.7 of the currently free heap space (1267 MB), memory will be allocated lazily.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.TaskManagerConfiguration] [main] [197] [INFO ] Messages have a max timeout of 10000 ms
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-3] [125] [INFO ] Start job leader service.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.filecache.FileCache] [flink-akka.actor.default-dispatcher-3] [107] [INFO ] User file cache uses directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-dist-cache-d179ce37-fdf9-448c-9e4f-451ad430cce0
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.rest.RestServerEndpoint] [main] [136] [INFO ] Starting rest endpoint.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.webmonitor.WebMonitorUtils$LogFileLocation] [main] [87] [WARN ] Log file environment variable 'log.file' is not set.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.webmonitor.WebMonitorUtils$LogFileLocation] [main] [93] [WARN ] JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] [main] [114] [INFO ] Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.rest.RestServerEndpoint] [main] [233] [INFO ] Rest endpoint listening at localhost:52855
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [main] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@7b3315a5 @ http://localhost:52855
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.webmonitor.WebMonitorEndpoint] [mini-cluster-io-thread-1] [711] [INFO ] http://localhost:52855 was granted leadership with leaderSessionID=6f287cfc-cfb3-4699-9a46-57137e57d6fd
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [mini-cluster-io-thread-1] [250] [INFO ] Received confirmation of leadership for leader http://localhost:52855 , session=6f287cfc-cfb3-4699-9a46-57137e57d6fd
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-2] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@482918a1 @ akka://flink/user/resourcemanager
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-3] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@7be15d59 @ akka://flink/user/dispatcher
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-3] [885] [INFO ] Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token ad06b172-c7ba-46b0-bf63-543d304f9d74
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [363] [INFO ] Flink Mini Cluster started successfully
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-2] [919] [INFO ] ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token 9749ee8c9e15485fee6a644ff80f4f13
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-4] [717] [INFO ] Recovering all persisted jobs.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl] [flink-akka.actor.default-dispatcher-2] [215] [INFO ] Starting the SlotManager.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-3] [250] [INFO ] Received confirmation of leadership for leader akka://flink/user/dispatcher , session=ad06b172-c7ba-46b0-bf63-543d304f9d74
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-4] [250] [INFO ] Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=ee6a644f-f80f-4f13-9749-ee8c9e15485f
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [982] [INFO ] Connecting to ResourceManager akka://flink/user/resourcemanager(9749ee8c9e15485fee6a644ff80f4f13).
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-4] [155] [INFO ] Resolved ResourceManager address, beginning registration
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-4] [204] [INFO ] Registration at ResourceManager attempt 1 (timeout=100ms)
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [711] [INFO ] Registering TaskManager with ResourceID ae8185a2-886e-4161-b416-f00507028bb9 (akka://flink/user/taskmanager_0) at ResourceManager
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-3] [264] [INFO ] Received JobGraph submission a08ee662b4955434ea225e6d889f51db (Flink Streaming Job).
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.TaskExecutorToResourceManagerConnection] [flink-akka.actor.default-dispatcher-4] [100] [INFO ] Successful registration at resource manager akka://flink/user/resourcemanager under registration id dbfd20de48ad002c5d5b5d5fa3a61fbe.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-3] [321] [INFO ] Submitting job a08ee662b4955434ea225e6d889f51db (Flink Streaming Job).
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [flink-akka.actor.default-dispatcher-4] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-4] [241] [INFO ] Initializing job Flink Streaming Job (a08ee662b4955434ea225e6d889f51db).
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.scheduler.LegacyScheduler] [flink-akka.actor.default-dispatcher-4] [171] [INFO ] Using restart strategy NoRestartStrategy for Flink Streaming Job (a08ee662b4955434ea225e6d889f51db).
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-4] [516] [INFO ] Job recovers via failover strategy: full graph restart
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.executiongraph.ExecutionGraphBuilder] [flink-akka.actor.default-dispatcher-4] [204] [INFO ] Running initialization on master for job Flink Streaming Job (a08ee662b4955434ea225e6d889f51db).
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.executiongraph.ExecutionGraphBuilder] [flink-akka.actor.default-dispatcher-4] [222] [INFO ] Successfully ran initialization on master in 0 ms.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.state.StateBackendLoader] [flink-akka.actor.default-dispatcher-4] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-4] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@8180753 @ akka://flink/user/jobmanager_1
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.jobmaster.JobManagerRunner] [mini-cluster-io-thread-3] [313] [INFO ] JobManager runner for job Flink Streaming Job (a08ee662b4955434ea225e6d889f51db) was granted leadership with session id 6984f5d8-aa50-4da3-ae5c-4b3c943ea210 at akka://flink/user/jobmanager_1.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-2] [709] [INFO ] Starting execution of job Flink Streaming Job (a08ee662b4955434ea225e6d889f51db) under job master id ae5c4b3c943ea2106984f5d8aa504da3.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-2] [1324] [INFO ] Job Flink Streaming Job (a08ee662b4955434ea225e6d889f51db) switched from state CREATED to RUNNING.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Source: Custom Source (1/1) (9cd9537acec3a46780aa8a8906b63a3c) switched from CREATED to SCHEDULED.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{9ec195af3e39933222c08c9057e0f093}]
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Map (1/8) (57015bc0c9d457363c061296e85a4c2d) switched from CREATED to SCHEDULED.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Map (2/8) (4923da72f6359ee51002cfa689ad49e7) switched from CREATED to SCHEDULED.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Map (3/8) (690e67f90e3e583240d7ec9d71e8a6e9) switched from CREATED to SCHEDULED.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Map (4/8) (104a0890c0574773dc49f9b2dcc1c6a2) switched from CREATED to SCHEDULED.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Map (5/8) (518b9018e8f611dba82a26659996e158) switched from CREATED to SCHEDULED.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Map (6/8) (0ea5ef2d027806fc913aa6b0d98ad34b) switched from CREATED to SCHEDULED.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Map (7/8) (e3abbd73c2217e8c5ad7b77c876c3a1a) switched from CREATED to SCHEDULED.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Map (8/8) (08ee9536828ece6bb1c7f6576b268464) switched from CREATED to SCHEDULED.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [jobmanager-future-thread-1] [250] [INFO ] Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=6984f5d8-aa50-4da3-ae5c-4b3c943ea210
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-2] [940] [INFO ] Connecting to ResourceManager akka://flink/user/resourcemanager(9749ee8c9e15485fee6a644ff80f4f13)
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-4] [155] [INFO ] Resolved ResourceManager address, beginning registration
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-4] [204] [INFO ] Registration at ResourceManager attempt 1 (timeout=100ms)
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-4] [302] [INFO ] Registering job manager ae5c4b3c943ea2106984f5d8aa504da3@akka://flink/user/jobmanager_1 for job a08ee662b4955434ea225e6d889f51db.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-5] [657] [INFO ] Registered job manager ae5c4b3c943ea2106984f5d8aa504da3@akka://flink/user/jobmanager_1 for job a08ee662b4955434ea225e6d889f51db.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-5] [962] [INFO ] JobManager successfully registered at ResourceManager, leader id: 9749ee8c9e15485fee6a644ff80f4f13.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [319] [INFO ] Requesting new slot [SlotRequestId{9ec195af3e39933222c08c9057e0f093}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-4] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job a08ee662b4955434ea225e6d889f51db with allocation id e55c362db5f174d2946b0892833ff157.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [816] [INFO ] Receive slot request e55c362db5f174d2946b0892833ff157 for job a08ee662b4955434ea225e6d889f51db from resource manager with leader id 9749ee8c9e15485fee6a644ff80f4f13.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [828] [INFO ] Allocated slot for e55c362db5f174d2946b0892833ff157.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-5] [193] [INFO ] Add job a08ee662b4955434ea225e6d889f51db for job leader monitoring.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-7] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 6984f5d8-aa50-4da3-ae5c-4b3c943ea210.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-5] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-5] [204] [INFO ] Registration at JobManager attempt 1 (timeout=100ms)
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener$JobManagerRegisteredRpcConnection] [flink-akka.actor.default-dispatcher-5] [382] [INFO ] Successful registration at job manager akka://flink/user/jobmanager_1 for job a08ee662b4955434ea225e6d889f51db.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [1220] [INFO ] Establish JobManager connection for job a08ee662b4955434ea225e6d889f51db.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [1121] [INFO ] Offer reserved slots to the leader of job a08ee662b4955434ea225e6d889f51db.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{3bc13423214b6a923876eeadce0aa1b2}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-5] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job a08ee662b4955434ea225e6d889f51db with allocation id 6d0e3feb9a8991641c00e38301e6f873.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{9bd0777bc10ea505c71e6800d07c4d6d}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request 6d0e3feb9a8991641c00e38301e6f873 for job a08ee662b4955434ea225e6d889f51db from resource manager with leader id 9749ee8c9e15485fee6a644ff80f4f13.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-5] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job a08ee662b4955434ea225e6d889f51db with allocation id 2fc8ff822fa68b5d4e7604a5987e814a.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for 6d0e3feb9a8991641c00e38301e6f873.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{879f010fb38392e87d61b3df1026560f}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [1121] [INFO ] Offer reserved slots to the leader of job a08ee662b4955434ea225e6d889f51db.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job a08ee662b4955434ea225e6d889f51db with allocation id 3efc349f043b34edded352ebeb6f5427.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{430ee0cb6be62688b0eb15d25f368c25}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request 2fc8ff822fa68b5d4e7604a5987e814a for job a08ee662b4955434ea225e6d889f51db from resource manager with leader id 9749ee8c9e15485fee6a644ff80f4f13.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job a08ee662b4955434ea225e6d889f51db with allocation id bcfd05de43afd619c6aa3ad9a5ffa9ab.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{b9294daaef9e7407957283f5fb5f146f}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for 2fc8ff822fa68b5d4e7604a5987e814a.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-5] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job a08ee662b4955434ea225e6d889f51db with allocation id 05ae99d38e23a3876541e2afe0d30ab4.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [1121] [INFO ] Offer reserved slots to the leader of job a08ee662b4955434ea225e6d889f51db.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{f4f9fcfacf54bdee469cc696a40d054a}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request 3efc349f043b34edded352ebeb6f5427 for job a08ee662b4955434ea225e6d889f51db from resource manager with leader id 9749ee8c9e15485fee6a644ff80f4f13.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-5] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job a08ee662b4955434ea225e6d889f51db with allocation id 5da299cd4c095087cf882185bf56af43.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{af8b94ce7c999bf4ff7f450e4a64485e}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for 3efc349f043b34edded352ebeb6f5427.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [1121] [INFO ] Offer reserved slots to the leader of job a08ee662b4955434ea225e6d889f51db.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-5] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job a08ee662b4955434ea225e6d889f51db with allocation id 9aaaf7c27868c36414178ba8023f69b0.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request bcfd05de43afd619c6aa3ad9a5ffa9ab for job a08ee662b4955434ea225e6d889f51db from resource manager with leader id 9749ee8c9e15485fee6a644ff80f4f13.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for bcfd05de43afd619c6aa3ad9a5ffa9ab.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [1121] [INFO ] Offer reserved slots to the leader of job a08ee662b4955434ea225e6d889f51db.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request 05ae99d38e23a3876541e2afe0d30ab4 for job a08ee662b4955434ea225e6d889f51db from resource manager with leader id 9749ee8c9e15485fee6a644ff80f4f13.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for 05ae99d38e23a3876541e2afe0d30ab4.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [1121] [INFO ] Offer reserved slots to the leader of job a08ee662b4955434ea225e6d889f51db.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request 5da299cd4c095087cf882185bf56af43 for job a08ee662b4955434ea225e6d889f51db from resource manager with leader id 9749ee8c9e15485fee6a644ff80f4f13.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for 5da299cd4c095087cf882185bf56af43.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [1121] [INFO ] Offer reserved slots to the leader of job a08ee662b4955434ea225e6d889f51db.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request 9aaaf7c27868c36414178ba8023f69b0 for job a08ee662b4955434ea225e6d889f51db from resource manager with leader id 9749ee8c9e15485fee6a644ff80f4f13.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for 9aaaf7c27868c36414178ba8023f69b0.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [1121] [INFO ] Offer reserved slots to the leader of job a08ee662b4955434ea225e6d889f51db.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [e55c362db5f174d2946b0892833ff157]. Ignoring.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot e55c362db5f174d2946b0892833ff157.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [6d0e3feb9a8991641c00e38301e6f873]. Ignoring.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 6d0e3feb9a8991641c00e38301e6f873.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [e55c362db5f174d2946b0892833ff157]. Ignoring.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot e55c362db5f174d2946b0892833ff157.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [e55c362db5f174d2946b0892833ff157]. Ignoring.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 6d0e3feb9a8991641c00e38301e6f873.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [6d0e3feb9a8991641c00e38301e6f873]. Ignoring.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 2fc8ff822fa68b5d4e7604a5987e814a.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [2fc8ff822fa68b5d4e7604a5987e814a]. Ignoring.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot e55c362db5f174d2946b0892833ff157.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot e55c362db5f174d2946b0892833ff157.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [e55c362db5f174d2946b0892833ff157]. Ignoring.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 3efc349f043b34edded352ebeb6f5427.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [3efc349f043b34edded352ebeb6f5427]. Ignoring.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 6d0e3feb9a8991641c00e38301e6f873.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [6d0e3feb9a8991641c00e38301e6f873]. Ignoring.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 2fc8ff822fa68b5d4e7604a5987e814a.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [2fc8ff822fa68b5d4e7604a5987e814a]. Ignoring.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [bcfd05de43afd619c6aa3ad9a5ffa9ab]. Ignoring.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot bcfd05de43afd619c6aa3ad9a5ffa9ab.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [e55c362db5f174d2946b0892833ff157]. Ignoring.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot e55c362db5f174d2946b0892833ff157.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [3efc349f043b34edded352ebeb6f5427]. Ignoring.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot 3efc349f043b34edded352ebeb6f5427.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [6d0e3feb9a8991641c00e38301e6f873]. Ignoring.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot 6d0e3feb9a8991641c00e38301e6f873.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [2fc8ff822fa68b5d4e7604a5987e814a]. Ignoring.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot 2fc8ff822fa68b5d4e7604a5987e814a.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [05ae99d38e23a3876541e2afe0d30ab4]. Ignoring.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot 05ae99d38e23a3876541e2afe0d30ab4.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [bcfd05de43afd619c6aa3ad9a5ffa9ab]. Ignoring.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot bcfd05de43afd619c6aa3ad9a5ffa9ab.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [e55c362db5f174d2946b0892833ff157]. Ignoring.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot e55c362db5f174d2946b0892833ff157.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [3efc349f043b34edded352ebeb6f5427]. Ignoring.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot 3efc349f043b34edded352ebeb6f5427.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [2fc8ff822fa68b5d4e7604a5987e814a]. Ignoring.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot 6d0e3feb9a8991641c00e38301e6f873.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [6d0e3feb9a8991641c00e38301e6f873]. Ignoring.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot 2fc8ff822fa68b5d4e7604a5987e814a.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [05ae99d38e23a3876541e2afe0d30ab4]. Ignoring.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot 05ae99d38e23a3876541e2afe0d30ab4.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [bcfd05de43afd619c6aa3ad9a5ffa9ab]. Ignoring.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot bcfd05de43afd619c6aa3ad9a5ffa9ab.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [e55c362db5f174d2946b0892833ff157]. Ignoring.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot e55c362db5f174d2946b0892833ff157.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot 3efc349f043b34edded352ebeb6f5427.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source (1/1) (9cd9537acec3a46780aa8a8906b63a3c) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot 2fc8ff822fa68b5d4e7604a5987e814a.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Source: Custom Source (1/1) (attempt #0) to ae8185a2-886e-4161-b416-f00507028bb9 @ localhost (dataPort=-1)
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot 5da299cd4c095087cf882185bf56af43.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot 6d0e3feb9a8991641c00e38301e6f873.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Map (1/8) (57015bc0c9d457363c061296e85a4c2d) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Map (1/8) (attempt #0) to ae8185a2-886e-4161-b416-f00507028bb9 @ localhost (dataPort=-1)
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Map (2/8) (4923da72f6359ee51002cfa689ad49e7) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Map (2/8) (attempt #0) to ae8185a2-886e-4161-b416-f00507028bb9 @ localhost (dataPort=-1)
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Map (3/8) (690e67f90e3e583240d7ec9d71e8a6e9) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Map (3/8) (attempt #0) to ae8185a2-886e-4161-b416-f00507028bb9 @ localhost (dataPort=-1)
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Map (4/8) (104a0890c0574773dc49f9b2dcc1c6a2) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Map (4/8) (attempt #0) to ae8185a2-886e-4161-b416-f00507028bb9 @ localhost (dataPort=-1)
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Map (5/8) (518b9018e8f611dba82a26659996e158) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Map (5/8) (attempt #0) to ae8185a2-886e-4161-b416-f00507028bb9 @ localhost (dataPort=-1)
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Map (6/8) (0ea5ef2d027806fc913aa6b0d98ad34b) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Map (6/8) (attempt #0) to ae8185a2-886e-4161-b416-f00507028bb9 @ localhost (dataPort=-1)
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Map (7/8) (e3abbd73c2217e8c5ad7b77c876c3a1a) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Map (7/8) (attempt #0) to ae8185a2-886e-4161-b416-f00507028bb9 @ localhost (dataPort=-1)
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Map (8/8) (08ee9536828ece6bb1c7f6576b268464) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Map (8/8) (attempt #0) to ae8185a2-886e-4161-b416-f00507028bb9 @ localhost (dataPort=-1)
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [3efc349f043b34edded352ebeb6f5427]. Ignoring.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [2fc8ff822fa68b5d4e7604a5987e814a]. Ignoring.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [5da299cd4c095087cf882185bf56af43]. Ignoring.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [618] [INFO ] Received repeated offer for slot [6d0e3feb9a8991641c00e38301e6f873]. Ignoring.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [587] [INFO ] Received task Source: Custom Source (1/1).
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source (1/1)] [958] [INFO ] Source: Custom Source (1/1) (9cd9537acec3a46780aa8a8906b63a3c) switched from CREATED to DEPLOYING.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source (1/1)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source (1/1) (9cd9537acec3a46780aa8a8906b63a3c) [DEPLOYING]
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source (1/1)] [593] [INFO ] Loading JAR files for task Source: Custom Source (1/1) (9cd9537acec3a46780aa8a8906b63a3c) [DEPLOYING].
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source (1/1)] [619] [INFO ] Registering task at network: Source: Custom Source (1/1) (9cd9537acec3a46780aa8a8906b63a3c) [DEPLOYING].
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [587] [INFO ] Received task Map (1/8).
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Map (1/8)] [958] [INFO ] Map (1/8) (57015bc0c9d457363c061296e85a4c2d) switched from CREATED to DEPLOYING.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Map (1/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Map (1/8) (57015bc0c9d457363c061296e85a4c2d) [DEPLOYING]
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Map (1/8)] [593] [INFO ] Loading JAR files for task Map (1/8) (57015bc0c9d457363c061296e85a4c2d) [DEPLOYING].
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [587] [INFO ] Received task Map (2/8).
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Map (1/8)] [619] [INFO ] Registering task at network: Map (1/8) (57015bc0c9d457363c061296e85a4c2d) [DEPLOYING].
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Map (2/8)] [958] [INFO ] Map (2/8) (4923da72f6359ee51002cfa689ad49e7) switched from CREATED to DEPLOYING.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Map (2/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Map (2/8) (4923da72f6359ee51002cfa689ad49e7) [DEPLOYING]
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Map (2/8)] [593] [INFO ] Loading JAR files for task Map (2/8) (4923da72f6359ee51002cfa689ad49e7) [DEPLOYING].
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Map (2/8)] [619] [INFO ] Registering task at network: Map (2/8) (4923da72f6359ee51002cfa689ad49e7) [DEPLOYING].
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [587] [INFO ] Received task Map (3/8).
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Map (3/8)] [958] [INFO ] Map (3/8) (690e67f90e3e583240d7ec9d71e8a6e9) switched from CREATED to DEPLOYING.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Map (3/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Map (3/8) (690e67f90e3e583240d7ec9d71e8a6e9) [DEPLOYING]
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Map (3/8)] [593] [INFO ] Loading JAR files for task Map (3/8) (690e67f90e3e583240d7ec9d71e8a6e9) [DEPLOYING].
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Map (3/8)] [619] [INFO ] Registering task at network: Map (3/8) (690e67f90e3e583240d7ec9d71e8a6e9) [DEPLOYING].
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [587] [INFO ] Received task Map (4/8).
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Map (4/8)] [958] [INFO ] Map (4/8) (104a0890c0574773dc49f9b2dcc1c6a2) switched from CREATED to DEPLOYING.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Map (4/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Map (4/8) (104a0890c0574773dc49f9b2dcc1c6a2) [DEPLOYING]
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Map (4/8)] [593] [INFO ] Loading JAR files for task Map (4/8) (104a0890c0574773dc49f9b2dcc1c6a2) [DEPLOYING].
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Map (4/8)] [619] [INFO ] Registering task at network: Map (4/8) (104a0890c0574773dc49f9b2dcc1c6a2) [DEPLOYING].
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [587] [INFO ] Received task Map (5/8).
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Map (5/8)] [958] [INFO ] Map (5/8) (518b9018e8f611dba82a26659996e158) switched from CREATED to DEPLOYING.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Map (5/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Map (5/8) (518b9018e8f611dba82a26659996e158) [DEPLOYING]
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Map (5/8)] [593] [INFO ] Loading JAR files for task Map (5/8) (518b9018e8f611dba82a26659996e158) [DEPLOYING].
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Map (2/8)] [958] [INFO ] Map (2/8) (4923da72f6359ee51002cfa689ad49e7) switched from DEPLOYING to RUNNING.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Map (1/8)] [958] [INFO ] Map (1/8) (57015bc0c9d457363c061296e85a4c2d) switched from DEPLOYING to RUNNING.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Map (4/8)] [958] [INFO ] Map (4/8) (104a0890c0574773dc49f9b2dcc1c6a2) switched from DEPLOYING to RUNNING.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Map (3/8)] [958] [INFO ] Map (3/8) (690e67f90e3e583240d7ec9d71e8a6e9) switched from DEPLOYING to RUNNING.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Map (5/8)] [619] [INFO ] Registering task at network: Map (5/8) (518b9018e8f611dba82a26659996e158) [DEPLOYING].
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Map (5/8)] [958] [INFO ] Map (5/8) (518b9018e8f611dba82a26659996e158) switched from DEPLOYING to RUNNING.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Map (2/8) (4923da72f6359ee51002cfa689ad49e7) switched from DEPLOYING to RUNNING.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.state.StateBackendLoader] [Map (2/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.state.StateBackendLoader] [Map (5/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.state.StateBackendLoader] [Map (3/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.state.StateBackendLoader] [Map (4/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.state.StateBackendLoader] [Map (1/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Map (1/8) (57015bc0c9d457363c061296e85a4c2d) switched from DEPLOYING to RUNNING.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Map (4/8) (104a0890c0574773dc49f9b2dcc1c6a2) switched from DEPLOYING to RUNNING.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Map (3/8) (690e67f90e3e583240d7ec9d71e8a6e9) switched from DEPLOYING to RUNNING.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [587] [INFO ] Received task Map (6/8).
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Map (5/8) (518b9018e8f611dba82a26659996e158) switched from DEPLOYING to RUNNING.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source (1/1)] [958] [INFO ] Source: Custom Source (1/1) (9cd9537acec3a46780aa8a8906b63a3c) switched from DEPLOYING to RUNNING.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Map (6/8)] [958] [INFO ] Map (6/8) (0ea5ef2d027806fc913aa6b0d98ad34b) switched from CREATED to DEPLOYING.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source (1/1)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Source: Custom Source (1/1) (9cd9537acec3a46780aa8a8906b63a3c) switched from DEPLOYING to RUNNING.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Map (6/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Map (6/8) (0ea5ef2d027806fc913aa6b0d98ad34b) [DEPLOYING]
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Map (6/8)] [593] [INFO ] Loading JAR files for task Map (6/8) (0ea5ef2d027806fc913aa6b0d98ad34b) [DEPLOYING].
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Map (6/8)] [619] [INFO ] Registering task at network: Map (6/8) (0ea5ef2d027806fc913aa6b0d98ad34b) [DEPLOYING].
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Map (6/8)] [958] [INFO ] Map (6/8) (0ea5ef2d027806fc913aa6b0d98ad34b) switched from DEPLOYING to RUNNING.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.state.StateBackendLoader] [Map (6/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [587] [INFO ] Received task Map (7/8).
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Map (6/8) (0ea5ef2d027806fc913aa6b0d98ad34b) switched from DEPLOYING to RUNNING.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Map (7/8)] [958] [INFO ] Map (7/8) (e3abbd73c2217e8c5ad7b77c876c3a1a) switched from CREATED to DEPLOYING.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Map (7/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Map (7/8) (e3abbd73c2217e8c5ad7b77c876c3a1a) [DEPLOYING]
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Map (7/8)] [593] [INFO ] Loading JAR files for task Map (7/8) (e3abbd73c2217e8c5ad7b77c876c3a1a) [DEPLOYING].
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Map (7/8)] [619] [INFO ] Registering task at network: Map (7/8) (e3abbd73c2217e8c5ad7b77c876c3a1a) [DEPLOYING].
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Map (7/8)] [958] [INFO ] Map (7/8) (e3abbd73c2217e8c5ad7b77c876c3a1a) switched from DEPLOYING to RUNNING.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.state.StateBackendLoader] [Map (7/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Map (7/8) (e3abbd73c2217e8c5ad7b77c876c3a1a) switched from DEPLOYING to RUNNING.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [587] [INFO ] Received task Map (8/8).
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Map (8/8)] [958] [INFO ] Map (8/8) (08ee9536828ece6bb1c7f6576b268464) switched from CREATED to DEPLOYING.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot 05ae99d38e23a3876541e2afe0d30ab4.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Map (8/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Map (8/8) (08ee9536828ece6bb1c7f6576b268464) [DEPLOYING]
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot bcfd05de43afd619c6aa3ad9a5ffa9ab.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Map (8/8)] [593] [INFO ] Loading JAR files for task Map (8/8) (08ee9536828ece6bb1c7f6576b268464) [DEPLOYING].
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot e55c362db5f174d2946b0892833ff157.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot 9aaaf7c27868c36414178ba8023f69b0.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot 3efc349f043b34edded352ebeb6f5427.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot 2fc8ff822fa68b5d4e7604a5987e814a.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Map (8/8)] [619] [INFO ] Registering task at network: Map (8/8) (08ee9536828ece6bb1c7f6576b268464) [DEPLOYING].
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot 5da299cd4c095087cf882185bf56af43.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskmanager.Task] [Map (8/8)] [958] [INFO ] Map (8/8) (08ee9536828ece6bb1c7f6576b268464) switched from DEPLOYING to RUNNING.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot 6d0e3feb9a8991641c00e38301e6f873.
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.state.StateBackendLoader] [Map (8/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:41:11.011] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Map (8/8) (08ee9536828ece6bb1c7f6576b268464) switched from DEPLOYING to RUNNING.
[2019-11-28 00:41:11.011] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source (1/1)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:41:11.011] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source (1/1)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:41:11.011] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source (1/1)] [886] [INFO ] Consumer subtask 0 has no restore state.
[2019-11-28 00:41:11.011] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source (1/1)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:41:11.011] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source (1/1)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:41:11.011] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source (1/1)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:41:11.011] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source (1/1)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:41:11.011] [org.apache.kafka.clients.Metadata] [Source: Custom Source (1/1)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:41:11.011] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source (1/1)] [610] [INFO ] Consumer subtask 0 will start reading the following 1 partitions from the latest offsets: [KafkaTopicPartition{topic='ota', partition=0}]
[2019-11-28 00:41:11.011] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-7] [688] [INFO ] Consumer subtask 0 creating fetcher with offsets {KafkaTopicPartition{topic='ota', partition=0}=-915623761774}.
[2019-11-28 00:41:11.011] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source (1/1)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:41:12.012] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source (1/1)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:41:12.012] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source (1/1)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:41:12.012] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source (1/1)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:41:12.012] [org.apache.kafka.clients.consumer.KafkaConsumer] [Kafka Fetcher for Source: Custom Source (1/1)] [1090] [INFO ] [Consumer clientId=consumer-2, groupId=test] Subscribed to partition(s): ota-0
[2019-11-28 00:41:12.012] [org.apache.kafka.clients.Metadata] [Kafka Fetcher for Source: Custom Source (1/1)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:41:12.012] [org.apache.kafka.clients.consumer.internals.Fetcher] [Kafka Fetcher for Source: Custom Source (1/1)] [584] [INFO ] [Consumer clientId=consumer-2, groupId=test] Resetting offset for partition ota-0 to offset 8.
[2019-11-28 00:41:17.017] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler] [Kafka Fetcher for Source: Custom Source (1/1)] [675] [INFO ] [Consumer clientId=consumer-2, groupId=test] Discovered group coordinator 192.168.1.14:9092 (id: 2147483647 rack: null)
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source (1/1)] [960] [INFO ] Source: Custom Source (1/1) (9cd9537acec3a46780aa8a8906b63a3c) switched from RUNNING to FAILED.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unrecognized token 's': was expecting ('true', 'false' or 'null')
 at [Source: (byte[])"s"; line: 1, column: 3]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:212) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.performDefaultAction(SourceStreamTask.java:132) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:298) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:403) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) [flink-runtime_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) [flink-runtime_2.11-1.9.0.jar:1.9.0]
	at java.lang.Thread.run(Thread.java:748) [na:1.8.0_131]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unrecognized token 's': was expecting ('true', 'false' or 'null')
 at [Source: (byte[])"s"; line: 1, column: 3]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1804) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:703) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser._reportInvalidToken(UTF8StreamJsonParser.java:3532) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser._handleUnexpectedValue(UTF8StreamJsonParser.java:2627) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser._nextTokenNotInObject(UTF8StreamJsonParser.java:832) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextToken(UTF8StreamJsonParser.java:729) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:4141) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4000) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:202) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source (1/1)] [804] [INFO ] Freeing task resources for Source: Custom Source (1/1) (9cd9537acec3a46780aa8a8906b63a3c).
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source (1/1)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Source: Custom Source (1/1) (9cd9537acec3a46780aa8a8906b63a3c) [FAILED]
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-8] [1438] [INFO ] Un-registering task and sending final execution state FAILED to JobManager for task Source: Custom Source 9cd9537acec3a46780aa8a8906b63a3c.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-6] [1493] [INFO ] Source: Custom Source (1/1) (9cd9537acec3a46780aa8a8906b63a3c) switched from RUNNING to FAILED.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unrecognized token 's': was expecting ('true', 'false' or 'null')
 at [Source: (byte[])"s"; line: 1, column: 3]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:212) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.performDefaultAction(SourceStreamTask.java:132) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:298) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:403) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_131]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unrecognized token 's': was expecting ('true', 'false' or 'null')
 at [Source: (byte[])"s"; line: 1, column: 3]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1804) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:703) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser._reportInvalidToken(UTF8StreamJsonParser.java:3532) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser._handleUnexpectedValue(UTF8StreamJsonParser.java:2627) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser._nextTokenNotInObject(UTF8StreamJsonParser.java:832) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextToken(UTF8StreamJsonParser.java:729) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:4141) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4000) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:202) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-6] [1324] [INFO ] Job Flink Streaming Job (a08ee662b4955434ea225e6d889f51db) switched from state RUNNING to FAILING.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unrecognized token 's': was expecting ('true', 'false' or 'null')
 at [Source: (byte[])"s"; line: 1, column: 3]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:212) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.performDefaultAction(SourceStreamTask.java:132) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:298) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:403) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_131]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unrecognized token 's': was expecting ('true', 'false' or 'null')
 at [Source: (byte[])"s"; line: 1, column: 3]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1804) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:703) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser._reportInvalidToken(UTF8StreamJsonParser.java:3532) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser._handleUnexpectedValue(UTF8StreamJsonParser.java:2627) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser._nextTokenNotInObject(UTF8StreamJsonParser.java:832) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextToken(UTF8StreamJsonParser.java:729) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:4141) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4000) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:202) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-6] [1491] [INFO ] Map (1/8) (57015bc0c9d457363c061296e85a4c2d) switched from RUNNING to CANCELING.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-8] [982] [INFO ] Attempting to cancel task Map (1/8) (57015bc0c9d457363c061296e85a4c2d).
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-8] [958] [INFO ] Map (1/8) (57015bc0c9d457363c061296e85a4c2d) switched from RUNNING to CANCELING.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-8] [1031] [INFO ] Triggering cancellation of task code Map (1/8) (57015bc0c9d457363c061296e85a4c2d).
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [Map (1/8)] [958] [INFO ] Map (1/8) (57015bc0c9d457363c061296e85a4c2d) switched from CANCELING to CANCELED.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-6] [1491] [INFO ] Map (2/8) (4923da72f6359ee51002cfa689ad49e7) switched from RUNNING to CANCELING.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [Map (1/8)] [804] [INFO ] Freeing task resources for Map (1/8) (57015bc0c9d457363c061296e85a4c2d).
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [Map (1/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Map (1/8) (57015bc0c9d457363c061296e85a4c2d) [CANCELED]
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-6] [1491] [INFO ] Map (3/8) (690e67f90e3e583240d7ec9d71e8a6e9) switched from RUNNING to CANCELING.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-8] [982] [INFO ] Attempting to cancel task Map (2/8) (4923da72f6359ee51002cfa689ad49e7).
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-8] [958] [INFO ] Map (2/8) (4923da72f6359ee51002cfa689ad49e7) switched from RUNNING to CANCELING.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-6] [1491] [INFO ] Map (4/8) (104a0890c0574773dc49f9b2dcc1c6a2) switched from RUNNING to CANCELING.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-8] [1031] [INFO ] Triggering cancellation of task code Map (2/8) (4923da72f6359ee51002cfa689ad49e7).
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-6] [1491] [INFO ] Map (5/8) (518b9018e8f611dba82a26659996e158) switched from RUNNING to CANCELING.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [Map (2/8)] [958] [INFO ] Map (2/8) (4923da72f6359ee51002cfa689ad49e7) switched from CANCELING to CANCELED.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-6] [1491] [INFO ] Map (6/8) (0ea5ef2d027806fc913aa6b0d98ad34b) switched from RUNNING to CANCELING.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-8] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Map 57015bc0c9d457363c061296e85a4c2d.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [Map (2/8)] [804] [INFO ] Freeing task resources for Map (2/8) (4923da72f6359ee51002cfa689ad49e7).
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-6] [1491] [INFO ] Map (7/8) (e3abbd73c2217e8c5ad7b77c876c3a1a) switched from RUNNING to CANCELING.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [Map (2/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Map (2/8) (4923da72f6359ee51002cfa689ad49e7) [CANCELED]
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-8] [982] [INFO ] Attempting to cancel task Map (3/8) (690e67f90e3e583240d7ec9d71e8a6e9).
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-6] [1491] [INFO ] Map (8/8) (08ee9536828ece6bb1c7f6576b268464) switched from RUNNING to CANCELING.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-8] [958] [INFO ] Map (3/8) (690e67f90e3e583240d7ec9d71e8a6e9) switched from RUNNING to CANCELING.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-8] [1031] [INFO ] Triggering cancellation of task code Map (3/8) (690e67f90e3e583240d7ec9d71e8a6e9).
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [Map (3/8)] [958] [INFO ] Map (3/8) (690e67f90e3e583240d7ec9d71e8a6e9) switched from CANCELING to CANCELED.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-8] [982] [INFO ] Attempting to cancel task Map (4/8) (104a0890c0574773dc49f9b2dcc1c6a2).
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [Map (3/8)] [804] [INFO ] Freeing task resources for Map (3/8) (690e67f90e3e583240d7ec9d71e8a6e9).
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-8] [958] [INFO ] Map (4/8) (104a0890c0574773dc49f9b2dcc1c6a2) switched from RUNNING to CANCELING.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [Map (3/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Map (3/8) (690e67f90e3e583240d7ec9d71e8a6e9) [CANCELED]
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-8] [1031] [INFO ] Triggering cancellation of task code Map (4/8) (104a0890c0574773dc49f9b2dcc1c6a2).
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [Map (4/8)] [958] [INFO ] Map (4/8) (104a0890c0574773dc49f9b2dcc1c6a2) switched from CANCELING to CANCELED.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-8] [982] [INFO ] Attempting to cancel task Map (5/8) (518b9018e8f611dba82a26659996e158).
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [Map (4/8)] [804] [INFO ] Freeing task resources for Map (4/8) (104a0890c0574773dc49f9b2dcc1c6a2).
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-8] [958] [INFO ] Map (5/8) (518b9018e8f611dba82a26659996e158) switched from RUNNING to CANCELING.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [Map (4/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Map (4/8) (104a0890c0574773dc49f9b2dcc1c6a2) [CANCELED]
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-8] [1031] [INFO ] Triggering cancellation of task code Map (5/8) (518b9018e8f611dba82a26659996e158).
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [Map (5/8)] [958] [INFO ] Map (5/8) (518b9018e8f611dba82a26659996e158) switched from CANCELING to CANCELED.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-8] [982] [INFO ] Attempting to cancel task Map (6/8) (0ea5ef2d027806fc913aa6b0d98ad34b).
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [Map (5/8)] [804] [INFO ] Freeing task resources for Map (5/8) (518b9018e8f611dba82a26659996e158).
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-8] [958] [INFO ] Map (6/8) (0ea5ef2d027806fc913aa6b0d98ad34b) switched from RUNNING to CANCELING.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [Map (5/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Map (5/8) (518b9018e8f611dba82a26659996e158) [CANCELED]
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-8] [1031] [INFO ] Triggering cancellation of task code Map (6/8) (0ea5ef2d027806fc913aa6b0d98ad34b).
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [Map (6/8)] [958] [INFO ] Map (6/8) (0ea5ef2d027806fc913aa6b0d98ad34b) switched from CANCELING to CANCELED.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-8] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Map 4923da72f6359ee51002cfa689ad49e7.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-6] [1491] [INFO ] Map (1/8) (57015bc0c9d457363c061296e85a4c2d) switched from CANCELING to CANCELED.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [Map (6/8)] [804] [INFO ] Freeing task resources for Map (6/8) (0ea5ef2d027806fc913aa6b0d98ad34b).
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [Map (6/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Map (6/8) (0ea5ef2d027806fc913aa6b0d98ad34b) [CANCELED]
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-8] [982] [INFO ] Attempting to cancel task Map (7/8) (e3abbd73c2217e8c5ad7b77c876c3a1a).
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-8] [958] [INFO ] Map (7/8) (e3abbd73c2217e8c5ad7b77c876c3a1a) switched from RUNNING to CANCELING.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-8] [1031] [INFO ] Triggering cancellation of task code Map (7/8) (e3abbd73c2217e8c5ad7b77c876c3a1a).
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [Map (7/8)] [958] [INFO ] Map (7/8) (e3abbd73c2217e8c5ad7b77c876c3a1a) switched from CANCELING to CANCELED.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-8] [982] [INFO ] Attempting to cancel task Map (8/8) (08ee9536828ece6bb1c7f6576b268464).
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [Map (7/8)] [804] [INFO ] Freeing task resources for Map (7/8) (e3abbd73c2217e8c5ad7b77c876c3a1a).
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-8] [958] [INFO ] Map (8/8) (08ee9536828ece6bb1c7f6576b268464) switched from RUNNING to CANCELING.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [Map (7/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Map (7/8) (e3abbd73c2217e8c5ad7b77c876c3a1a) [CANCELED]
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-8] [1031] [INFO ] Triggering cancellation of task code Map (8/8) (08ee9536828ece6bb1c7f6576b268464).
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-6] [1491] [INFO ] Map (2/8) (4923da72f6359ee51002cfa689ad49e7) switched from CANCELING to CANCELED.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [Map (8/8)] [958] [INFO ] Map (8/8) (08ee9536828ece6bb1c7f6576b268464) switched from CANCELING to CANCELED.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-8] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Map 690e67f90e3e583240d7ec9d71e8a6e9.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [Map (8/8)] [804] [INFO ] Freeing task resources for Map (8/8) (08ee9536828ece6bb1c7f6576b268464).
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-8] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Map 104a0890c0574773dc49f9b2dcc1c6a2.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskmanager.Task] [Map (8/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Map (8/8) (08ee9536828ece6bb1c7f6576b268464) [CANCELED]
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-11] [1491] [INFO ] Map (3/8) (690e67f90e3e583240d7ec9d71e8a6e9) switched from CANCELING to CANCELED.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-8] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Map 518b9018e8f611dba82a26659996e158.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-8] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Map 0ea5ef2d027806fc913aa6b0d98ad34b.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-11] [1491] [INFO ] Map (4/8) (104a0890c0574773dc49f9b2dcc1c6a2) switched from CANCELING to CANCELED.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-8] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Map e3abbd73c2217e8c5ad7b77c876c3a1a.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-11] [1491] [INFO ] Map (5/8) (518b9018e8f611dba82a26659996e158) switched from CANCELING to CANCELED.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-8] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Map 08ee9536828ece6bb1c7f6576b268464.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-11] [1491] [INFO ] Map (6/8) (0ea5ef2d027806fc913aa6b0d98ad34b) switched from CANCELING to CANCELED.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-11] [1491] [INFO ] Map (7/8) (e3abbd73c2217e8c5ad7b77c876c3a1a) switched from CANCELING to CANCELED.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-11] [1491] [INFO ] Map (8/8) (08ee9536828ece6bb1c7f6576b268464) switched from CANCELING to CANCELED.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-11] [1446] [INFO ] Try to restart or fail the job Flink Streaming Job (a08ee662b4955434ea225e6d889f51db) if no longer possible.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-11] [1324] [INFO ] Job Flink Streaming Job (a08ee662b4955434ea225e6d889f51db) switched from state FAILING to FAILED.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unrecognized token 's': was expecting ('true', 'false' or 'null')
 at [Source: (byte[])"s"; line: 1, column: 3]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:212) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.performDefaultAction(SourceStreamTask.java:132) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:298) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:403) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_131]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unrecognized token 's': was expecting ('true', 'false' or 'null')
 at [Source: (byte[])"s"; line: 1, column: 3]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1804) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:703) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser._reportInvalidToken(UTF8StreamJsonParser.java:3532) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser._handleUnexpectedValue(UTF8StreamJsonParser.java:2627) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser._nextTokenNotInObject(UTF8StreamJsonParser.java:832) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextToken(UTF8StreamJsonParser.java:729) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:4141) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4000) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:202) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-11] [1472] [INFO ] Could not restart the job Flink Streaming Job (a08ee662b4955434ea225e6d889f51db) because the restart strategy prevented it.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unrecognized token 's': was expecting ('true', 'false' or 'null')
 at [Source: (byte[])"s"; line: 1, column: 3]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:212) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.performDefaultAction(SourceStreamTask.java:132) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:298) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:403) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_131]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unrecognized token 's': was expecting ('true', 'false' or 'null')
 at [Source: (byte[])"s"; line: 1, column: 3]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1804) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:703) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser._reportInvalidToken(UTF8StreamJsonParser.java:3532) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser._handleUnexpectedValue(UTF8StreamJsonParser.java:2627) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser._nextTokenNotInObject(UTF8StreamJsonParser.java:832) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextToken(UTF8StreamJsonParser.java:729) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:4141) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4000) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:202) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.checkpoint.CheckpointCoordinator] [flink-akka.actor.default-dispatcher-11] [329] [INFO ] Stopping checkpoint coordinator for job a08ee662b4955434ea225e6d889f51db.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore] [flink-akka.actor.default-dispatcher-11] [97] [INFO ] Shutting down
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-10] [775] [INFO ] Job a08ee662b4955434ea225e6d889f51db reached globally terminal state FAILED.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [417] [INFO ] Shutting down Flink Mini Cluster
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-8] [334] [INFO ] Stopping TaskExecutor akka://flink/user/taskmanager_0.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.rest.RestServerEndpoint] [main] [290] [INFO ] Shutting down rest endpoint.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-8] [142] [INFO ] Stop job leader service.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-11] [335] [INFO ] Stopping the JobMaster for job Flink Streaming Job(a08ee662b4955434ea225e6d889f51db).
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager] [flink-akka.actor.default-dispatcher-8] [213] [INFO ] Shutting down TaskExecutorLocalStateStoresManager.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-11] [228] [INFO ] Suspending SlotPool.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-11] [1010] [INFO ] Close ResourceManager connection 247b3a77c4ff430e7815609532171bd0: JobManager is shutting down..
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-11] [249] [INFO ] Stopping SlotPool.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-10] [774] [INFO ] Disconnect job manager ae5c4b3c943ea2106984f5d8aa504da3@akka://flink/user/jobmanager_1 for job a08ee662b4955434ea225e6d889f51db from the resource manager.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [flink-akka.actor.default-dispatcher-8] [112] [INFO ] FileChannelManager removed spill file directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-io-c874900f-7408-44f4-a229-89ebd03452e8
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.io.network.NettyShuffleEnvironment] [flink-akka.actor.default-dispatcher-8] [304] [INFO ] Shutting down the network environment and its components.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [flink-akka.actor.default-dispatcher-8] [112] [INFO ] FileChannelManager removed spill file directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-netty-shuffle-8e4cca95-b42e-408e-ab88-58551cd8d52d
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskexecutor.KvStateService] [flink-akka.actor.default-dispatcher-8] [119] [INFO ] Shutting down the kvState service and its components.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.webmonitor.WebMonitorEndpoint] [ForkJoinPool.commonPool-worker-1] [687] [INFO ] Removing cache directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-web-ui
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-8] [142] [INFO ] Stop job leader service.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.rest.RestServerEndpoint] [ForkJoinPool.commonPool-worker-1] [299] [INFO ] Shut down complete.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.filecache.FileCache] [flink-akka.actor.default-dispatcher-8] [153] [INFO ] removed file cache directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-dist-cache-d179ce37-fdf9-448c-9e4f-451ad430cce0
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-8] [359] [INFO ] Stopped TaskExecutor akka://flink/user/taskmanager_0.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-10] [499] [INFO ] Shut down cluster because application is in CANCELED, diagnostics DispatcherResourceManagerComponent has been closed..
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-8] [220] [INFO ] Stopping dispatcher akka://flink/user/dispatcher.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl] [flink-akka.actor.default-dispatcher-11] [280] [INFO ] Closing the SlotManager.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-8] [697] [INFO ] Stopping all currently running jobs of dispatcher akka://flink/user/dispatcher.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl] [flink-akka.actor.default-dispatcher-11] [243] [INFO ] Suspending the SlotManager.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.rest.handler.legacy.backpressure.StackTraceSampleCoordinator] [flink-akka.actor.default-dispatcher-8] [220] [INFO ] Shutting down stack trace sample coordinator.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-8] [229] [INFO ] Stopped dispatcher akka://flink/user/dispatcher.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [flink-akka.actor.default-dispatcher-8] [335] [INFO ] Stopping Akka RPC service.
[2019-11-28 00:41:41.041] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-2] [83] [INFO ] Shutting down remote daemon.
[2019-11-28 00:41:41.041] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-2] [83] [INFO ] Remote daemon shut down; proceeding with flushing remote transports.
[2019-11-28 00:41:41.041] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-2] [83] [INFO ] Remoting shut down.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [flink-metrics-2] [335] [INFO ] Stopping Akka RPC service.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [flink-metrics-2] [354] [INFO ] Stopped Akka RPC service.
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.blob.AbstractBlobCache] [flink-akka.actor.default-dispatcher-8] [247] [INFO ] Shutting down BLOB cache
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.blob.AbstractBlobCache] [flink-akka.actor.default-dispatcher-8] [247] [INFO ] Shutting down BLOB cache
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.blob.BlobServer] [flink-akka.actor.default-dispatcher-8] [340] [INFO ] Stopped BLOB server at 0.0.0.0:52854
[2019-11-28 00:41:41.041] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [flink-akka.actor.default-dispatcher-8] [354] [INFO ] Stopped Akka RPC service.
[2019-11-28 00:41:52.052] [org.apache.flink.api.java.typeutils.TypeExtractor] [main] [1815] [INFO ] class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a getter for field _children
[2019-11-28 00:41:52.052] [org.apache.flink.api.java.typeutils.TypeExtractor] [main] [1818] [INFO ] class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a setter for field _children
[2019-11-28 00:41:52.052] [org.apache.flink.api.java.typeutils.TypeExtractor] [main] [1857] [INFO ] Class class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:41:52.052] [org.apache.flink.streaming.api.environment.LocalStreamEnvironment] [main] [108] [INFO ] Running job on local embedded Flink mini cluster
[2019-11-28 00:41:53.053] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [254] [INFO ] Starting Flink Mini Cluster
[2019-11-28 00:41:53.053] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [263] [INFO ] Starting Metrics Registry
[2019-11-28 00:41:53.053] [org.apache.flink.runtime.metrics.MetricRegistryImpl] [main] [114] [INFO ] No metrics reporter configured, no metrics will be exposed/reported.
[2019-11-28 00:41:53.053] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [267] [INFO ] Starting RPC Service(s)
[2019-11-28 00:41:53.053] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1] [flink-akka.actor.default-dispatcher-2] [92] [INFO ] Slf4jLogger started
[2019-11-28 00:41:53.053] [org.apache.flink.runtime.clusterframework.BootstrapTools] [main] [244] [INFO ] Trying to start actor system at :0
[2019-11-28 00:41:53.053] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1] [flink-metrics-2] [92] [INFO ] Slf4jLogger started
[2019-11-28 00:41:53.053] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-2] [83] [INFO ] Starting remoting
[2019-11-28 00:41:53.053] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-2] [83] [INFO ] Remoting started; listening on addresses :[akka.tcp://flink-metrics@192.168.1.14:52868]
[2019-11-28 00:41:53.053] [org.apache.flink.runtime.clusterframework.BootstrapTools] [main] [256] [INFO ] Actor system started at akka.tcp://flink-metrics@192.168.1.14:52868
[2019-11-28 00:41:53.053] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
[2019-11-28 00:41:53.053] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [398] [INFO ] Starting high-availability services
[2019-11-28 00:41:53.053] [org.apache.flink.runtime.blob.BlobServer] [main] [141] [INFO ] Created BLOB server storage directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/blobStore-3643fc07-8738-4377-995c-dadde4b13bee
[2019-11-28 00:41:53.053] [org.apache.flink.runtime.blob.BlobServer] [main] [203] [INFO ] Started BLOB server at 0.0.0.0:52869 - max concurrent requests: 50 - max backlog: 1000
[2019-11-28 00:41:53.053] [org.apache.flink.runtime.blob.AbstractBlobCache] [main] [107] [INFO ] Created BLOB cache storage directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/blobStore-d9878234-b6be-458f-bcca-ce55a51d0a61
[2019-11-28 00:41:53.053] [org.apache.flink.runtime.blob.AbstractBlobCache] [main] [107] [INFO ] Created BLOB cache storage directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/blobStore-1b3c62fb-0e23-47f6-b51c-91b59844efdd
[2019-11-28 00:41:53.053] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [480] [INFO ] Starting 1 TaskManger(s)
[2019-11-28 00:41:53.053] [org.apache.flink.runtime.taskexecutor.TaskManagerRunner] [main] [351] [INFO ] Starting TaskManager with ResourceID: 44b4d4ea-d5bb-4bad-a057-6b7c638ea598
[2019-11-28 00:41:53.053] [org.apache.flink.runtime.taskexecutor.TaskManagerServices] [main] [519] [INFO ] Temporary file directory '/var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T': total 233 GB, usable 170 GB (72.96% usable)
[2019-11-28 00:41:53.053] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [main] [76] [INFO ] FileChannelManager uses directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-io-a3d985a3-c078-4c58-85dd-ba7e4eb1bd86 for spill files.
[2019-11-28 00:41:53.053] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [main] [76] [INFO ] FileChannelManager uses directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-netty-shuffle-fdeb8921-9591-4f99-8cea-0c56b8998ceb for spill files.
[2019-11-28 00:41:53.053] [org.apache.flink.runtime.io.network.buffer.NetworkBufferPool] [main] [140] [INFO ] Allocated 202 MB for network buffer pool (number of memory segments: 6472, bytes per segment: 32768).
[2019-11-28 00:41:53.053] [org.apache.flink.runtime.io.network.NettyShuffleEnvironment] [main] [283] [INFO ] Starting the network environment and its components.
[2019-11-28 00:41:53.053] [org.apache.flink.runtime.taskexecutor.KvStateService] [main] [89] [INFO ] Starting the kvState service and its components.
[2019-11-28 00:41:53.053] [org.apache.flink.runtime.taskexecutor.TaskManagerServices] [main] [364] [INFO ] Limiting managed memory to 0.7 of the currently free heap space (1267 MB), memory will be allocated lazily.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.TaskManagerConfiguration] [main] [197] [INFO ] Messages have a max timeout of 10000 ms
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-3] [125] [INFO ] Start job leader service.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.filecache.FileCache] [flink-akka.actor.default-dispatcher-3] [107] [INFO ] User file cache uses directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-dist-cache-e1fbfde7-3363-4f62-a4ea-eef940dbba12
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.rest.RestServerEndpoint] [main] [136] [INFO ] Starting rest endpoint.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.webmonitor.WebMonitorUtils$LogFileLocation] [main] [87] [WARN ] Log file environment variable 'log.file' is not set.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.webmonitor.WebMonitorUtils$LogFileLocation] [main] [93] [WARN ] JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] [main] [114] [INFO ] Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.rest.RestServerEndpoint] [main] [233] [INFO ] Rest endpoint listening at localhost:52870
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [main] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@1e6dad8 @ http://localhost:52870
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.webmonitor.WebMonitorEndpoint] [mini-cluster-io-thread-1] [711] [INFO ] http://localhost:52870 was granted leadership with leaderSessionID=c1d97a65-f6a9-44c9-ab83-d74ab5ab456a
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [mini-cluster-io-thread-1] [250] [INFO ] Received confirmation of leadership for leader http://localhost:52870 , session=c1d97a65-f6a9-44c9-ab83-d74ab5ab456a
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-3] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@75bd53f5 @ akka://flink/user/resourcemanager
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-2] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@6e49179f @ akka://flink/user/dispatcher
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-2] [885] [INFO ] Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token a30e7b81-f6a0-4eed-b86f-149d0eade292
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [363] [INFO ] Flink Mini Cluster started successfully
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [919] [INFO ] ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token 8b32ef2bf27a44e36f1a46776054498c
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-4] [717] [INFO ] Recovering all persisted jobs.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl] [flink-akka.actor.default-dispatcher-3] [215] [INFO ] Starting the SlotManager.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-4] [250] [INFO ] Received confirmation of leadership for leader akka://flink/user/dispatcher , session=a30e7b81-f6a0-4eed-b86f-149d0eade292
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-2] [250] [INFO ] Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=6f1a4677-6054-498c-8b32-ef2bf27a44e3
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [982] [INFO ] Connecting to ResourceManager akka://flink/user/resourcemanager(8b32ef2bf27a44e36f1a46776054498c).
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-3] [155] [INFO ] Resolved ResourceManager address, beginning registration
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-3] [204] [INFO ] Registration at ResourceManager attempt 1 (timeout=100ms)
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-4] [711] [INFO ] Registering TaskManager with ResourceID 44b4d4ea-d5bb-4bad-a057-6b7c638ea598 (akka://flink/user/taskmanager_0) at ResourceManager
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.TaskExecutorToResourceManagerConnection] [flink-akka.actor.default-dispatcher-3] [100] [INFO ] Successful registration at resource manager akka://flink/user/resourcemanager under registration id d3231c10ab026326571e03fb40b700c8.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-2] [264] [INFO ] Received JobGraph submission f618a414e9974272e1c62f748c1b3fdc (Flink Streaming Job).
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-2] [321] [INFO ] Submitting job f618a414e9974272e1c62f748c1b3fdc (Flink Streaming Job).
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [flink-akka.actor.default-dispatcher-3] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-3] [241] [INFO ] Initializing job Flink Streaming Job (f618a414e9974272e1c62f748c1b3fdc).
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.scheduler.LegacyScheduler] [flink-akka.actor.default-dispatcher-3] [171] [INFO ] Using restart strategy NoRestartStrategy for Flink Streaming Job (f618a414e9974272e1c62f748c1b3fdc).
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-3] [516] [INFO ] Job recovers via failover strategy: full graph restart
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.executiongraph.ExecutionGraphBuilder] [flink-akka.actor.default-dispatcher-3] [204] [INFO ] Running initialization on master for job Flink Streaming Job (f618a414e9974272e1c62f748c1b3fdc).
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.executiongraph.ExecutionGraphBuilder] [flink-akka.actor.default-dispatcher-3] [222] [INFO ] Successfully ran initialization on master in 0 ms.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.state.StateBackendLoader] [flink-akka.actor.default-dispatcher-3] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-3] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@5acf9f62 @ akka://flink/user/jobmanager_1
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.jobmaster.JobManagerRunner] [mini-cluster-io-thread-3] [313] [INFO ] JobManager runner for job Flink Streaming Job (f618a414e9974272e1c62f748c1b3fdc) was granted leadership with session id 905379ba-6f4f-427b-8c77-fe71fdd7b87d at akka://flink/user/jobmanager_1.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-2] [709] [INFO ] Starting execution of job Flink Streaming Job (f618a414e9974272e1c62f748c1b3fdc) under job master id 8c77fe71fdd7b87d905379ba6f4f427b.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-2] [1324] [INFO ] Job Flink Streaming Job (f618a414e9974272e1c62f748c1b3fdc) switched from state CREATED to RUNNING.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Source: Custom Source (1/1) (e6bd50760060b5513d2b231eb1a78c0f) switched from CREATED to SCHEDULED.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{78c47a48fadc757e07a45e75b12b3a3e}]
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Map (1/8) (cb936255dac13f574c03cfe8b4ad02f9) switched from CREATED to SCHEDULED.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Map (2/8) (c95e797404bbe294a093e544a395fa12) switched from CREATED to SCHEDULED.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Map (3/8) (807cbdb3591fa37cac6e1c2b68af4355) switched from CREATED to SCHEDULED.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Map (4/8) (26f737bed065f22071db4704ad57f8bd) switched from CREATED to SCHEDULED.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Map (5/8) (b31deb74f10fbec04c690cb85a7cb4f6) switched from CREATED to SCHEDULED.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Map (6/8) (a2e0b48225e6c3a53a7acfe545c12357) switched from CREATED to SCHEDULED.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Map (7/8) (5ac6c948ef29182de16b466b479e1b0e) switched from CREATED to SCHEDULED.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Map (8/8) (c9210809e5726127b1b1852fb869b99c) switched from CREATED to SCHEDULED.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [jobmanager-future-thread-1] [250] [INFO ] Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=905379ba-6f4f-427b-8c77-fe71fdd7b87d
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-2] [940] [INFO ] Connecting to ResourceManager akka://flink/user/resourcemanager(8b32ef2bf27a44e36f1a46776054498c)
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-2] [155] [INFO ] Resolved ResourceManager address, beginning registration
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-2] [204] [INFO ] Registration at ResourceManager attempt 1 (timeout=100ms)
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [302] [INFO ] Registering job manager 8c77fe71fdd7b87d905379ba6f4f427b@akka://flink/user/jobmanager_1 for job f618a414e9974272e1c62f748c1b3fdc.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-5] [657] [INFO ] Registered job manager 8c77fe71fdd7b87d905379ba6f4f427b@akka://flink/user/jobmanager_1 for job f618a414e9974272e1c62f748c1b3fdc.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-5] [962] [INFO ] JobManager successfully registered at ResourceManager, leader id: 8b32ef2bf27a44e36f1a46776054498c.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [319] [INFO ] Requesting new slot [SlotRequestId{78c47a48fadc757e07a45e75b12b3a3e}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job f618a414e9974272e1c62f748c1b3fdc with allocation id 6fd53e389ca41a15330146ad387aacb4.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [816] [INFO ] Receive slot request 6fd53e389ca41a15330146ad387aacb4 for job f618a414e9974272e1c62f748c1b3fdc from resource manager with leader id 8b32ef2bf27a44e36f1a46776054498c.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [828] [INFO ] Allocated slot for 6fd53e389ca41a15330146ad387aacb4.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-5] [193] [INFO ] Add job f618a414e9974272e1c62f748c1b3fdc for job leader monitoring.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-7] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 905379ba-6f4f-427b-8c77-fe71fdd7b87d.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-2] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-2] [204] [INFO ] Registration at JobManager attempt 1 (timeout=100ms)
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener$JobManagerRegisteredRpcConnection] [flink-akka.actor.default-dispatcher-3] [382] [INFO ] Successful registration at job manager akka://flink/user/jobmanager_1 for job f618a414e9974272e1c62f748c1b3fdc.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [1220] [INFO ] Establish JobManager connection for job f618a414e9974272e1c62f748c1b3fdc.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [1121] [INFO ] Offer reserved slots to the leader of job f618a414e9974272e1c62f748c1b3fdc.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [319] [INFO ] Requesting new slot [SlotRequestId{4c8f3d034b172595665913363a3edd50}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job f618a414e9974272e1c62f748c1b3fdc with allocation id be7b292ca21bc2845001e6f96ac8eb82.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [319] [INFO ] Requesting new slot [SlotRequestId{62c44cf8eaea1070a1b23aa4041ef9a7}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [816] [INFO ] Receive slot request be7b292ca21bc2845001e6f96ac8eb82 for job f618a414e9974272e1c62f748c1b3fdc from resource manager with leader id 8b32ef2bf27a44e36f1a46776054498c.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job f618a414e9974272e1c62f748c1b3fdc with allocation id 0259d56f2112544be196b535f64dfd5a.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [319] [INFO ] Requesting new slot [SlotRequestId{cf48914dc541fdc7c61badf8c228232d}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [828] [INFO ] Allocated slot for be7b292ca21bc2845001e6f96ac8eb82.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [1121] [INFO ] Offer reserved slots to the leader of job f618a414e9974272e1c62f748c1b3fdc.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-5] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job f618a414e9974272e1c62f748c1b3fdc with allocation id e99aa118dc4e3efa06178dc4da4ed2b7.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [319] [INFO ] Requesting new slot [SlotRequestId{af291493a1c041590d5cf25ff8b5b9fa}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [816] [INFO ] Receive slot request 0259d56f2112544be196b535f64dfd5a for job f618a414e9974272e1c62f748c1b3fdc from resource manager with leader id 8b32ef2bf27a44e36f1a46776054498c.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-5] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job f618a414e9974272e1c62f748c1b3fdc with allocation id 99798ae35e5a7b4914279030903d2033.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [319] [INFO ] Requesting new slot [SlotRequestId{a0f1be664e9481c6dbc09cb70fb7bf65}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [828] [INFO ] Allocated slot for 0259d56f2112544be196b535f64dfd5a.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [1121] [INFO ] Offer reserved slots to the leader of job f618a414e9974272e1c62f748c1b3fdc.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-5] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job f618a414e9974272e1c62f748c1b3fdc with allocation id 0411ad93d44c5b367cdd1601cebdec53.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [319] [INFO ] Requesting new slot [SlotRequestId{b84d195804e6060312d7b75cdd6a75e1}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [816] [INFO ] Receive slot request e99aa118dc4e3efa06178dc4da4ed2b7 for job f618a414e9974272e1c62f748c1b3fdc from resource manager with leader id 8b32ef2bf27a44e36f1a46776054498c.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [828] [INFO ] Allocated slot for e99aa118dc4e3efa06178dc4da4ed2b7.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job f618a414e9974272e1c62f748c1b3fdc with allocation id baff57759d628b003da78609366acedb.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [319] [INFO ] Requesting new slot [SlotRequestId{dc08f51c43104a1d9035fe3d7d7eba18}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [1121] [INFO ] Offer reserved slots to the leader of job f618a414e9974272e1c62f748c1b3fdc.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-5] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job f618a414e9974272e1c62f748c1b3fdc with allocation id b30e45fa50610162419a85ea6269d171.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [816] [INFO ] Receive slot request 99798ae35e5a7b4914279030903d2033 for job f618a414e9974272e1c62f748c1b3fdc from resource manager with leader id 8b32ef2bf27a44e36f1a46776054498c.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [828] [INFO ] Allocated slot for 99798ae35e5a7b4914279030903d2033.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [1121] [INFO ] Offer reserved slots to the leader of job f618a414e9974272e1c62f748c1b3fdc.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [816] [INFO ] Receive slot request 0411ad93d44c5b367cdd1601cebdec53 for job f618a414e9974272e1c62f748c1b3fdc from resource manager with leader id 8b32ef2bf27a44e36f1a46776054498c.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [828] [INFO ] Allocated slot for 0411ad93d44c5b367cdd1601cebdec53.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [1121] [INFO ] Offer reserved slots to the leader of job f618a414e9974272e1c62f748c1b3fdc.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [816] [INFO ] Receive slot request baff57759d628b003da78609366acedb for job f618a414e9974272e1c62f748c1b3fdc from resource manager with leader id 8b32ef2bf27a44e36f1a46776054498c.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [828] [INFO ] Allocated slot for baff57759d628b003da78609366acedb.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [1121] [INFO ] Offer reserved slots to the leader of job f618a414e9974272e1c62f748c1b3fdc.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [816] [INFO ] Receive slot request b30e45fa50610162419a85ea6269d171 for job f618a414e9974272e1c62f748c1b3fdc from resource manager with leader id 8b32ef2bf27a44e36f1a46776054498c.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [618] [INFO ] Received repeated offer for slot [6fd53e389ca41a15330146ad387aacb4]. Ignoring.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [828] [INFO ] Allocated slot for b30e45fa50610162419a85ea6269d171.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [1121] [INFO ] Offer reserved slots to the leader of job f618a414e9974272e1c62f748c1b3fdc.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [618] [INFO ] Received repeated offer for slot [6fd53e389ca41a15330146ad387aacb4]. Ignoring.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [618] [INFO ] Received repeated offer for slot [be7b292ca21bc2845001e6f96ac8eb82]. Ignoring.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot 6fd53e389ca41a15330146ad387aacb4.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [618] [INFO ] Received repeated offer for slot [be7b292ca21bc2845001e6f96ac8eb82]. Ignoring.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot 6fd53e389ca41a15330146ad387aacb4.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [618] [INFO ] Received repeated offer for slot [0259d56f2112544be196b535f64dfd5a]. Ignoring.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot be7b292ca21bc2845001e6f96ac8eb82.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [618] [INFO ] Received repeated offer for slot [6fd53e389ca41a15330146ad387aacb4]. Ignoring.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot 6fd53e389ca41a15330146ad387aacb4.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot be7b292ca21bc2845001e6f96ac8eb82.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [618] [INFO ] Received repeated offer for slot [be7b292ca21bc2845001e6f96ac8eb82]. Ignoring.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot 0259d56f2112544be196b535f64dfd5a.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [618] [INFO ] Received repeated offer for slot [0259d56f2112544be196b535f64dfd5a]. Ignoring.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot be7b292ca21bc2845001e6f96ac8eb82.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [618] [INFO ] Received repeated offer for slot [e99aa118dc4e3efa06178dc4da4ed2b7]. Ignoring.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot 0259d56f2112544be196b535f64dfd5a.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [618] [INFO ] Received repeated offer for slot [6fd53e389ca41a15330146ad387aacb4]. Ignoring.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot e99aa118dc4e3efa06178dc4da4ed2b7.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [618] [INFO ] Received repeated offer for slot [99798ae35e5a7b4914279030903d2033]. Ignoring.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot 6fd53e389ca41a15330146ad387aacb4.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [618] [INFO ] Received repeated offer for slot [be7b292ca21bc2845001e6f96ac8eb82]. Ignoring.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot 99798ae35e5a7b4914279030903d2033.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [618] [INFO ] Received repeated offer for slot [0259d56f2112544be196b535f64dfd5a]. Ignoring.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot be7b292ca21bc2845001e6f96ac8eb82.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [618] [INFO ] Received repeated offer for slot [e99aa118dc4e3efa06178dc4da4ed2b7]. Ignoring.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot 0259d56f2112544be196b535f64dfd5a.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [618] [INFO ] Received repeated offer for slot [6fd53e389ca41a15330146ad387aacb4]. Ignoring.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot e99aa118dc4e3efa06178dc4da4ed2b7.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [618] [INFO ] Received repeated offer for slot [99798ae35e5a7b4914279030903d2033]. Ignoring.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot 6fd53e389ca41a15330146ad387aacb4.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [618] [INFO ] Received repeated offer for slot [be7b292ca21bc2845001e6f96ac8eb82]. Ignoring.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot 99798ae35e5a7b4914279030903d2033.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [618] [INFO ] Received repeated offer for slot [0411ad93d44c5b367cdd1601cebdec53]. Ignoring.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot be7b292ca21bc2845001e6f96ac8eb82.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [618] [INFO ] Received repeated offer for slot [0259d56f2112544be196b535f64dfd5a]. Ignoring.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot 0411ad93d44c5b367cdd1601cebdec53.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [618] [INFO ] Received repeated offer for slot [e99aa118dc4e3efa06178dc4da4ed2b7]. Ignoring.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot 0259d56f2112544be196b535f64dfd5a.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [618] [INFO ] Received repeated offer for slot [6fd53e389ca41a15330146ad387aacb4]. Ignoring.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot e99aa118dc4e3efa06178dc4da4ed2b7.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [618] [INFO ] Received repeated offer for slot [99798ae35e5a7b4914279030903d2033]. Ignoring.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot 6fd53e389ca41a15330146ad387aacb4.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [618] [INFO ] Received repeated offer for slot [baff57759d628b003da78609366acedb]. Ignoring.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot 99798ae35e5a7b4914279030903d2033.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [618] [INFO ] Received repeated offer for slot [be7b292ca21bc2845001e6f96ac8eb82]. Ignoring.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot baff57759d628b003da78609366acedb.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [618] [INFO ] Received repeated offer for slot [0411ad93d44c5b367cdd1601cebdec53]. Ignoring.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot be7b292ca21bc2845001e6f96ac8eb82.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [618] [INFO ] Received repeated offer for slot [0259d56f2112544be196b535f64dfd5a]. Ignoring.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot 0411ad93d44c5b367cdd1601cebdec53.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [618] [INFO ] Received repeated offer for slot [e99aa118dc4e3efa06178dc4da4ed2b7]. Ignoring.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot 0259d56f2112544be196b535f64dfd5a.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [618] [INFO ] Received repeated offer for slot [6fd53e389ca41a15330146ad387aacb4]. Ignoring.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot e99aa118dc4e3efa06178dc4da4ed2b7.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot 6fd53e389ca41a15330146ad387aacb4.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Source: Custom Source (1/1) (e6bd50760060b5513d2b231eb1a78c0f) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [712] [INFO ] Deploying Source: Custom Source (1/1) (attempt #0) to 44b4d4ea-d5bb-4bad-a057-6b7c638ea598 @ localhost (dataPort=-1)
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Map (1/8) (cb936255dac13f574c03cfe8b4ad02f9) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [712] [INFO ] Deploying Map (1/8) (attempt #0) to 44b4d4ea-d5bb-4bad-a057-6b7c638ea598 @ localhost (dataPort=-1)
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Map (2/8) (c95e797404bbe294a093e544a395fa12) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [712] [INFO ] Deploying Map (2/8) (attempt #0) to 44b4d4ea-d5bb-4bad-a057-6b7c638ea598 @ localhost (dataPort=-1)
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Map (3/8) (807cbdb3591fa37cac6e1c2b68af4355) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [712] [INFO ] Deploying Map (3/8) (attempt #0) to 44b4d4ea-d5bb-4bad-a057-6b7c638ea598 @ localhost (dataPort=-1)
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Map (4/8) (26f737bed065f22071db4704ad57f8bd) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [712] [INFO ] Deploying Map (4/8) (attempt #0) to 44b4d4ea-d5bb-4bad-a057-6b7c638ea598 @ localhost (dataPort=-1)
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Map (5/8) (b31deb74f10fbec04c690cb85a7cb4f6) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [712] [INFO ] Deploying Map (5/8) (attempt #0) to 44b4d4ea-d5bb-4bad-a057-6b7c638ea598 @ localhost (dataPort=-1)
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Map (6/8) (a2e0b48225e6c3a53a7acfe545c12357) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [712] [INFO ] Deploying Map (6/8) (attempt #0) to 44b4d4ea-d5bb-4bad-a057-6b7c638ea598 @ localhost (dataPort=-1)
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Map (7/8) (5ac6c948ef29182de16b466b479e1b0e) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [712] [INFO ] Deploying Map (7/8) (attempt #0) to 44b4d4ea-d5bb-4bad-a057-6b7c638ea598 @ localhost (dataPort=-1)
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Map (8/8) (c9210809e5726127b1b1852fb869b99c) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [712] [INFO ] Deploying Map (8/8) (attempt #0) to 44b4d4ea-d5bb-4bad-a057-6b7c638ea598 @ localhost (dataPort=-1)
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [587] [INFO ] Received task Source: Custom Source (1/1).
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source (1/1)] [958] [INFO ] Source: Custom Source (1/1) (e6bd50760060b5513d2b231eb1a78c0f) switched from CREATED to DEPLOYING.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source (1/1)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source (1/1) (e6bd50760060b5513d2b231eb1a78c0f) [DEPLOYING]
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source (1/1)] [593] [INFO ] Loading JAR files for task Source: Custom Source (1/1) (e6bd50760060b5513d2b231eb1a78c0f) [DEPLOYING].
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source (1/1)] [619] [INFO ] Registering task at network: Source: Custom Source (1/1) (e6bd50760060b5513d2b231eb1a78c0f) [DEPLOYING].
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [587] [INFO ] Received task Map (1/8).
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Map (1/8)] [958] [INFO ] Map (1/8) (cb936255dac13f574c03cfe8b4ad02f9) switched from CREATED to DEPLOYING.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Map (1/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Map (1/8) (cb936255dac13f574c03cfe8b4ad02f9) [DEPLOYING]
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Map (1/8)] [593] [INFO ] Loading JAR files for task Map (1/8) (cb936255dac13f574c03cfe8b4ad02f9) [DEPLOYING].
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Map (1/8)] [619] [INFO ] Registering task at network: Map (1/8) (cb936255dac13f574c03cfe8b4ad02f9) [DEPLOYING].
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [587] [INFO ] Received task Map (2/8).
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Map (2/8)] [958] [INFO ] Map (2/8) (c95e797404bbe294a093e544a395fa12) switched from CREATED to DEPLOYING.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Map (2/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Map (2/8) (c95e797404bbe294a093e544a395fa12) [DEPLOYING]
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Map (2/8)] [593] [INFO ] Loading JAR files for task Map (2/8) (c95e797404bbe294a093e544a395fa12) [DEPLOYING].
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Map (2/8)] [619] [INFO ] Registering task at network: Map (2/8) (c95e797404bbe294a093e544a395fa12) [DEPLOYING].
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [587] [INFO ] Received task Map (3/8).
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Map (3/8)] [958] [INFO ] Map (3/8) (807cbdb3591fa37cac6e1c2b68af4355) switched from CREATED to DEPLOYING.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Map (3/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Map (3/8) (807cbdb3591fa37cac6e1c2b68af4355) [DEPLOYING]
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Map (3/8)] [593] [INFO ] Loading JAR files for task Map (3/8) (807cbdb3591fa37cac6e1c2b68af4355) [DEPLOYING].
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Map (3/8)] [619] [INFO ] Registering task at network: Map (3/8) (807cbdb3591fa37cac6e1c2b68af4355) [DEPLOYING].
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [587] [INFO ] Received task Map (4/8).
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Map (4/8)] [958] [INFO ] Map (4/8) (26f737bed065f22071db4704ad57f8bd) switched from CREATED to DEPLOYING.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Map (4/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Map (4/8) (26f737bed065f22071db4704ad57f8bd) [DEPLOYING]
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Map (4/8)] [593] [INFO ] Loading JAR files for task Map (4/8) (26f737bed065f22071db4704ad57f8bd) [DEPLOYING].
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Map (1/8)] [958] [INFO ] Map (1/8) (cb936255dac13f574c03cfe8b4ad02f9) switched from DEPLOYING to RUNNING.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Map (4/8)] [619] [INFO ] Registering task at network: Map (4/8) (26f737bed065f22071db4704ad57f8bd) [DEPLOYING].
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Map (2/8)] [958] [INFO ] Map (2/8) (c95e797404bbe294a093e544a395fa12) switched from DEPLOYING to RUNNING.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Map (3/8)] [958] [INFO ] Map (3/8) (807cbdb3591fa37cac6e1c2b68af4355) switched from DEPLOYING to RUNNING.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [587] [INFO ] Received task Map (5/8).
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Map (1/8) (cb936255dac13f574c03cfe8b4ad02f9) switched from DEPLOYING to RUNNING.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Map (4/8)] [958] [INFO ] Map (4/8) (26f737bed065f22071db4704ad57f8bd) switched from DEPLOYING to RUNNING.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.state.StateBackendLoader] [Map (2/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.state.StateBackendLoader] [Map (1/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.state.StateBackendLoader] [Map (3/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Map (5/8)] [958] [INFO ] Map (5/8) (b31deb74f10fbec04c690cb85a7cb4f6) switched from CREATED to DEPLOYING.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Map (2/8) (c95e797404bbe294a093e544a395fa12) switched from DEPLOYING to RUNNING.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.state.StateBackendLoader] [Map (4/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Map (5/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Map (5/8) (b31deb74f10fbec04c690cb85a7cb4f6) [DEPLOYING]
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Map (3/8) (807cbdb3591fa37cac6e1c2b68af4355) switched from DEPLOYING to RUNNING.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Map (5/8)] [593] [INFO ] Loading JAR files for task Map (5/8) (b31deb74f10fbec04c690cb85a7cb4f6) [DEPLOYING].
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source (1/1)] [958] [INFO ] Source: Custom Source (1/1) (e6bd50760060b5513d2b231eb1a78c0f) switched from DEPLOYING to RUNNING.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Map (4/8) (26f737bed065f22071db4704ad57f8bd) switched from DEPLOYING to RUNNING.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [587] [INFO ] Received task Map (6/8).
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source (1/1)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Map (5/8)] [619] [INFO ] Registering task at network: Map (5/8) (b31deb74f10fbec04c690cb85a7cb4f6) [DEPLOYING].
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Source: Custom Source (1/1) (e6bd50760060b5513d2b231eb1a78c0f) switched from DEPLOYING to RUNNING.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Map (6/8)] [958] [INFO ] Map (6/8) (a2e0b48225e6c3a53a7acfe545c12357) switched from CREATED to DEPLOYING.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Map (5/8)] [958] [INFO ] Map (5/8) (b31deb74f10fbec04c690cb85a7cb4f6) switched from DEPLOYING to RUNNING.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Map (6/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Map (6/8) (a2e0b48225e6c3a53a7acfe545c12357) [DEPLOYING]
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [587] [INFO ] Received task Map (7/8).
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.state.StateBackendLoader] [Map (5/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Map (5/8) (b31deb74f10fbec04c690cb85a7cb4f6) switched from DEPLOYING to RUNNING.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Map (6/8)] [593] [INFO ] Loading JAR files for task Map (6/8) (a2e0b48225e6c3a53a7acfe545c12357) [DEPLOYING].
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Map (7/8)] [958] [INFO ] Map (7/8) (5ac6c948ef29182de16b466b479e1b0e) switched from CREATED to DEPLOYING.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot 99798ae35e5a7b4914279030903d2033.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Map (7/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Map (7/8) (5ac6c948ef29182de16b466b479e1b0e) [DEPLOYING]
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot baff57759d628b003da78609366acedb.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Map (6/8)] [619] [INFO ] Registering task at network: Map (6/8) (a2e0b48225e6c3a53a7acfe545c12357) [DEPLOYING].
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Map (7/8)] [593] [INFO ] Loading JAR files for task Map (7/8) (5ac6c948ef29182de16b466b479e1b0e) [DEPLOYING].
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot be7b292ca21bc2845001e6f96ac8eb82.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot 0411ad93d44c5b367cdd1601cebdec53.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Map (6/8)] [958] [INFO ] Map (6/8) (a2e0b48225e6c3a53a7acfe545c12357) switched from DEPLOYING to RUNNING.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot 0259d56f2112544be196b535f64dfd5a.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Map (6/8) (a2e0b48225e6c3a53a7acfe545c12357) switched from DEPLOYING to RUNNING.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.state.StateBackendLoader] [Map (6/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot e99aa118dc4e3efa06178dc4da4ed2b7.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Map (7/8)] [619] [INFO ] Registering task at network: Map (7/8) (5ac6c948ef29182de16b466b479e1b0e) [DEPLOYING].
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot 6fd53e389ca41a15330146ad387aacb4.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Map (7/8)] [958] [INFO ] Map (7/8) (5ac6c948ef29182de16b466b479e1b0e) switched from DEPLOYING to RUNNING.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-4] [237] [INFO ] Activate slot b30e45fa50610162419a85ea6269d171.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.state.StateBackendLoader] [Map (7/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Map (7/8) (5ac6c948ef29182de16b466b479e1b0e) switched from DEPLOYING to RUNNING.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [587] [INFO ] Received task Map (8/8).
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Map (8/8)] [958] [INFO ] Map (8/8) (c9210809e5726127b1b1852fb869b99c) switched from CREATED to DEPLOYING.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Map (8/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Map (8/8) (c9210809e5726127b1b1852fb869b99c) [DEPLOYING]
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Map (8/8)] [593] [INFO ] Loading JAR files for task Map (8/8) (c9210809e5726127b1b1852fb869b99c) [DEPLOYING].
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Map (8/8)] [619] [INFO ] Registering task at network: Map (8/8) (c9210809e5726127b1b1852fb869b99c) [DEPLOYING].
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.taskmanager.Task] [Map (8/8)] [958] [INFO ] Map (8/8) (c9210809e5726127b1b1852fb869b99c) switched from DEPLOYING to RUNNING.
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.state.StateBackendLoader] [Map (8/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:41:54.054] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Map (8/8) (c9210809e5726127b1b1852fb869b99c) switched from DEPLOYING to RUNNING.
[2019-11-28 00:41:54.054] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source (1/1)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:41:54.054] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source (1/1)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:41:54.054] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source (1/1)] [886] [INFO ] Consumer subtask 0 has no restore state.
[2019-11-28 00:41:54.054] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source (1/1)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:41:54.054] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source (1/1)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:41:54.054] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source (1/1)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:41:54.054] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source (1/1)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:41:54.054] [org.apache.kafka.clients.Metadata] [Source: Custom Source (1/1)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:41:54.054] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source (1/1)] [610] [INFO ] Consumer subtask 0 will start reading the following 1 partitions from the latest offsets: [KafkaTopicPartition{topic='ota', partition=0}]
[2019-11-28 00:41:54.054] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-7] [688] [INFO ] Consumer subtask 0 creating fetcher with offsets {KafkaTopicPartition{topic='ota', partition=0}=-915623761774}.
[2019-11-28 00:41:54.054] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source (1/1)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:41:54.054] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source (1/1)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:41:54.054] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source (1/1)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:41:54.054] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source (1/1)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:41:54.054] [org.apache.kafka.clients.consumer.KafkaConsumer] [Kafka Fetcher for Source: Custom Source (1/1)] [1090] [INFO ] [Consumer clientId=consumer-2, groupId=test] Subscribed to partition(s): ota-0
[2019-11-28 00:41:54.054] [org.apache.kafka.clients.Metadata] [Kafka Fetcher for Source: Custom Source (1/1)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:41:54.054] [org.apache.kafka.clients.consumer.internals.Fetcher] [Kafka Fetcher for Source: Custom Source (1/1)] [584] [INFO ] [Consumer clientId=consumer-2, groupId=test] Resetting offset for partition ota-0 to offset 11.
[2019-11-28 00:41:59.059] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler] [Kafka Fetcher for Source: Custom Source (1/1)] [675] [INFO ] [Consumer clientId=consumer-2, groupId=test] Discovered group coordinator 192.168.1.14:9092 (id: 2147483647 rack: null)
[2019-11-28 00:42:11.011] [org.apache.flink.runtime.blob.AbstractBlobCache] [TransientBlobCache shutdown hook] [247] [INFO ] Shutting down BLOB cache
[2019-11-28 00:42:11.011] [org.apache.flink.runtime.blob.AbstractBlobCache] [PermanentBlobCache shutdown hook] [247] [INFO ] Shutting down BLOB cache
[2019-11-28 00:42:11.011] [org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager] [TaskExecutorLocalStateStoresManager shutdown hook] [213] [INFO ] Shutting down TaskExecutorLocalStateStoresManager.
[2019-11-28 00:42:11.011] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [IOManagerAsync shutdown hook] [112] [INFO ] FileChannelManager removed spill file directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-io-a3d985a3-c078-4c58-85dd-ba7e4eb1bd86
[2019-11-28 00:42:11.011] [org.apache.flink.runtime.filecache.FileCache] [FileCache shutdown hook] [153] [INFO ] removed file cache directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-dist-cache-e1fbfde7-3363-4f62-a4ea-eef940dbba12
[2019-11-28 00:42:11.011] [org.apache.flink.runtime.blob.BlobServer] [BlobServer shutdown hook] [340] [INFO ] Stopped BLOB server at 0.0.0.0:52869
[2019-11-28 00:42:23.023] [org.apache.flink.api.java.typeutils.TypeExtractor] [main] [1815] [INFO ] class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a getter for field _children
[2019-11-28 00:42:23.023] [org.apache.flink.api.java.typeutils.TypeExtractor] [main] [1818] [INFO ] class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a setter for field _children
[2019-11-28 00:42:23.023] [org.apache.flink.api.java.typeutils.TypeExtractor] [main] [1857] [INFO ] Class class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:42:23.023] [org.apache.flink.streaming.api.environment.LocalStreamEnvironment] [main] [108] [INFO ] Running job on local embedded Flink mini cluster
[2019-11-28 00:42:23.023] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [254] [INFO ] Starting Flink Mini Cluster
[2019-11-28 00:42:23.023] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [263] [INFO ] Starting Metrics Registry
[2019-11-28 00:42:23.023] [org.apache.flink.runtime.metrics.MetricRegistryImpl] [main] [114] [INFO ] No metrics reporter configured, no metrics will be exposed/reported.
[2019-11-28 00:42:23.023] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [267] [INFO ] Starting RPC Service(s)
[2019-11-28 00:42:24.024] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1] [flink-akka.actor.default-dispatcher-2] [92] [INFO ] Slf4jLogger started
[2019-11-28 00:42:24.024] [org.apache.flink.runtime.clusterframework.BootstrapTools] [main] [244] [INFO ] Trying to start actor system at :0
[2019-11-28 00:42:24.024] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1] [flink-metrics-2] [92] [INFO ] Slf4jLogger started
[2019-11-28 00:42:24.024] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-2] [83] [INFO ] Starting remoting
[2019-11-28 00:42:24.024] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-2] [83] [INFO ] Remoting started; listening on addresses :[akka.tcp://flink-metrics@192.168.1.14:52883]
[2019-11-28 00:42:24.024] [org.apache.flink.runtime.clusterframework.BootstrapTools] [main] [256] [INFO ] Actor system started at akka.tcp://flink-metrics@192.168.1.14:52883
[2019-11-28 00:42:24.024] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
[2019-11-28 00:42:24.024] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [398] [INFO ] Starting high-availability services
[2019-11-28 00:42:24.024] [org.apache.flink.runtime.blob.BlobServer] [main] [141] [INFO ] Created BLOB server storage directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/blobStore-4bf4fe2e-ad5c-4d0e-97ba-5159e19c7744
[2019-11-28 00:42:24.024] [org.apache.flink.runtime.blob.BlobServer] [main] [203] [INFO ] Started BLOB server at 0.0.0.0:52884 - max concurrent requests: 50 - max backlog: 1000
[2019-11-28 00:42:24.024] [org.apache.flink.runtime.blob.AbstractBlobCache] [main] [107] [INFO ] Created BLOB cache storage directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/blobStore-b019324b-1b2b-4458-bede-b4b29eaa172c
[2019-11-28 00:42:24.024] [org.apache.flink.runtime.blob.AbstractBlobCache] [main] [107] [INFO ] Created BLOB cache storage directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/blobStore-18b81c98-74fc-4eb1-a1cd-bd908f7fcefd
[2019-11-28 00:42:24.024] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [480] [INFO ] Starting 1 TaskManger(s)
[2019-11-28 00:42:24.024] [org.apache.flink.runtime.taskexecutor.TaskManagerRunner] [main] [351] [INFO ] Starting TaskManager with ResourceID: efd8d72d-41e8-485e-b068-7cc5dab69677
[2019-11-28 00:42:24.024] [org.apache.flink.runtime.taskexecutor.TaskManagerServices] [main] [519] [INFO ] Temporary file directory '/var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T': total 233 GB, usable 170 GB (72.96% usable)
[2019-11-28 00:42:24.024] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [main] [76] [INFO ] FileChannelManager uses directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-io-265d7bcd-00ad-4241-9df3-0b3c31d975b7 for spill files.
[2019-11-28 00:42:24.024] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [main] [76] [INFO ] FileChannelManager uses directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-netty-shuffle-a4b739ac-ce8e-4edd-a0eb-1c1f6ad87b46 for spill files.
[2019-11-28 00:42:24.024] [org.apache.flink.runtime.io.network.buffer.NetworkBufferPool] [main] [140] [INFO ] Allocated 202 MB for network buffer pool (number of memory segments: 6472, bytes per segment: 32768).
[2019-11-28 00:42:24.024] [org.apache.flink.runtime.io.network.NettyShuffleEnvironment] [main] [283] [INFO ] Starting the network environment and its components.
[2019-11-28 00:42:24.024] [org.apache.flink.runtime.taskexecutor.KvStateService] [main] [89] [INFO ] Starting the kvState service and its components.
[2019-11-28 00:42:24.024] [org.apache.flink.runtime.taskexecutor.TaskManagerServices] [main] [364] [INFO ] Limiting managed memory to 0.7 of the currently free heap space (1267 MB), memory will be allocated lazily.
[2019-11-28 00:42:24.024] [org.apache.flink.runtime.taskexecutor.TaskManagerConfiguration] [main] [197] [INFO ] Messages have a max timeout of 10000 ms
[2019-11-28 00:42:24.024] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
[2019-11-28 00:42:24.024] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-2] [125] [INFO ] Start job leader service.
[2019-11-28 00:42:24.024] [org.apache.flink.runtime.filecache.FileCache] [flink-akka.actor.default-dispatcher-2] [107] [INFO ] User file cache uses directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-dist-cache-77682a3a-1de4-447a-a597-5128c19f43b1
[2019-11-28 00:42:24.024] [org.apache.flink.runtime.rest.RestServerEndpoint] [main] [136] [INFO ] Starting rest endpoint.
[2019-11-28 00:42:24.024] [org.apache.flink.runtime.webmonitor.WebMonitorUtils$LogFileLocation] [main] [87] [WARN ] Log file environment variable 'log.file' is not set.
[2019-11-28 00:42:24.024] [org.apache.flink.runtime.webmonitor.WebMonitorUtils$LogFileLocation] [main] [93] [WARN ] JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
[2019-11-28 00:42:24.024] [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] [main] [114] [INFO ] Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
[2019-11-28 00:42:24.024] [org.apache.flink.runtime.rest.RestServerEndpoint] [main] [233] [INFO ] Rest endpoint listening at localhost:52885
[2019-11-28 00:42:24.024] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [main] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@4a5905d9 @ http://localhost:52885
[2019-11-28 00:42:24.024] [org.apache.flink.runtime.webmonitor.WebMonitorEndpoint] [mini-cluster-io-thread-1] [711] [INFO ] http://localhost:52885 was granted leadership with leaderSessionID=060f1d39-04c9-419e-b0fe-70dbbfc351e3
[2019-11-28 00:42:24.024] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [mini-cluster-io-thread-1] [250] [INFO ] Received confirmation of leadership for leader http://localhost:52885 , session=060f1d39-04c9-419e-b0fe-70dbbfc351e3
[2019-11-28 00:42:24.024] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
[2019-11-28 00:42:24.024] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-2] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@5828ad38 @ akka://flink/user/resourcemanager
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-3] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@69519e78 @ akka://flink/user/dispatcher
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-3] [885] [INFO ] Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token 047f5834-08c5-43eb-82ad-58f96626a4ed
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-2] [919] [INFO ] ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token 957a2b9e9ad71af324af9957aba24eb7
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [363] [INFO ] Flink Mini Cluster started successfully
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-5] [717] [INFO ] Recovering all persisted jobs.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl] [flink-akka.actor.default-dispatcher-2] [215] [INFO ] Starting the SlotManager.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-3] [250] [INFO ] Received confirmation of leadership for leader akka://flink/user/dispatcher , session=047f5834-08c5-43eb-82ad-58f96626a4ed
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-4] [250] [INFO ] Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=24af9957-aba2-4eb7-957a-2b9e9ad71af3
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [982] [INFO ] Connecting to ResourceManager akka://flink/user/resourcemanager(957a2b9e9ad71af324af9957aba24eb7).
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-4] [155] [INFO ] Resolved ResourceManager address, beginning registration
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-4] [204] [INFO ] Registration at ResourceManager attempt 1 (timeout=100ms)
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [711] [INFO ] Registering TaskManager with ResourceID efd8d72d-41e8-485e-b068-7cc5dab69677 (akka://flink/user/taskmanager_0) at ResourceManager
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-5] [264] [INFO ] Received JobGraph submission 29c7a11ff12d9861eb4223934ac1dfe0 (Flink Streaming Job).
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.TaskExecutorToResourceManagerConnection] [flink-akka.actor.default-dispatcher-3] [100] [INFO ] Successful registration at resource manager akka://flink/user/resourcemanager under registration id 21e716d52d77077be9fcb8300e9197da.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-5] [321] [INFO ] Submitting job 29c7a11ff12d9861eb4223934ac1dfe0 (Flink Streaming Job).
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [flink-akka.actor.default-dispatcher-3] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-3] [241] [INFO ] Initializing job Flink Streaming Job (29c7a11ff12d9861eb4223934ac1dfe0).
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.scheduler.LegacyScheduler] [flink-akka.actor.default-dispatcher-3] [171] [INFO ] Using restart strategy NoRestartStrategy for Flink Streaming Job (29c7a11ff12d9861eb4223934ac1dfe0).
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-3] [516] [INFO ] Job recovers via failover strategy: full graph restart
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.executiongraph.ExecutionGraphBuilder] [flink-akka.actor.default-dispatcher-3] [204] [INFO ] Running initialization on master for job Flink Streaming Job (29c7a11ff12d9861eb4223934ac1dfe0).
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.executiongraph.ExecutionGraphBuilder] [flink-akka.actor.default-dispatcher-3] [222] [INFO ] Successfully ran initialization on master in 0 ms.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.state.StateBackendLoader] [flink-akka.actor.default-dispatcher-3] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-3] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@f59b96 @ akka://flink/user/jobmanager_1
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.jobmaster.JobManagerRunner] [mini-cluster-io-thread-3] [313] [INFO ] JobManager runner for job Flink Streaming Job (29c7a11ff12d9861eb4223934ac1dfe0) was granted leadership with session id 78bb0359-8c36-47ab-9071-e28a3732f9c8 at akka://flink/user/jobmanager_1.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-5] [709] [INFO ] Starting execution of job Flink Streaming Job (29c7a11ff12d9861eb4223934ac1dfe0) under job master id 9071e28a3732f9c878bb03598c3647ab.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-5] [1324] [INFO ] Job Flink Streaming Job (29c7a11ff12d9861eb4223934ac1dfe0) switched from state CREATED to RUNNING.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map (1/8) (db59f64e5717706d3ad095e82c0b7cf7) switched from CREATED to SCHEDULED.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{347ea06c1a465a929cb3978682b9b0e2}]
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map (2/8) (3b2c7e8fb64fd9cd2b50b69682813417) switched from CREATED to SCHEDULED.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{b91e8e4052a51e594337237aced5a25c}]
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map (3/8) (1d1cf9ba6f0666bd0dbf10576cefe3a9) switched from CREATED to SCHEDULED.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{218d0c6d8ff82cabc7e13f22a80e8b1c}]
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map (4/8) (d693d6543ba2be07b133e85296324b05) switched from CREATED to SCHEDULED.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{55f5b1a51ca2f2d4bdce08425d1fb725}]
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map (5/8) (1f46b21826165dcb07df975dc4cde4d0) switched from CREATED to SCHEDULED.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{1ee5ad06163a391f78adaec76248bda9}]
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map (6/8) (47e7b86af92271b4b0297616ee75ca48) switched from CREATED to SCHEDULED.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{4ae4cff5de8a96b38f6b717f0ff99e4a}]
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map (7/8) (8a8de52aad68586cdb8ee7483487f7e1) switched from CREATED to SCHEDULED.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{fd562e2274175ead710fbafa7ea51992}]
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map (8/8) (a8182faaa4f88c51ad7e248dba41c711) switched from CREATED to SCHEDULED.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{ec207fd2812cc27e8f276abafd0860b0}]
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [jobmanager-future-thread-1] [250] [INFO ] Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=78bb0359-8c36-47ab-9071-e28a3732f9c8
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-5] [940] [INFO ] Connecting to ResourceManager akka://flink/user/resourcemanager(957a2b9e9ad71af324af9957aba24eb7)
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-5] [155] [INFO ] Resolved ResourceManager address, beginning registration
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-5] [204] [INFO ] Registration at ResourceManager attempt 1 (timeout=100ms)
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [302] [INFO ] Registering job manager 9071e28a3732f9c878bb03598c3647ab@akka://flink/user/jobmanager_1 for job 29c7a11ff12d9861eb4223934ac1dfe0.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-4] [657] [INFO ] Registered job manager 9071e28a3732f9c878bb03598c3647ab@akka://flink/user/jobmanager_1 for job 29c7a11ff12d9861eb4223934ac1dfe0.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-4] [962] [INFO ] JobManager successfully registered at ResourceManager, leader id: 957a2b9e9ad71af324af9957aba24eb7.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{347ea06c1a465a929cb3978682b9b0e2}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 29c7a11ff12d9861eb4223934ac1dfe0 with allocation id 68f6c0d37e1fca536f738f795c88428c.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{b91e8e4052a51e594337237aced5a25c}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{218d0c6d8ff82cabc7e13f22a80e8b1c}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{55f5b1a51ca2f2d4bdce08425d1fb725}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [816] [INFO ] Receive slot request 68f6c0d37e1fca536f738f795c88428c for job 29c7a11ff12d9861eb4223934ac1dfe0 from resource manager with leader id 957a2b9e9ad71af324af9957aba24eb7.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{1ee5ad06163a391f78adaec76248bda9}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{4ae4cff5de8a96b38f6b717f0ff99e4a}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 29c7a11ff12d9861eb4223934ac1dfe0 with allocation id 1d66b2739e632587089c96a383cc7875.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [828] [INFO ] Allocated slot for 68f6c0d37e1fca536f738f795c88428c.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{fd562e2274175ead710fbafa7ea51992}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-5] [193] [INFO ] Add job 29c7a11ff12d9861eb4223934ac1dfe0 for job leader monitoring.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 29c7a11ff12d9861eb4223934ac1dfe0 with allocation id 0f918997db368befad3d760f135e0176.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{ec207fd2812cc27e8f276abafd0860b0}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 29c7a11ff12d9861eb4223934ac1dfe0 with allocation id 7f1cf2119e836bfa3ef1656ec31f10d0.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 29c7a11ff12d9861eb4223934ac1dfe0 with allocation id 6bed53622bd0ddf269fb509fbef6eb8f.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [816] [INFO ] Receive slot request 1d66b2739e632587089c96a383cc7875 for job 29c7a11ff12d9861eb4223934ac1dfe0 from resource manager with leader id 957a2b9e9ad71af324af9957aba24eb7.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [828] [INFO ] Allocated slot for 1d66b2739e632587089c96a383cc7875.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 29c7a11ff12d9861eb4223934ac1dfe0 with allocation id f5117734bbe4222a09ee4bc62413b3db.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-7] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 78bb0359-8c36-47ab-9071-e28a3732f9c8.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-5] [193] [INFO ] Add job 29c7a11ff12d9861eb4223934ac1dfe0 for job leader monitoring.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 29c7a11ff12d9861eb4223934ac1dfe0 with allocation id 13e39431be2e4e730e26a5b4bb2d158d.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-8] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 78bb0359-8c36-47ab-9071-e28a3732f9c8.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [816] [INFO ] Receive slot request 0f918997db368befad3d760f135e0176 for job 29c7a11ff12d9861eb4223934ac1dfe0 from resource manager with leader id 957a2b9e9ad71af324af9957aba24eb7.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-2] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 29c7a11ff12d9861eb4223934ac1dfe0 with allocation id 41e9c0f2a062ded438d73c918a6ca805.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [828] [INFO ] Allocated slot for 0f918997db368befad3d760f135e0176.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-2] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-5] [193] [INFO ] Add job 29c7a11ff12d9861eb4223934ac1dfe0 for job leader monitoring.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-2] [204] [INFO ] Registration at JobManager attempt 1 (timeout=100ms)
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-1] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 78bb0359-8c36-47ab-9071-e28a3732f9c8.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [816] [INFO ] Receive slot request 7f1cf2119e836bfa3ef1656ec31f10d0 for job 29c7a11ff12d9861eb4223934ac1dfe0 from resource manager with leader id 957a2b9e9ad71af324af9957aba24eb7.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [828] [INFO ] Allocated slot for 7f1cf2119e836bfa3ef1656ec31f10d0.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-5] [193] [INFO ] Add job 29c7a11ff12d9861eb4223934ac1dfe0 for job leader monitoring.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-5] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 78bb0359-8c36-47ab-9071-e28a3732f9c8.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [816] [INFO ] Receive slot request 6bed53622bd0ddf269fb509fbef6eb8f for job 29c7a11ff12d9861eb4223934ac1dfe0 from resource manager with leader id 957a2b9e9ad71af324af9957aba24eb7.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-4] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [828] [INFO ] Allocated slot for 6bed53622bd0ddf269fb509fbef6eb8f.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-5] [193] [INFO ] Add job 29c7a11ff12d9861eb4223934ac1dfe0 for job leader monitoring.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-2] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-6] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 78bb0359-8c36-47ab-9071-e28a3732f9c8.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [816] [INFO ] Receive slot request f5117734bbe4222a09ee4bc62413b3db for job 29c7a11ff12d9861eb4223934ac1dfe0 from resource manager with leader id 957a2b9e9ad71af324af9957aba24eb7.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [828] [INFO ] Allocated slot for f5117734bbe4222a09ee4bc62413b3db.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-5] [193] [INFO ] Add job 29c7a11ff12d9861eb4223934ac1dfe0 for job leader monitoring.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-4] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-3] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 78bb0359-8c36-47ab-9071-e28a3732f9c8.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [816] [INFO ] Receive slot request 13e39431be2e4e730e26a5b4bb2d158d for job 29c7a11ff12d9861eb4223934ac1dfe0 from resource manager with leader id 957a2b9e9ad71af324af9957aba24eb7.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [828] [INFO ] Allocated slot for 13e39431be2e4e730e26a5b4bb2d158d.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-5] [193] [INFO ] Add job 29c7a11ff12d9861eb4223934ac1dfe0 for job leader monitoring.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-4] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-2] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 78bb0359-8c36-47ab-9071-e28a3732f9c8.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [816] [INFO ] Receive slot request 41e9c0f2a062ded438d73c918a6ca805 for job 29c7a11ff12d9861eb4223934ac1dfe0 from resource manager with leader id 957a2b9e9ad71af324af9957aba24eb7.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-5] [828] [INFO ] Allocated slot for 41e9c0f2a062ded438d73c918a6ca805.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-5] [193] [INFO ] Add job 29c7a11ff12d9861eb4223934ac1dfe0 for job leader monitoring.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-4] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-4] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 78bb0359-8c36-47ab-9071-e28a3732f9c8.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-3] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-3] [204] [INFO ] Registration at JobManager attempt 1 (timeout=100ms)
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener$JobManagerRegisteredRpcConnection] [flink-akka.actor.default-dispatcher-3] [382] [INFO ] Successful registration at job manager akka://flink/user/jobmanager_1 for job 29c7a11ff12d9861eb4223934ac1dfe0.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [1220] [INFO ] Establish JobManager connection for job 29c7a11ff12d9861eb4223934ac1dfe0.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [1121] [INFO ] Offer reserved slots to the leader of job 29c7a11ff12d9861eb4223934ac1dfe0.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map (1/8) (db59f64e5717706d3ad095e82c0b7cf7) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [712] [INFO ] Deploying Source: Custom Source -> Map (1/8) (attempt #0) to efd8d72d-41e8-485e-b068-7cc5dab69677 @ localhost (dataPort=-1)
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map (2/8) (3b2c7e8fb64fd9cd2b50b69682813417) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [712] [INFO ] Deploying Source: Custom Source -> Map (2/8) (attempt #0) to efd8d72d-41e8-485e-b068-7cc5dab69677 @ localhost (dataPort=-1)
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map (3/8) (1d1cf9ba6f0666bd0dbf10576cefe3a9) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [712] [INFO ] Deploying Source: Custom Source -> Map (3/8) (attempt #0) to efd8d72d-41e8-485e-b068-7cc5dab69677 @ localhost (dataPort=-1)
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map (4/8) (d693d6543ba2be07b133e85296324b05) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [712] [INFO ] Deploying Source: Custom Source -> Map (4/8) (attempt #0) to efd8d72d-41e8-485e-b068-7cc5dab69677 @ localhost (dataPort=-1)
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map (5/8) (1f46b21826165dcb07df975dc4cde4d0) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [712] [INFO ] Deploying Source: Custom Source -> Map (5/8) (attempt #0) to efd8d72d-41e8-485e-b068-7cc5dab69677 @ localhost (dataPort=-1)
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map (6/8) (47e7b86af92271b4b0297616ee75ca48) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [712] [INFO ] Deploying Source: Custom Source -> Map (6/8) (attempt #0) to efd8d72d-41e8-485e-b068-7cc5dab69677 @ localhost (dataPort=-1)
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map (7/8) (8a8de52aad68586cdb8ee7483487f7e1) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [712] [INFO ] Deploying Source: Custom Source -> Map (7/8) (attempt #0) to efd8d72d-41e8-485e-b068-7cc5dab69677 @ localhost (dataPort=-1)
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map (8/8) (a8182faaa4f88c51ad7e248dba41c711) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [712] [INFO ] Deploying Source: Custom Source -> Map (8/8) (attempt #0) to efd8d72d-41e8-485e-b068-7cc5dab69677 @ localhost (dataPort=-1)
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [587] [INFO ] Received task Source: Custom Source -> Map (1/8).
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (1/8)] [958] [INFO ] Source: Custom Source -> Map (1/8) (db59f64e5717706d3ad095e82c0b7cf7) switched from CREATED to DEPLOYING.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (1/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (1/8) (db59f64e5717706d3ad095e82c0b7cf7) [DEPLOYING]
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (1/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map (1/8) (db59f64e5717706d3ad095e82c0b7cf7) [DEPLOYING].
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [587] [INFO ] Received task Source: Custom Source -> Map (2/8).
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (2/8)] [958] [INFO ] Source: Custom Source -> Map (2/8) (3b2c7e8fb64fd9cd2b50b69682813417) switched from CREATED to DEPLOYING.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (1/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map (1/8) (db59f64e5717706d3ad095e82c0b7cf7) [DEPLOYING].
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (2/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (2/8) (3b2c7e8fb64fd9cd2b50b69682813417) [DEPLOYING]
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (2/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map (2/8) (3b2c7e8fb64fd9cd2b50b69682813417) [DEPLOYING].
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (2/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map (2/8) (3b2c7e8fb64fd9cd2b50b69682813417) [DEPLOYING].
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [587] [INFO ] Received task Source: Custom Source -> Map (3/8).
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (3/8)] [958] [INFO ] Source: Custom Source -> Map (3/8) (1d1cf9ba6f0666bd0dbf10576cefe3a9) switched from CREATED to DEPLOYING.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (3/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (3/8) (1d1cf9ba6f0666bd0dbf10576cefe3a9) [DEPLOYING]
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (3/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map (3/8) (1d1cf9ba6f0666bd0dbf10576cefe3a9) [DEPLOYING].
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (3/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map (3/8) (1d1cf9ba6f0666bd0dbf10576cefe3a9) [DEPLOYING].
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [587] [INFO ] Received task Source: Custom Source -> Map (4/8).
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (4/8)] [958] [INFO ] Source: Custom Source -> Map (4/8) (d693d6543ba2be07b133e85296324b05) switched from CREATED to DEPLOYING.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (4/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (4/8) (d693d6543ba2be07b133e85296324b05) [DEPLOYING]
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (4/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map (4/8) (d693d6543ba2be07b133e85296324b05) [DEPLOYING].
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (4/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map (4/8) (d693d6543ba2be07b133e85296324b05) [DEPLOYING].
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [587] [INFO ] Received task Source: Custom Source -> Map (5/8).
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (5/8)] [958] [INFO ] Source: Custom Source -> Map (5/8) (1f46b21826165dcb07df975dc4cde4d0) switched from CREATED to DEPLOYING.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (5/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (5/8) (1f46b21826165dcb07df975dc4cde4d0) [DEPLOYING]
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (5/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map (5/8) (1f46b21826165dcb07df975dc4cde4d0) [DEPLOYING].
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (1/8)] [958] [INFO ] Source: Custom Source -> Map (1/8) (db59f64e5717706d3ad095e82c0b7cf7) switched from DEPLOYING to RUNNING.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (3/8)] [958] [INFO ] Source: Custom Source -> Map (3/8) (1d1cf9ba6f0666bd0dbf10576cefe3a9) switched from DEPLOYING to RUNNING.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (4/8)] [958] [INFO ] Source: Custom Source -> Map (4/8) (d693d6543ba2be07b133e85296324b05) switched from DEPLOYING to RUNNING.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (2/8)] [958] [INFO ] Source: Custom Source -> Map (2/8) (3b2c7e8fb64fd9cd2b50b69682813417) switched from DEPLOYING to RUNNING.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (5/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map (5/8) (1f46b21826165dcb07df975dc4cde4d0) [DEPLOYING].
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Source: Custom Source -> Map (1/8) (db59f64e5717706d3ad095e82c0b7cf7) switched from DEPLOYING to RUNNING.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [587] [INFO ] Received task Source: Custom Source -> Map (6/8).
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map (1/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map (3/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map (4/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Source: Custom Source -> Map (3/8) (1d1cf9ba6f0666bd0dbf10576cefe3a9) switched from DEPLOYING to RUNNING.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map (2/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (6/8)] [958] [INFO ] Source: Custom Source -> Map (6/8) (47e7b86af92271b4b0297616ee75ca48) switched from CREATED to DEPLOYING.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (5/8)] [958] [INFO ] Source: Custom Source -> Map (5/8) (1f46b21826165dcb07df975dc4cde4d0) switched from DEPLOYING to RUNNING.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Source: Custom Source -> Map (4/8) (d693d6543ba2be07b133e85296324b05) switched from DEPLOYING to RUNNING.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (6/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (6/8) (47e7b86af92271b4b0297616ee75ca48) [DEPLOYING]
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map (5/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Source: Custom Source -> Map (2/8) (3b2c7e8fb64fd9cd2b50b69682813417) switched from DEPLOYING to RUNNING.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (6/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map (6/8) (47e7b86af92271b4b0297616ee75ca48) [DEPLOYING].
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [587] [INFO ] Received task Source: Custom Source -> Map (7/8).
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Source: Custom Source -> Map (5/8) (1f46b21826165dcb07df975dc4cde4d0) switched from DEPLOYING to RUNNING.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (6/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map (6/8) (47e7b86af92271b4b0297616ee75ca48) [DEPLOYING].
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (6/8)] [958] [INFO ] Source: Custom Source -> Map (6/8) (47e7b86af92271b4b0297616ee75ca48) switched from DEPLOYING to RUNNING.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (7/8)] [958] [INFO ] Source: Custom Source -> Map (7/8) (8a8de52aad68586cdb8ee7483487f7e1) switched from CREATED to DEPLOYING.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map (6/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map (6/8) (47e7b86af92271b4b0297616ee75ca48) switched from DEPLOYING to RUNNING.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (7/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (7/8) (8a8de52aad68586cdb8ee7483487f7e1) [DEPLOYING]
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [587] [INFO ] Received task Source: Custom Source -> Map (8/8).
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (7/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map (7/8) (8a8de52aad68586cdb8ee7483487f7e1) [DEPLOYING].
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot 6bed53622bd0ddf269fb509fbef6eb8f.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (8/8)] [958] [INFO ] Source: Custom Source -> Map (8/8) (a8182faaa4f88c51ad7e248dba41c711) switched from CREATED to DEPLOYING.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot 41e9c0f2a062ded438d73c918a6ca805.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (7/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map (7/8) (8a8de52aad68586cdb8ee7483487f7e1) [DEPLOYING].
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (8/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map (8/8) (a8182faaa4f88c51ad7e248dba41c711) [DEPLOYING]
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot 7f1cf2119e836bfa3ef1656ec31f10d0.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (8/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map (8/8) (a8182faaa4f88c51ad7e248dba41c711) [DEPLOYING].
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot 0f918997db368befad3d760f135e0176.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot 68f6c0d37e1fca536f738f795c88428c.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot 1d66b2739e632587089c96a383cc7875.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (8/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map (8/8) (a8182faaa4f88c51ad7e248dba41c711) [DEPLOYING].
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot f5117734bbe4222a09ee4bc62413b3db.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (7/8)] [958] [INFO ] Source: Custom Source -> Map (7/8) (8a8de52aad68586cdb8ee7483487f7e1) switched from DEPLOYING to RUNNING.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-3] [237] [INFO ] Activate slot 13e39431be2e4e730e26a5b4bb2d158d.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map (7/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map (7/8) (8a8de52aad68586cdb8ee7483487f7e1) switched from DEPLOYING to RUNNING.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map (8/8)] [958] [INFO ] Source: Custom Source -> Map (8/8) (a8182faaa4f88c51ad7e248dba41c711) switched from DEPLOYING to RUNNING.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map (8/8) (a8182faaa4f88c51ad7e248dba41c711) switched from DEPLOYING to RUNNING.
[2019-11-28 00:42:25.025] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map (8/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:42:25.025] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (1/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:42:25.025] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (4/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:42:25.025] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (3/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:42:25.025] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (6/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:42:25.025] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (2/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:42:25.025] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (7/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:42:25.025] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (8/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:42:25.025] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (5/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:42:25.025] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (1/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:42:25.025] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (4/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:42:25.025] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (3/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:42:25.025] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (6/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:42:25.025] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (2/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:42:25.025] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (7/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:42:25.025] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (8/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:42:25.025] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map (5/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:42:25.025] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (3/8)] [886] [INFO ] Consumer subtask 2 has no restore state.
[2019-11-28 00:42:25.025] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (8/8)] [886] [INFO ] Consumer subtask 7 has no restore state.
[2019-11-28 00:42:25.025] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (5/8)] [886] [INFO ] Consumer subtask 4 has no restore state.
[2019-11-28 00:42:25.025] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (4/8)] [886] [INFO ] Consumer subtask 3 has no restore state.
[2019-11-28 00:42:25.025] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (6/8)] [886] [INFO ] Consumer subtask 5 has no restore state.
[2019-11-28 00:42:25.025] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (2/8)] [886] [INFO ] Consumer subtask 1 has no restore state.
[2019-11-28 00:42:25.025] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (1/8)] [886] [INFO ] Consumer subtask 0 has no restore state.
[2019-11-28 00:42:25.025] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (7/8)] [886] [INFO ] Consumer subtask 6 has no restore state.
[2019-11-28 00:42:25.025] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (4/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:42:25.025] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (3/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:42:25.025] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (6/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:42:25.025] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (1/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:42:25.025] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (7/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:42:25.025] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (2/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:42:25.025] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (8/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:42:25.025] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (5/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:42:25.025] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (4/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:42:25.025] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (2/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:42:25.025] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (1/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:42:25.025] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (7/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:42:25.025] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (8/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:42:25.025] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (3/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:42:25.025] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (4/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:42:25.025] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (6/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:42:25.025] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map (5/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:42:25.025] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (4/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:42:25.025] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (5/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:42:25.025] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (5/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:42:25.025] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (6/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:42:25.025] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (6/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:42:25.025] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (3/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:42:25.025] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (3/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:42:25.025] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (8/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:42:25.025] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (8/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:42:25.025] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (7/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:42:25.025] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (7/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:42:25.025] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (1/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:42:25.025] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (1/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:42:25.025] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (2/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:42:25.025] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map (2/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:42:25.025] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map (5/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:42:25.025] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map (6/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:42:25.025] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map (1/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:42:25.025] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map (4/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:42:25.025] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map (7/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:42:25.025] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map (3/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:42:25.025] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map (8/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:42:25.025] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map (2/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:42:25.025] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (1/8)] [651] [INFO ] Consumer subtask 0 initially has no partitions to read from.
[2019-11-28 00:42:25.025] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (6/8)] [651] [INFO ] Consumer subtask 5 initially has no partitions to read from.
[2019-11-28 00:42:25.025] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (3/8)] [651] [INFO ] Consumer subtask 2 initially has no partitions to read from.
[2019-11-28 00:42:25.025] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (4/8)] [651] [INFO ] Consumer subtask 3 initially has no partitions to read from.
[2019-11-28 00:42:25.025] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (7/8)] [651] [INFO ] Consumer subtask 6 initially has no partitions to read from.
[2019-11-28 00:42:25.025] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (2/8)] [651] [INFO ] Consumer subtask 1 initially has no partitions to read from.
[2019-11-28 00:42:25.025] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (5/8)] [610] [INFO ] Consumer subtask 4 will start reading the following 1 partitions from the latest offsets: [KafkaTopicPartition{topic='ota', partition=0}]
[2019-11-28 00:42:25.025] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map (8/8)] [651] [INFO ] Consumer subtask 7 initially has no partitions to read from.
[2019-11-28 00:42:25.025] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-13] [688] [INFO ] Consumer subtask 6 creating fetcher with offsets {}.
[2019-11-28 00:42:25.025] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-14] [688] [INFO ] Consumer subtask 7 creating fetcher with offsets {}.
[2019-11-28 00:42:25.025] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-9] [688] [INFO ] Consumer subtask 1 creating fetcher with offsets {}.
[2019-11-28 00:42:25.025] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-10] [688] [INFO ] Consumer subtask 3 creating fetcher with offsets {}.
[2019-11-28 00:42:25.025] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-11] [688] [INFO ] Consumer subtask 4 creating fetcher with offsets {KafkaTopicPartition{topic='ota', partition=0}=-915623761774}.
[2019-11-28 00:42:25.025] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-12] [688] [INFO ] Consumer subtask 5 creating fetcher with offsets {}.
[2019-11-28 00:42:25.025] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-8] [688] [INFO ] Consumer subtask 2 creating fetcher with offsets {}.
[2019-11-28 00:42:25.025] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-7] [688] [INFO ] Consumer subtask 0 creating fetcher with offsets {}.
[2019-11-28 00:42:25.025] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (4/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:42:25.025] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (8/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:42:25.025] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (3/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:42:25.025] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (1/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:42:25.025] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (6/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:42:25.025] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (2/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:42:25.025] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (5/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:42:25.025] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (7/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:42:25.025] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (3/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:42:25.025] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (3/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:42:25.025] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (3/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:42:25.025] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (6/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:42:25.025] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (6/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:42:25.025] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (6/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:42:25.025] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (8/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:42:25.025] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (8/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:42:25.025] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (8/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:42:25.025] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (5/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:42:25.025] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (7/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:42:25.025] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (7/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:42:25.025] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (7/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:42:25.025] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (5/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:42:25.025] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (4/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:42:25.025] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (5/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:42:25.025] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (2/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:42:25.025] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map (1/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:42:25.025] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (2/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:42:25.025] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (2/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:42:25.025] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (4/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:42:25.025] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (4/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:42:25.025] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (1/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:42:25.025] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map (1/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:42:25.025] [org.apache.kafka.clients.consumer.KafkaConsumer] [Kafka Fetcher for Source: Custom Source -> Map (5/8)] [1090] [INFO ] [Consumer clientId=consumer-15, groupId=test] Subscribed to partition(s): ota-0
[2019-11-28 00:42:25.025] [org.apache.kafka.clients.Metadata] [Kafka Fetcher for Source: Custom Source -> Map (5/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:42:25.025] [org.apache.kafka.clients.consumer.internals.Fetcher] [Kafka Fetcher for Source: Custom Source -> Map (5/8)] [584] [INFO ] [Consumer clientId=consumer-15, groupId=test] Resetting offset for partition ota-0 to offset 11.
[2019-11-28 00:42:30.030] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler] [Kafka Fetcher for Source: Custom Source -> Map (5/8)] [675] [INFO ] [Consumer clientId=consumer-15, groupId=test] Discovered group coordinator 192.168.1.14:9092 (id: 2147483647 rack: null)
[2019-11-28 00:42:51.051] [org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager] [TaskExecutorLocalStateStoresManager shutdown hook] [213] [INFO ] Shutting down TaskExecutorLocalStateStoresManager.
[2019-11-28 00:42:51.051] [org.apache.flink.runtime.blob.AbstractBlobCache] [PermanentBlobCache shutdown hook] [247] [INFO ] Shutting down BLOB cache
[2019-11-28 00:42:51.051] [org.apache.flink.runtime.blob.AbstractBlobCache] [TransientBlobCache shutdown hook] [247] [INFO ] Shutting down BLOB cache
[2019-11-28 00:42:51.051] [org.apache.flink.runtime.blob.BlobServer] [BlobServer shutdown hook] [340] [INFO ] Stopped BLOB server at 0.0.0.0:52884
[2019-11-28 00:42:51.051] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [IOManagerAsync shutdown hook] [112] [INFO ] FileChannelManager removed spill file directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-io-265d7bcd-00ad-4241-9df3-0b3c31d975b7
[2019-11-28 00:42:51.051] [org.apache.flink.runtime.filecache.FileCache] [FileCache shutdown hook] [153] [INFO ] removed file cache directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-dist-cache-77682a3a-1de4-447a-a597-5128c19f43b1
[2019-11-28 00:44:00.000] [org.apache.flink.api.java.typeutils.TypeExtractor] [main] [1815] [INFO ] class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a getter for field _children
[2019-11-28 00:44:00.000] [org.apache.flink.api.java.typeutils.TypeExtractor] [main] [1818] [INFO ] class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a setter for field _children
[2019-11-28 00:44:00.000] [org.apache.flink.api.java.typeutils.TypeExtractor] [main] [1857] [INFO ] Class class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:44:00.000] [org.apache.flink.streaming.api.environment.LocalStreamEnvironment] [main] [108] [INFO ] Running job on local embedded Flink mini cluster
[2019-11-28 00:44:00.000] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [254] [INFO ] Starting Flink Mini Cluster
[2019-11-28 00:44:00.000] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [263] [INFO ] Starting Metrics Registry
[2019-11-28 00:44:00.000] [org.apache.flink.runtime.metrics.MetricRegistryImpl] [main] [114] [INFO ] No metrics reporter configured, no metrics will be exposed/reported.
[2019-11-28 00:44:00.000] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [267] [INFO ] Starting RPC Service(s)
[2019-11-28 00:44:01.001] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1] [flink-akka.actor.default-dispatcher-3] [92] [INFO ] Slf4jLogger started
[2019-11-28 00:44:01.001] [org.apache.flink.runtime.clusterframework.BootstrapTools] [main] [244] [INFO ] Trying to start actor system at :0
[2019-11-28 00:44:01.001] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1] [flink-metrics-2] [92] [INFO ] Slf4jLogger started
[2019-11-28 00:44:01.001] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-2] [83] [INFO ] Starting remoting
[2019-11-28 00:44:01.001] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-2] [83] [INFO ] Remoting started; listening on addresses :[akka.tcp://flink-metrics@192.168.1.14:53093]
[2019-11-28 00:44:01.001] [org.apache.flink.runtime.clusterframework.BootstrapTools] [main] [256] [INFO ] Actor system started at akka.tcp://flink-metrics@192.168.1.14:53093
[2019-11-28 00:44:01.001] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
[2019-11-28 00:44:01.001] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [398] [INFO ] Starting high-availability services
[2019-11-28 00:44:01.001] [org.apache.flink.runtime.blob.BlobServer] [main] [141] [INFO ] Created BLOB server storage directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/blobStore-b509bb4e-17aa-4c00-bb75-c70839295103
[2019-11-28 00:44:01.001] [org.apache.flink.runtime.blob.BlobServer] [main] [203] [INFO ] Started BLOB server at 0.0.0.0:53094 - max concurrent requests: 50 - max backlog: 1000
[2019-11-28 00:44:01.001] [org.apache.flink.runtime.blob.AbstractBlobCache] [main] [107] [INFO ] Created BLOB cache storage directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/blobStore-bb489fe4-497f-4179-a61d-0ff160b78e37
[2019-11-28 00:44:01.001] [org.apache.flink.runtime.blob.AbstractBlobCache] [main] [107] [INFO ] Created BLOB cache storage directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/blobStore-26b26a85-3854-4c37-8c82-4d5451aabab2
[2019-11-28 00:44:01.001] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [480] [INFO ] Starting 1 TaskManger(s)
[2019-11-28 00:44:01.001] [org.apache.flink.runtime.taskexecutor.TaskManagerRunner] [main] [351] [INFO ] Starting TaskManager with ResourceID: bc1cdf60-150c-495b-9ce0-6a69cc3635d5
[2019-11-28 00:44:01.001] [org.apache.flink.runtime.taskexecutor.TaskManagerServices] [main] [519] [INFO ] Temporary file directory '/var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T': total 233 GB, usable 170 GB (72.96% usable)
[2019-11-28 00:44:01.001] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [main] [76] [INFO ] FileChannelManager uses directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-io-624b915e-2f82-492b-868f-e05150dc2c99 for spill files.
[2019-11-28 00:44:01.001] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [main] [76] [INFO ] FileChannelManager uses directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-netty-shuffle-6c976a2f-b622-4aaf-8c66-0a6afc20d36e for spill files.
[2019-11-28 00:44:01.001] [org.apache.flink.runtime.io.network.buffer.NetworkBufferPool] [main] [140] [INFO ] Allocated 202 MB for network buffer pool (number of memory segments: 6472, bytes per segment: 32768).
[2019-11-28 00:44:01.001] [org.apache.flink.runtime.io.network.NettyShuffleEnvironment] [main] [283] [INFO ] Starting the network environment and its components.
[2019-11-28 00:44:01.001] [org.apache.flink.runtime.taskexecutor.KvStateService] [main] [89] [INFO ] Starting the kvState service and its components.
[2019-11-28 00:44:01.001] [org.apache.flink.runtime.taskexecutor.TaskManagerServices] [main] [364] [INFO ] Limiting managed memory to 0.7 of the currently free heap space (1267 MB), memory will be allocated lazily.
[2019-11-28 00:44:01.001] [org.apache.flink.runtime.taskexecutor.TaskManagerConfiguration] [main] [197] [INFO ] Messages have a max timeout of 10000 ms
[2019-11-28 00:44:01.001] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
[2019-11-28 00:44:01.001] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-2] [125] [INFO ] Start job leader service.
[2019-11-28 00:44:01.001] [org.apache.flink.runtime.filecache.FileCache] [flink-akka.actor.default-dispatcher-2] [107] [INFO ] User file cache uses directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-dist-cache-924852e0-f9a8-4c82-a75c-9280ae95a7d6
[2019-11-28 00:44:01.001] [org.apache.flink.runtime.rest.RestServerEndpoint] [main] [136] [INFO ] Starting rest endpoint.
[2019-11-28 00:44:01.001] [org.apache.flink.runtime.webmonitor.WebMonitorUtils$LogFileLocation] [main] [87] [WARN ] Log file environment variable 'log.file' is not set.
[2019-11-28 00:44:01.001] [org.apache.flink.runtime.webmonitor.WebMonitorUtils$LogFileLocation] [main] [93] [WARN ] JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] [main] [114] [INFO ] Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.rest.RestServerEndpoint] [main] [233] [INFO ] Rest endpoint listening at localhost:53095
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [main] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@42b21d99 @ http://localhost:53095
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.webmonitor.WebMonitorEndpoint] [mini-cluster-io-thread-1] [711] [INFO ] http://localhost:53095 was granted leadership with leaderSessionID=3c20df6e-c3d8-4d31-8956-9dc71b396585
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [mini-cluster-io-thread-1] [250] [INFO ] Received confirmation of leadership for leader http://localhost:53095 , session=3c20df6e-c3d8-4d31-8956-9dc71b396585
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-3] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@28a937e2 @ akka://flink/user/resourcemanager
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-2] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@464f5bcc @ akka://flink/user/dispatcher
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-2] [885] [INFO ] Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token dba1c5c0-a0a6-44a7-a9de-1b558d1f7939
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [919] [INFO ] ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token 9b8cc55d62848f85ea48f1f32c914e0d
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [363] [INFO ] Flink Mini Cluster started successfully
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-4] [717] [INFO ] Recovering all persisted jobs.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl] [flink-akka.actor.default-dispatcher-3] [215] [INFO ] Starting the SlotManager.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-5] [250] [INFO ] Received confirmation of leadership for leader akka://flink/user/dispatcher , session=dba1c5c0-a0a6-44a7-a9de-1b558d1f7939
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-4] [250] [INFO ] Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=ea48f1f3-2c91-4e0d-9b8c-c55d62848f85
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [982] [INFO ] Connecting to ResourceManager akka://flink/user/resourcemanager(9b8cc55d62848f85ea48f1f32c914e0d).
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-2] [155] [INFO ] Resolved ResourceManager address, beginning registration
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-2] [204] [INFO ] Registration at ResourceManager attempt 1 (timeout=100ms)
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-4] [711] [INFO ] Registering TaskManager with ResourceID bc1cdf60-150c-495b-9ce0-6a69cc3635d5 (akka://flink/user/taskmanager_0) at ResourceManager
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.TaskExecutorToResourceManagerConnection] [flink-akka.actor.default-dispatcher-2] [100] [INFO ] Successful registration at resource manager akka://flink/user/resourcemanager under registration id 1a91df577eb4c54404aa3cba7cb50618.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-4] [264] [INFO ] Received JobGraph submission ee4d363f98df5a551119ef85534913fa (Flink Streaming Job).
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-4] [321] [INFO ] Submitting job ee4d363f98df5a551119ef85534913fa (Flink Streaming Job).
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [flink-akka.actor.default-dispatcher-2] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-2] [241] [INFO ] Initializing job Flink Streaming Job (ee4d363f98df5a551119ef85534913fa).
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.scheduler.LegacyScheduler] [flink-akka.actor.default-dispatcher-2] [171] [INFO ] Using restart strategy NoRestartStrategy for Flink Streaming Job (ee4d363f98df5a551119ef85534913fa).
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-2] [516] [INFO ] Job recovers via failover strategy: full graph restart
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.executiongraph.ExecutionGraphBuilder] [flink-akka.actor.default-dispatcher-2] [204] [INFO ] Running initialization on master for job Flink Streaming Job (ee4d363f98df5a551119ef85534913fa).
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.executiongraph.ExecutionGraphBuilder] [flink-akka.actor.default-dispatcher-2] [222] [INFO ] Successfully ran initialization on master in 0 ms.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.state.StateBackendLoader] [flink-akka.actor.default-dispatcher-2] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-2] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@56158944 @ akka://flink/user/jobmanager_1
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.jobmaster.JobManagerRunner] [mini-cluster-io-thread-3] [313] [INFO ] JobManager runner for job Flink Streaming Job (ee4d363f98df5a551119ef85534913fa) was granted leadership with session id c8e779c6-5c49-4ebc-b210-fe796be44918 at akka://flink/user/jobmanager_1.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-3] [709] [INFO ] Starting execution of job Flink Streaming Job (ee4d363f98df5a551119ef85534913fa) under job master id b210fe796be44918c8e779c65c494ebc.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-3] [1324] [INFO ] Job Flink Streaming Job (ee4d363f98df5a551119ef85534913fa) switched from state CREATED to RUNNING.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (eb259da6093b7957e803e67023fe180e) switched from CREATED to SCHEDULED.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-3] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{79e04fa6fb1d6a5653014730197a79b3}]
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (5c90474d0d36fb70ba67b38a02ad928d) switched from CREATED to SCHEDULED.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-3] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{63ce43bed1cfadefb8798c9e91e85a8e}]
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (df33b2018317f5db6ff14195c2bf34cf) switched from CREATED to SCHEDULED.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-3] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{d25c8b3525ad2cde1f67e522f854d6b1}]
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (02fd69580c072a20d6c9f4a916eb255c) switched from CREATED to SCHEDULED.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-3] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{e18fac40d4b1b968d5d0140c3c184392}]
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8) (8b23c8d42d9b3cb10b1010ede370d821) switched from CREATED to SCHEDULED.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-3] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{69d5767a4d0e2a03a1ba9869d50bba96}]
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (26c5fe03f2478f72480c5cdc2197d69a) switched from CREATED to SCHEDULED.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-3] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{51c4884e03f19725027944e7f4fd69bc}]
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (bbc197d59e7fc07bc0e332aae7b2662c) switched from CREATED to SCHEDULED.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-3] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{23599bc0d8e3ef53c24b10e5c61fc488}]
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (4d813725c9cdd11ca5c0b5030239b0d2) switched from CREATED to SCHEDULED.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-3] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{542bf669b5060d66cebddedb09b1a133}]
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [jobmanager-future-thread-1] [250] [INFO ] Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=c8e779c6-5c49-4ebc-b210-fe796be44918
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-3] [940] [INFO ] Connecting to ResourceManager akka://flink/user/resourcemanager(9b8cc55d62848f85ea48f1f32c914e0d)
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-3] [155] [INFO ] Resolved ResourceManager address, beginning registration
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-3] [204] [INFO ] Registration at ResourceManager attempt 1 (timeout=100ms)
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [302] [INFO ] Registering job manager b210fe796be44918c8e779c65c494ebc@akka://flink/user/jobmanager_1 for job ee4d363f98df5a551119ef85534913fa.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-4] [657] [INFO ] Registered job manager b210fe796be44918c8e779c65c494ebc@akka://flink/user/jobmanager_1 for job ee4d363f98df5a551119ef85534913fa.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-4] [962] [INFO ] JobManager successfully registered at ResourceManager, leader id: 9b8cc55d62848f85ea48f1f32c914e0d.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{79e04fa6fb1d6a5653014730197a79b3}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job ee4d363f98df5a551119ef85534913fa with allocation id 1a5e43e1a62493f05d75dda3575eac9e.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{63ce43bed1cfadefb8798c9e91e85a8e}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{d25c8b3525ad2cde1f67e522f854d6b1}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{e18fac40d4b1b968d5d0140c3c184392}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request 1a5e43e1a62493f05d75dda3575eac9e for job ee4d363f98df5a551119ef85534913fa from resource manager with leader id 9b8cc55d62848f85ea48f1f32c914e0d.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{69d5767a4d0e2a03a1ba9869d50bba96}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{51c4884e03f19725027944e7f4fd69bc}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job ee4d363f98df5a551119ef85534913fa with allocation id 519398aa9913bd1f98b033ea0f7f8e11.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{23599bc0d8e3ef53c24b10e5c61fc488}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for 1a5e43e1a62493f05d75dda3575eac9e.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job ee4d363f98df5a551119ef85534913fa with allocation id 0c700541837074be6f2550451360c5f7.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{542bf669b5060d66cebddedb09b1a133}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-2] [193] [INFO ] Add job ee4d363f98df5a551119ef85534913fa for job leader monitoring.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job ee4d363f98df5a551119ef85534913fa with allocation id ea35329f6b7f719a68a4b67140c6e560.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job ee4d363f98df5a551119ef85534913fa with allocation id 4f79082f8e1859ef23f41cc27aaceb43.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job ee4d363f98df5a551119ef85534913fa with allocation id fb7e15ec8708e5e8e3b7b657dac694a1.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request 519398aa9913bd1f98b033ea0f7f8e11 for job ee4d363f98df5a551119ef85534913fa from resource manager with leader id 9b8cc55d62848f85ea48f1f32c914e0d.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for 519398aa9913bd1f98b033ea0f7f8e11.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job ee4d363f98df5a551119ef85534913fa with allocation id 49e00baa142926660a586c8ed9150ae9.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-2] [193] [INFO ] Add job ee4d363f98df5a551119ef85534913fa for job leader monitoring.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-8] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id c8e779c6-5c49-4ebc-b210-fe796be44918.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-1] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id c8e779c6-5c49-4ebc-b210-fe796be44918.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request 0c700541837074be6f2550451360c5f7 for job ee4d363f98df5a551119ef85534913fa from resource manager with leader id 9b8cc55d62848f85ea48f1f32c914e0d.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job ee4d363f98df5a551119ef85534913fa with allocation id 1dbfd1aad5a6f4008f8fbbba8ead949e.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for 0c700541837074be6f2550451360c5f7.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-2] [193] [INFO ] Add job ee4d363f98df5a551119ef85534913fa for job leader monitoring.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request ea35329f6b7f719a68a4b67140c6e560 for job ee4d363f98df5a551119ef85534913fa from resource manager with leader id 9b8cc55d62848f85ea48f1f32c914e0d.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-5] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-6] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id c8e779c6-5c49-4ebc-b210-fe796be44918.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for ea35329f6b7f719a68a4b67140c6e560.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-2] [193] [INFO ] Add job ee4d363f98df5a551119ef85534913fa for job leader monitoring.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-7] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id c8e779c6-5c49-4ebc-b210-fe796be44918.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request 4f79082f8e1859ef23f41cc27aaceb43 for job ee4d363f98df5a551119ef85534913fa from resource manager with leader id 9b8cc55d62848f85ea48f1f32c914e0d.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-4] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for 4f79082f8e1859ef23f41cc27aaceb43.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-2] [193] [INFO ] Add job ee4d363f98df5a551119ef85534913fa for job leader monitoring.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-3] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-5] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id c8e779c6-5c49-4ebc-b210-fe796be44918.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request fb7e15ec8708e5e8e3b7b657dac694a1 for job ee4d363f98df5a551119ef85534913fa from resource manager with leader id 9b8cc55d62848f85ea48f1f32c914e0d.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for fb7e15ec8708e5e8e3b7b657dac694a1.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-2] [193] [INFO ] Add job ee4d363f98df5a551119ef85534913fa for job leader monitoring.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-4] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-3] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id c8e779c6-5c49-4ebc-b210-fe796be44918.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request 49e00baa142926660a586c8ed9150ae9 for job ee4d363f98df5a551119ef85534913fa from resource manager with leader id 9b8cc55d62848f85ea48f1f32c914e0d.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for 49e00baa142926660a586c8ed9150ae9.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-2] [193] [INFO ] Add job ee4d363f98df5a551119ef85534913fa for job leader monitoring.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-3] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-2] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id c8e779c6-5c49-4ebc-b210-fe796be44918.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request 1dbfd1aad5a6f4008f8fbbba8ead949e for job ee4d363f98df5a551119ef85534913fa from resource manager with leader id 9b8cc55d62848f85ea48f1f32c914e0d.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for 1dbfd1aad5a6f4008f8fbbba8ead949e.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-2] [193] [INFO ] Add job ee4d363f98df5a551119ef85534913fa for job leader monitoring.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-3] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-4] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id c8e779c6-5c49-4ebc-b210-fe796be44918.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService$NotifyOfLeaderCall] [mini-cluster-io-thread-8] [516] [WARN ] Error notifying leader listener about new leader
java.lang.IllegalStateException: The RPC connection is already closed
	at org.apache.flink.util.Preconditions.checkState(Preconditions.java:195) ~[flink-core-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.registration.RegisteredRpcConnection.start(RegisteredRpcConnection.java:90) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener.notifyLeaderAddress(JobLeaderService.java:334) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService$NotifyOfLeaderCall.run(EmbeddedLeaderService.java:513) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at java.util.concurrent.CompletableFuture$AsyncRun.run(CompletableFuture.java:1626) [na:1.8.0_131]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_131]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_131]
	at java.lang.Thread.run(Thread.java:748) [na:1.8.0_131]
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-2] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-2] [204] [INFO ] Registration at JobManager attempt 1 (timeout=100ms)
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener$JobManagerRegisteredRpcConnection] [flink-akka.actor.default-dispatcher-2] [382] [INFO ] Successful registration at job manager akka://flink/user/jobmanager_1 for job ee4d363f98df5a551119ef85534913fa.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [1220] [INFO ] Establish JobManager connection for job ee4d363f98df5a551119ef85534913fa.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [1121] [INFO ] Offer reserved slots to the leader of job ee4d363f98df5a551119ef85534913fa.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (eb259da6093b7957e803e67023fe180e) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [712] [INFO ] Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (attempt #0) to bc1cdf60-150c-495b-9ce0-6a69cc3635d5 @ localhost (dataPort=-1)
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (5c90474d0d36fb70ba67b38a02ad928d) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [712] [INFO ] Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (attempt #0) to bc1cdf60-150c-495b-9ce0-6a69cc3635d5 @ localhost (dataPort=-1)
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (df33b2018317f5db6ff14195c2bf34cf) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [712] [INFO ] Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (attempt #0) to bc1cdf60-150c-495b-9ce0-6a69cc3635d5 @ localhost (dataPort=-1)
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (02fd69580c072a20d6c9f4a916eb255c) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [712] [INFO ] Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (attempt #0) to bc1cdf60-150c-495b-9ce0-6a69cc3635d5 @ localhost (dataPort=-1)
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8) (8b23c8d42d9b3cb10b1010ede370d821) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [712] [INFO ] Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8) (attempt #0) to bc1cdf60-150c-495b-9ce0-6a69cc3635d5 @ localhost (dataPort=-1)
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (26c5fe03f2478f72480c5cdc2197d69a) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [712] [INFO ] Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (attempt #0) to bc1cdf60-150c-495b-9ce0-6a69cc3635d5 @ localhost (dataPort=-1)
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (bbc197d59e7fc07bc0e332aae7b2662c) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [712] [INFO ] Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (attempt #0) to bc1cdf60-150c-495b-9ce0-6a69cc3635d5 @ localhost (dataPort=-1)
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (4d813725c9cdd11ca5c0b5030239b0d2) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [712] [INFO ] Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (attempt #0) to bc1cdf60-150c-495b-9ce0-6a69cc3635d5 @ localhost (dataPort=-1)
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8).
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (eb259da6093b7957e803e67023fe180e) switched from CREATED to DEPLOYING.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (eb259da6093b7957e803e67023fe180e) [DEPLOYING]
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (eb259da6093b7957e803e67023fe180e) [DEPLOYING].
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (eb259da6093b7957e803e67023fe180e) [DEPLOYING].
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8).
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (5c90474d0d36fb70ba67b38a02ad928d) switched from CREATED to DEPLOYING.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (5c90474d0d36fb70ba67b38a02ad928d) [DEPLOYING]
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (5c90474d0d36fb70ba67b38a02ad928d) [DEPLOYING].
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (5c90474d0d36fb70ba67b38a02ad928d) [DEPLOYING].
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8).
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (df33b2018317f5db6ff14195c2bf34cf) switched from CREATED to DEPLOYING.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (df33b2018317f5db6ff14195c2bf34cf) [DEPLOYING]
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (df33b2018317f5db6ff14195c2bf34cf) [DEPLOYING].
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (df33b2018317f5db6ff14195c2bf34cf) [DEPLOYING].
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8).
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (02fd69580c072a20d6c9f4a916eb255c) switched from CREATED to DEPLOYING.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (02fd69580c072a20d6c9f4a916eb255c) [DEPLOYING]
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (02fd69580c072a20d6c9f4a916eb255c) [DEPLOYING].
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (02fd69580c072a20d6c9f4a916eb255c) [DEPLOYING].
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8).
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8) (8b23c8d42d9b3cb10b1010ede370d821) switched from CREATED to DEPLOYING.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8) (8b23c8d42d9b3cb10b1010ede370d821) [DEPLOYING]
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (df33b2018317f5db6ff14195c2bf34cf) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (eb259da6093b7957e803e67023fe180e) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (5c90474d0d36fb70ba67b38a02ad928d) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (02fd69580c072a20d6c9f4a916eb255c) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8) (8b23c8d42d9b3cb10b1010ede370d821) [DEPLOYING].
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (eb259da6093b7957e803e67023fe180e) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (df33b2018317f5db6ff14195c2bf34cf) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8) (8b23c8d42d9b3cb10b1010ede370d821) [DEPLOYING].
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8).
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (5c90474d0d36fb70ba67b38a02ad928d) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (26c5fe03f2478f72480c5cdc2197d69a) switched from CREATED to DEPLOYING.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (02fd69580c072a20d6c9f4a916eb255c) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (26c5fe03f2478f72480c5cdc2197d69a) [DEPLOYING]
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (26c5fe03f2478f72480c5cdc2197d69a) [DEPLOYING].
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8) (8b23c8d42d9b3cb10b1010ede370d821) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8) (8b23c8d42d9b3cb10b1010ede370d821) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (26c5fe03f2478f72480c5cdc2197d69a) [DEPLOYING].
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8).
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (26c5fe03f2478f72480c5cdc2197d69a) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (26c5fe03f2478f72480c5cdc2197d69a) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (bbc197d59e7fc07bc0e332aae7b2662c) switched from CREATED to DEPLOYING.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (bbc197d59e7fc07bc0e332aae7b2662c) [DEPLOYING]
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (bbc197d59e7fc07bc0e332aae7b2662c) [DEPLOYING].
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (bbc197d59e7fc07bc0e332aae7b2662c) [DEPLOYING].
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8).
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (bbc197d59e7fc07bc0e332aae7b2662c) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (bbc197d59e7fc07bc0e332aae7b2662c) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 519398aa9913bd1f98b033ea0f7f8e11.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (4d813725c9cdd11ca5c0b5030239b0d2) switched from CREATED to DEPLOYING.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot fb7e15ec8708e5e8e3b7b657dac694a1.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (4d813725c9cdd11ca5c0b5030239b0d2) [DEPLOYING]
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 1dbfd1aad5a6f4008f8fbbba8ead949e.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (4d813725c9cdd11ca5c0b5030239b0d2) [DEPLOYING].
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 0c700541837074be6f2550451360c5f7.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 4f79082f8e1859ef23f41cc27aaceb43.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot ea35329f6b7f719a68a4b67140c6e560.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 1a5e43e1a62493f05d75dda3575eac9e.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 49e00baa142926660a586c8ed9150ae9.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (4d813725c9cdd11ca5c0b5030239b0d2) [DEPLOYING].
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (4d813725c9cdd11ca5c0b5030239b0d2) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:44:02.002] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (4d813725c9cdd11ca5c0b5030239b0d2) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:02.002] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:44:02.002] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:44:02.002] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:44:02.002] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:44:02.002] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:44:02.002] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:44:02.002] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:44:02.002] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:44:02.002] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:44:02.002] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:44:02.002] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:44:02.002] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:44:02.002] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:44:02.002] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:44:02.002] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:44:02.002] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:44:02.002] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [886] [INFO ] Consumer subtask 1 has no restore state.
[2019-11-28 00:44:02.002] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [886] [INFO ] Consumer subtask 3 has no restore state.
[2019-11-28 00:44:02.002] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [886] [INFO ] Consumer subtask 7 has no restore state.
[2019-11-28 00:44:02.002] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [886] [INFO ] Consumer subtask 5 has no restore state.
[2019-11-28 00:44:02.002] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [886] [INFO ] Consumer subtask 0 has no restore state.
[2019-11-28 00:44:02.002] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [886] [INFO ] Consumer subtask 6 has no restore state.
[2019-11-28 00:44:02.002] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [886] [INFO ] Consumer subtask 4 has no restore state.
[2019-11-28 00:44:02.002] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [886] [INFO ] Consumer subtask 2 has no restore state.
[2019-11-28 00:44:02.002] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:02.002] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:02.002] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:02.002] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:02.002] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:02.002] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:02.002] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:02.002] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:02.002] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:02.002] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:02.002] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:02.002] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:02.002] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:02.002] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:02.002] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:02.002] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:02.002] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:02.002] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:02.002] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:02.002] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:02.002] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:02.002] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:02.002] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:02.002] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:02.002] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:02.002] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:02.002] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:02.002] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:02.002] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:02.002] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:02.002] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:02.002] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:02.002] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:44:02.002] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:44:02.002] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:44:02.002] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:44:02.002] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:44:02.002] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:44:02.002] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:44:02.002] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:44:02.002] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [651] [INFO ] Consumer subtask 0 initially has no partitions to read from.
[2019-11-28 00:44:02.002] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [651] [INFO ] Consumer subtask 2 initially has no partitions to read from.
[2019-11-28 00:44:02.002] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [651] [INFO ] Consumer subtask 3 initially has no partitions to read from.
[2019-11-28 00:44:02.002] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [651] [INFO ] Consumer subtask 5 initially has no partitions to read from.
[2019-11-28 00:44:02.002] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [651] [INFO ] Consumer subtask 6 initially has no partitions to read from.
[2019-11-28 00:44:02.002] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [651] [INFO ] Consumer subtask 7 initially has no partitions to read from.
[2019-11-28 00:44:02.002] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [651] [INFO ] Consumer subtask 1 initially has no partitions to read from.
[2019-11-28 00:44:02.002] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [610] [INFO ] Consumer subtask 4 will start reading the following 1 partitions from the latest offsets: [KafkaTopicPartition{topic='ota', partition=0}]
[2019-11-28 00:44:02.002] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-7] [688] [INFO ] Consumer subtask 0 creating fetcher with offsets {}.
[2019-11-28 00:44:02.002] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-8] [688] [INFO ] Consumer subtask 1 creating fetcher with offsets {}.
[2019-11-28 00:44:02.002] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-14] [688] [INFO ] Consumer subtask 7 creating fetcher with offsets {}.
[2019-11-28 00:44:02.002] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-12] [688] [INFO ] Consumer subtask 5 creating fetcher with offsets {}.
[2019-11-28 00:44:02.002] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-11] [688] [INFO ] Consumer subtask 4 creating fetcher with offsets {KafkaTopicPartition{topic='ota', partition=0}=-915623761774}.
[2019-11-28 00:44:02.002] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-10] [688] [INFO ] Consumer subtask 3 creating fetcher with offsets {}.
[2019-11-28 00:44:02.002] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-9] [688] [INFO ] Consumer subtask 2 creating fetcher with offsets {}.
[2019-11-28 00:44:02.002] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-13] [688] [INFO ] Consumer subtask 6 creating fetcher with offsets {}.
[2019-11-28 00:44:02.002] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:02.002] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:02.002] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:02.002] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:02.002] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:02.002] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:02.002] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:02.002] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:02.002] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:02.002] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:02.002] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:02.002] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:02.002] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:02.002] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:02.002] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:02.002] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:02.002] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:02.002] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:02.002] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:02.002] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:02.002] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:02.002] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:02.002] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:02.002] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:02.002] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:02.002] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:02.002] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:02.002] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:02.002] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:02.002] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:02.002] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:02.002] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:02.002] [org.apache.kafka.clients.consumer.KafkaConsumer] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [1090] [INFO ] [Consumer clientId=consumer-15, groupId=test] Subscribed to partition(s): ota-0
[2019-11-28 00:44:02.002] [org.apache.kafka.clients.Metadata] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:44:02.002] [org.apache.kafka.clients.consumer.internals.Fetcher] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [584] [INFO ] [Consumer clientId=consumer-15, groupId=test] Resetting offset for partition ota-0 to offset 11.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [960] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8) (8b23c8d42d9b3cb10b1010ede370d821) switched from RUNNING to FAILED.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException: No content to map due to end-of-input
 at [Source: (byte[])""; line: 1, column: 0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:212) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.performDefaultAction(SourceStreamTask.java:132) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:298) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:403) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) [flink-runtime_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) [flink-runtime_2.11-1.9.0.jar:1.9.0]
	at java.lang.Thread.run(Thread.java:748) [na:1.8.0_131]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException: No content to map due to end-of-input
 at [Source: (byte[])""; line: 1, column: 0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException.from(MismatchedInputException.java:59) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:4145) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4000) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:202) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [804] [INFO ] Freeing task resources for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8) (8b23c8d42d9b3cb10b1010ede370d821).
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8) (8b23c8d42d9b3cb10b1010ede370d821) [FAILED]
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [1438] [INFO ] Un-registering task and sending final execution state FAILED to JobManager for task Source: Custom Source -> Map -> Sink: Print to Std. Out 8b23c8d42d9b3cb10b1010ede370d821.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1493] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8) (8b23c8d42d9b3cb10b1010ede370d821) switched from RUNNING to FAILED.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException: No content to map due to end-of-input
 at [Source: (byte[])""; line: 1, column: 0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:212) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.performDefaultAction(SourceStreamTask.java:132) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:298) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:403) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_131]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException: No content to map due to end-of-input
 at [Source: (byte[])""; line: 1, column: 0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException.from(MismatchedInputException.java:59) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:4145) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4000) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:202) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-4] [1324] [INFO ] Job Flink Streaming Job (ee4d363f98df5a551119ef85534913fa) switched from state RUNNING to FAILING.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException: No content to map due to end-of-input
 at [Source: (byte[])""; line: 1, column: 0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:212) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.performDefaultAction(SourceStreamTask.java:132) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:298) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:403) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_131]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException: No content to map due to end-of-input
 at [Source: (byte[])""; line: 1, column: 0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException.from(MismatchedInputException.java:59) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:4145) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4000) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:202) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (eb259da6093b7957e803e67023fe180e) switched from RUNNING to CANCELING.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-2] [982] [INFO ] Attempting to cancel task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (eb259da6093b7957e803e67023fe180e).
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-2] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (eb259da6093b7957e803e67023fe180e) switched from RUNNING to CANCELING.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-2] [1031] [INFO ] Triggering cancellation of task code Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (eb259da6093b7957e803e67023fe180e).
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (5c90474d0d36fb70ba67b38a02ad928d) switched from RUNNING to CANCELING.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (df33b2018317f5db6ff14195c2bf34cf) switched from RUNNING to CANCELING.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (02fd69580c072a20d6c9f4a916eb255c) switched from RUNNING to CANCELING.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-2] [982] [INFO ] Attempting to cancel task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (5c90474d0d36fb70ba67b38a02ad928d).
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (26c5fe03f2478f72480c5cdc2197d69a) switched from RUNNING to CANCELING.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-2] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (5c90474d0d36fb70ba67b38a02ad928d) switched from RUNNING to CANCELING.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (bbc197d59e7fc07bc0e332aae7b2662c) switched from RUNNING to CANCELING.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-2] [1031] [INFO ] Triggering cancellation of task code Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (5c90474d0d36fb70ba67b38a02ad928d).
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (4d813725c9cdd11ca5c0b5030239b0d2) switched from RUNNING to CANCELING.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (eb259da6093b7957e803e67023fe180e) switched from CANCELING to CANCELED.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [804] [INFO ] Freeing task resources for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (eb259da6093b7957e803e67023fe180e).
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (eb259da6093b7957e803e67023fe180e) [CANCELED]
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-2] [982] [INFO ] Attempting to cancel task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (df33b2018317f5db6ff14195c2bf34cf).
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-2] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (df33b2018317f5db6ff14195c2bf34cf) switched from RUNNING to CANCELING.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-2] [1031] [INFO ] Triggering cancellation of task code Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (df33b2018317f5db6ff14195c2bf34cf).
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-2] [982] [INFO ] Attempting to cancel task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (02fd69580c072a20d6c9f4a916eb255c).
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-2] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (02fd69580c072a20d6c9f4a916eb255c) switched from RUNNING to CANCELING.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-2] [1031] [INFO ] Triggering cancellation of task code Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (02fd69580c072a20d6c9f4a916eb255c).
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-2] [982] [INFO ] Attempting to cancel task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (26c5fe03f2478f72480c5cdc2197d69a).
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-2] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (26c5fe03f2478f72480c5cdc2197d69a) switched from RUNNING to CANCELING.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-2] [1031] [INFO ] Triggering cancellation of task code Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (26c5fe03f2478f72480c5cdc2197d69a).
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-2] [982] [INFO ] Attempting to cancel task Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (bbc197d59e7fc07bc0e332aae7b2662c).
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-2] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (bbc197d59e7fc07bc0e332aae7b2662c) switched from RUNNING to CANCELING.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-2] [1031] [INFO ] Triggering cancellation of task code Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (bbc197d59e7fc07bc0e332aae7b2662c).
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-2] [982] [INFO ] Attempting to cancel task Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (4d813725c9cdd11ca5c0b5030239b0d2).
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-2] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (4d813725c9cdd11ca5c0b5030239b0d2) switched from RUNNING to CANCELING.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-2] [1031] [INFO ] Triggering cancellation of task code Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (4d813725c9cdd11ca5c0b5030239b0d2).
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map -> Sink: Print to Std. Out eb259da6093b7957e803e67023fe180e.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (5c90474d0d36fb70ba67b38a02ad928d) switched from CANCELING to CANCELED.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [804] [INFO ] Freeing task resources for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (5c90474d0d36fb70ba67b38a02ad928d).
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (5c90474d0d36fb70ba67b38a02ad928d) [CANCELED]
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (eb259da6093b7957e803e67023fe180e) switched from CANCELING to CANCELED.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map -> Sink: Print to Std. Out 5c90474d0d36fb70ba67b38a02ad928d.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-6] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (5c90474d0d36fb70ba67b38a02ad928d) switched from CANCELING to CANCELED.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (bbc197d59e7fc07bc0e332aae7b2662c) switched from CANCELING to CANCELED.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [804] [INFO ] Freeing task resources for Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (bbc197d59e7fc07bc0e332aae7b2662c).
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (bbc197d59e7fc07bc0e332aae7b2662c) [CANCELED]
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map -> Sink: Print to Std. Out bbc197d59e7fc07bc0e332aae7b2662c.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (02fd69580c072a20d6c9f4a916eb255c) switched from CANCELING to CANCELED.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (26c5fe03f2478f72480c5cdc2197d69a) switched from CANCELING to CANCELED.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-6] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (bbc197d59e7fc07bc0e332aae7b2662c) switched from CANCELING to CANCELED.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [804] [INFO ] Freeing task resources for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (02fd69580c072a20d6c9f4a916eb255c).
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [804] [INFO ] Freeing task resources for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (26c5fe03f2478f72480c5cdc2197d69a).
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (02fd69580c072a20d6c9f4a916eb255c) [CANCELED]
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (26c5fe03f2478f72480c5cdc2197d69a) [CANCELED]
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-6] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map -> Sink: Print to Std. Out 02fd69580c072a20d6c9f4a916eb255c.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (4d813725c9cdd11ca5c0b5030239b0d2) switched from CANCELING to CANCELED.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-6] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map -> Sink: Print to Std. Out 26c5fe03f2478f72480c5cdc2197d69a.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [804] [INFO ] Freeing task resources for Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (4d813725c9cdd11ca5c0b5030239b0d2).
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (df33b2018317f5db6ff14195c2bf34cf) switched from CANCELING to CANCELED.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (02fd69580c072a20d6c9f4a916eb255c) switched from CANCELING to CANCELED.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (4d813725c9cdd11ca5c0b5030239b0d2) [CANCELED]
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [804] [INFO ] Freeing task resources for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (df33b2018317f5db6ff14195c2bf34cf).
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-6] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map -> Sink: Print to Std. Out 4d813725c9cdd11ca5c0b5030239b0d2.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (df33b2018317f5db6ff14195c2bf34cf) [CANCELED]
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (26c5fe03f2478f72480c5cdc2197d69a) switched from CANCELING to CANCELED.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-6] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map -> Sink: Print to Std. Out df33b2018317f5db6ff14195c2bf34cf.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (4d813725c9cdd11ca5c0b5030239b0d2) switched from CANCELING to CANCELED.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (df33b2018317f5db6ff14195c2bf34cf) switched from CANCELING to CANCELED.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-5] [1446] [INFO ] Try to restart or fail the job Flink Streaming Job (ee4d363f98df5a551119ef85534913fa) if no longer possible.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-5] [1324] [INFO ] Job Flink Streaming Job (ee4d363f98df5a551119ef85534913fa) switched from state FAILING to FAILED.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException: No content to map due to end-of-input
 at [Source: (byte[])""; line: 1, column: 0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:212) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.performDefaultAction(SourceStreamTask.java:132) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:298) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:403) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_131]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException: No content to map due to end-of-input
 at [Source: (byte[])""; line: 1, column: 0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException.from(MismatchedInputException.java:59) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:4145) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4000) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:202) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-5] [1472] [INFO ] Could not restart the job Flink Streaming Job (ee4d363f98df5a551119ef85534913fa) because the restart strategy prevented it.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException: No content to map due to end-of-input
 at [Source: (byte[])""; line: 1, column: 0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:212) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.performDefaultAction(SourceStreamTask.java:132) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:298) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:403) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_131]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException: No content to map due to end-of-input
 at [Source: (byte[])""; line: 1, column: 0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.MismatchedInputException.from(MismatchedInputException.java:59) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:4145) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4000) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:202) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.checkpoint.CheckpointCoordinator] [flink-akka.actor.default-dispatcher-5] [329] [INFO ] Stopping checkpoint coordinator for job ee4d363f98df5a551119ef85534913fa.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore] [flink-akka.actor.default-dispatcher-5] [97] [INFO ] Shutting down
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-2] [775] [INFO ] Job ee4d363f98df5a551119ef85534913fa reached globally terminal state FAILED.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [417] [INFO ] Shutting down Flink Mini Cluster
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.rest.RestServerEndpoint] [main] [290] [INFO ] Shutting down rest endpoint.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-6] [334] [INFO ] Stopping TaskExecutor akka://flink/user/taskmanager_0.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-6] [142] [INFO ] Stop job leader service.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-5] [335] [INFO ] Stopping the JobMaster for job Flink Streaming Job(ee4d363f98df5a551119ef85534913fa).
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager] [flink-akka.actor.default-dispatcher-6] [213] [INFO ] Shutting down TaskExecutorLocalStateStoresManager.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [228] [INFO ] Suspending SlotPool.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-5] [1010] [INFO ] Close ResourceManager connection ab319a23bdcf3bb645f50a14c936b2cd: JobManager is shutting down..
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-5] [249] [INFO ] Stopping SlotPool.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-2] [774] [INFO ] Disconnect job manager b210fe796be44918c8e779c65c494ebc@akka://flink/user/jobmanager_1 for job ee4d363f98df5a551119ef85534913fa from the resource manager.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [flink-akka.actor.default-dispatcher-6] [112] [INFO ] FileChannelManager removed spill file directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-io-624b915e-2f82-492b-868f-e05150dc2c99
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.io.network.NettyShuffleEnvironment] [flink-akka.actor.default-dispatcher-6] [304] [INFO ] Shutting down the network environment and its components.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.webmonitor.WebMonitorEndpoint] [ForkJoinPool.commonPool-worker-1] [687] [INFO ] Removing cache directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-web-ui
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.rest.RestServerEndpoint] [ForkJoinPool.commonPool-worker-1] [299] [INFO ] Shut down complete.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [flink-akka.actor.default-dispatcher-6] [112] [INFO ] FileChannelManager removed spill file directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-netty-shuffle-6c976a2f-b622-4aaf-8c66-0a6afc20d36e
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskexecutor.KvStateService] [flink-akka.actor.default-dispatcher-6] [119] [INFO ] Shutting down the kvState service and its components.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-4] [499] [INFO ] Shut down cluster because application is in CANCELED, diagnostics DispatcherResourceManagerComponent has been closed..
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-6] [142] [INFO ] Stop job leader service.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-4] [220] [INFO ] Stopping dispatcher akka://flink/user/dispatcher.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl] [flink-akka.actor.default-dispatcher-2] [280] [INFO ] Closing the SlotManager.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.filecache.FileCache] [flink-akka.actor.default-dispatcher-6] [153] [INFO ] removed file cache directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-dist-cache-924852e0-f9a8-4c82-a75c-9280ae95a7d6
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-4] [697] [INFO ] Stopping all currently running jobs of dispatcher akka://flink/user/dispatcher.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl] [flink-akka.actor.default-dispatcher-2] [243] [INFO ] Suspending the SlotManager.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-6] [359] [INFO ] Stopped TaskExecutor akka://flink/user/taskmanager_0.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.rest.handler.legacy.backpressure.StackTraceSampleCoordinator] [flink-akka.actor.default-dispatcher-4] [220] [INFO ] Shutting down stack trace sample coordinator.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-4] [229] [INFO ] Stopped dispatcher akka://flink/user/dispatcher.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [flink-akka.actor.default-dispatcher-4] [335] [INFO ] Stopping Akka RPC service.
[2019-11-28 00:44:07.007] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-2] [83] [INFO ] Shutting down remote daemon.
[2019-11-28 00:44:07.007] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-2] [83] [INFO ] Remote daemon shut down; proceeding with flushing remote transports.
[2019-11-28 00:44:07.007] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-2] [83] [INFO ] Remoting shut down.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [flink-metrics-2] [335] [INFO ] Stopping Akka RPC service.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [flink-metrics-2] [354] [INFO ] Stopped Akka RPC service.
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.blob.AbstractBlobCache] [flink-akka.actor.default-dispatcher-4] [247] [INFO ] Shutting down BLOB cache
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.blob.AbstractBlobCache] [flink-akka.actor.default-dispatcher-4] [247] [INFO ] Shutting down BLOB cache
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.blob.BlobServer] [flink-akka.actor.default-dispatcher-4] [340] [INFO ] Stopped BLOB server at 0.0.0.0:53094
[2019-11-28 00:44:07.007] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [flink-akka.actor.default-dispatcher-4] [354] [INFO ] Stopped Akka RPC service.
[2019-11-28 00:44:07.007] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [675] [INFO ] [Consumer clientId=consumer-15, groupId=test] Discovered group coordinator 192.168.1.14:9092 (id: 2147483647 rack: null)
[2019-11-28 00:44:21.021] [org.apache.flink.api.java.typeutils.TypeExtractor] [main] [1815] [INFO ] class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a getter for field _children
[2019-11-28 00:44:21.021] [org.apache.flink.api.java.typeutils.TypeExtractor] [main] [1818] [INFO ] class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a setter for field _children
[2019-11-28 00:44:21.021] [org.apache.flink.api.java.typeutils.TypeExtractor] [main] [1857] [INFO ] Class class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:44:21.021] [org.apache.flink.streaming.api.environment.LocalStreamEnvironment] [main] [108] [INFO ] Running job on local embedded Flink mini cluster
[2019-11-28 00:44:21.021] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [254] [INFO ] Starting Flink Mini Cluster
[2019-11-28 00:44:21.021] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [263] [INFO ] Starting Metrics Registry
[2019-11-28 00:44:21.021] [org.apache.flink.runtime.metrics.MetricRegistryImpl] [main] [114] [INFO ] No metrics reporter configured, no metrics will be exposed/reported.
[2019-11-28 00:44:21.021] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [267] [INFO ] Starting RPC Service(s)
[2019-11-28 00:44:21.021] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1] [flink-akka.actor.default-dispatcher-3] [92] [INFO ] Slf4jLogger started
[2019-11-28 00:44:21.021] [org.apache.flink.runtime.clusterframework.BootstrapTools] [main] [244] [INFO ] Trying to start actor system at :0
[2019-11-28 00:44:21.021] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1] [flink-metrics-2] [92] [INFO ] Slf4jLogger started
[2019-11-28 00:44:21.021] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-2] [83] [INFO ] Starting remoting
[2019-11-28 00:44:21.021] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-2] [83] [INFO ] Remoting started; listening on addresses :[akka.tcp://flink-metrics@192.168.1.14:53116]
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.clusterframework.BootstrapTools] [main] [256] [INFO ] Actor system started at akka.tcp://flink-metrics@192.168.1.14:53116
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [398] [INFO ] Starting high-availability services
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.blob.BlobServer] [main] [141] [INFO ] Created BLOB server storage directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/blobStore-4cd61139-9dac-43d5-9e58-6c8b2ec16d3b
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.blob.BlobServer] [main] [203] [INFO ] Started BLOB server at 0.0.0.0:53117 - max concurrent requests: 50 - max backlog: 1000
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.blob.AbstractBlobCache] [main] [107] [INFO ] Created BLOB cache storage directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/blobStore-5d5ee6a7-48d4-4b48-b748-00c840b135d4
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.blob.AbstractBlobCache] [main] [107] [INFO ] Created BLOB cache storage directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/blobStore-84fa7268-5b30-401d-a7af-96014300f059
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [480] [INFO ] Starting 1 TaskManger(s)
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.TaskManagerRunner] [main] [351] [INFO ] Starting TaskManager with ResourceID: b856774f-4b0c-4e3f-b383-07f51eb59c9a
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.TaskManagerServices] [main] [519] [INFO ] Temporary file directory '/var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T': total 233 GB, usable 169 GB (72.53% usable)
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [main] [76] [INFO ] FileChannelManager uses directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-io-e400e5da-7ac0-4bdd-8cec-1af4f470a394 for spill files.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [main] [76] [INFO ] FileChannelManager uses directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-netty-shuffle-00b93a9f-6d1d-4c6c-910a-5931a437cfbb for spill files.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.io.network.buffer.NetworkBufferPool] [main] [140] [INFO ] Allocated 202 MB for network buffer pool (number of memory segments: 6472, bytes per segment: 32768).
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.io.network.NettyShuffleEnvironment] [main] [283] [INFO ] Starting the network environment and its components.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.KvStateService] [main] [89] [INFO ] Starting the kvState service and its components.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.TaskManagerServices] [main] [364] [INFO ] Limiting managed memory to 0.7 of the currently free heap space (1267 MB), memory will be allocated lazily.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.TaskManagerConfiguration] [main] [197] [INFO ] Messages have a max timeout of 10000 ms
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-2] [125] [INFO ] Start job leader service.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.filecache.FileCache] [flink-akka.actor.default-dispatcher-2] [107] [INFO ] User file cache uses directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-dist-cache-dbf10f2f-380f-470e-b0e6-774288969c68
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.rest.RestServerEndpoint] [main] [136] [INFO ] Starting rest endpoint.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.webmonitor.WebMonitorUtils$LogFileLocation] [main] [87] [WARN ] Log file environment variable 'log.file' is not set.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.webmonitor.WebMonitorUtils$LogFileLocation] [main] [93] [WARN ] JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] [main] [114] [INFO ] Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.rest.RestServerEndpoint] [main] [233] [INFO ] Rest endpoint listening at localhost:53118
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [main] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@42b21d99 @ http://localhost:53118
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.webmonitor.WebMonitorEndpoint] [mini-cluster-io-thread-1] [711] [INFO ] http://localhost:53118 was granted leadership with leaderSessionID=f43f2474-e3e8-4978-9eb2-5911a7cbb5e5
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [mini-cluster-io-thread-1] [250] [INFO ] Received confirmation of leadership for leader http://localhost:53118 , session=f43f2474-e3e8-4978-9eb2-5911a7cbb5e5
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-2] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@7693fe62 @ akka://flink/user/resourcemanager
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-3] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@41cb2288 @ akka://flink/user/dispatcher
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-3] [885] [INFO ] Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token a2c751f3-579d-4fcb-9dbc-6679e8ba247a
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-2] [919] [INFO ] ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token add4e2788d59be187f5697dc76a9436d
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [363] [INFO ] Flink Mini Cluster started successfully
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-4] [717] [INFO ] Recovering all persisted jobs.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl] [flink-akka.actor.default-dispatcher-2] [215] [INFO ] Starting the SlotManager.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-3] [250] [INFO ] Received confirmation of leadership for leader akka://flink/user/dispatcher , session=a2c751f3-579d-4fcb-9dbc-6679e8ba247a
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-4] [250] [INFO ] Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=7f5697dc-76a9-436d-add4-e2788d59be18
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [982] [INFO ] Connecting to ResourceManager akka://flink/user/resourcemanager(add4e2788d59be187f5697dc76a9436d).
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-4] [155] [INFO ] Resolved ResourceManager address, beginning registration
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-4] [204] [INFO ] Registration at ResourceManager attempt 1 (timeout=100ms)
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [711] [INFO ] Registering TaskManager with ResourceID b856774f-4b0c-4e3f-b383-07f51eb59c9a (akka://flink/user/taskmanager_0) at ResourceManager
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.TaskExecutorToResourceManagerConnection] [flink-akka.actor.default-dispatcher-4] [100] [INFO ] Successful registration at resource manager akka://flink/user/resourcemanager under registration id beb3352b8e9137fe30b71e28ec020e78.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-3] [264] [INFO ] Received JobGraph submission b494e0c8586cd374f4daf94e56b080ea (Flink Streaming Job).
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-3] [321] [INFO ] Submitting job b494e0c8586cd374f4daf94e56b080ea (Flink Streaming Job).
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [flink-akka.actor.default-dispatcher-4] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-4] [241] [INFO ] Initializing job Flink Streaming Job (b494e0c8586cd374f4daf94e56b080ea).
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.scheduler.LegacyScheduler] [flink-akka.actor.default-dispatcher-4] [171] [INFO ] Using restart strategy NoRestartStrategy for Flink Streaming Job (b494e0c8586cd374f4daf94e56b080ea).
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-4] [516] [INFO ] Job recovers via failover strategy: full graph restart
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.executiongraph.ExecutionGraphBuilder] [flink-akka.actor.default-dispatcher-4] [204] [INFO ] Running initialization on master for job Flink Streaming Job (b494e0c8586cd374f4daf94e56b080ea).
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.executiongraph.ExecutionGraphBuilder] [flink-akka.actor.default-dispatcher-4] [222] [INFO ] Successfully ran initialization on master in 0 ms.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.state.StateBackendLoader] [flink-akka.actor.default-dispatcher-4] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-4] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@ba2f03a @ akka://flink/user/jobmanager_1
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.jobmaster.JobManagerRunner] [mini-cluster-io-thread-3] [313] [INFO ] JobManager runner for job Flink Streaming Job (b494e0c8586cd374f4daf94e56b080ea) was granted leadership with session id 6cf9f41a-8f8e-457c-9106-ef05e117becf at akka://flink/user/jobmanager_1.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-2] [709] [INFO ] Starting execution of job Flink Streaming Job (b494e0c8586cd374f4daf94e56b080ea) under job master id 9106ef05e117becf6cf9f41a8f8e457c.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-2] [1324] [INFO ] Job Flink Streaming Job (b494e0c8586cd374f4daf94e56b080ea) switched from state CREATED to RUNNING.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (16ee0a2b93bc5dee8148e9426a78fe37) switched from CREATED to SCHEDULED.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{86ff61d2518193a189985dc01e5005d6}]
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (4e6246ab149f469d0a286a4b0ce3ef1e) switched from CREATED to SCHEDULED.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{8d493b2c0a42e528705395f9c01dd982}]
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (c52a42f18e1a0db0328dc0d681947ba3) switched from CREATED to SCHEDULED.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{40e84d40f01dc31e7bcbf431657056f4}]
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (5b200f7244da16752d1b91832fc8e8fb) switched from CREATED to SCHEDULED.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{4e6b7aff3160f5412e465b1d60775ad8}]
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8) (9570c081fb294ac4950018d915ac0725) switched from CREATED to SCHEDULED.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{ea4e71c2132f81c278670327b658cacc}]
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (35921e838cfa72504f1bd219144e4a5f) switched from CREATED to SCHEDULED.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{17f732021ace667def054105bfcde700}]
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (6e20b444ef932b409b25463ab79287dc) switched from CREATED to SCHEDULED.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{c4e8f83ac125cd7838a64677b3aea90d}]
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (c225dfa8c48457fdf18c473471dd49b4) switched from CREATED to SCHEDULED.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-2] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{ee62921c6440d89f8b41c95d48d1ac12}]
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [jobmanager-future-thread-1] [250] [INFO ] Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=6cf9f41a-8f8e-457c-9106-ef05e117becf
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-2] [940] [INFO ] Connecting to ResourceManager akka://flink/user/resourcemanager(add4e2788d59be187f5697dc76a9436d)
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-2] [155] [INFO ] Resolved ResourceManager address, beginning registration
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-2] [204] [INFO ] Registration at ResourceManager attempt 1 (timeout=100ms)
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-4] [302] [INFO ] Registering job manager 9106ef05e117becf6cf9f41a8f8e457c@akka://flink/user/jobmanager_1 for job b494e0c8586cd374f4daf94e56b080ea.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [657] [INFO ] Registered job manager 9106ef05e117becf6cf9f41a8f8e457c@akka://flink/user/jobmanager_1 for job b494e0c8586cd374f4daf94e56b080ea.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-4] [962] [INFO ] JobManager successfully registered at ResourceManager, leader id: add4e2788d59be187f5697dc76a9436d.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{86ff61d2518193a189985dc01e5005d6}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job b494e0c8586cd374f4daf94e56b080ea with allocation id 9885e630d6583a1e5a7c8bef141e9850.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{8d493b2c0a42e528705395f9c01dd982}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{40e84d40f01dc31e7bcbf431657056f4}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{4e6b7aff3160f5412e465b1d60775ad8}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{ea4e71c2132f81c278670327b658cacc}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request 9885e630d6583a1e5a7c8bef141e9850 for job b494e0c8586cd374f4daf94e56b080ea from resource manager with leader id add4e2788d59be187f5697dc76a9436d.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{17f732021ace667def054105bfcde700}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{c4e8f83ac125cd7838a64677b3aea90d}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{ee62921c6440d89f8b41c95d48d1ac12}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job b494e0c8586cd374f4daf94e56b080ea with allocation id bb806bf3076c60bdb13fbcf9849e5a15.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for 9885e630d6583a1e5a7c8bef141e9850.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-2] [193] [INFO ] Add job b494e0c8586cd374f4daf94e56b080ea for job leader monitoring.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job b494e0c8586cd374f4daf94e56b080ea with allocation id 7f36b52f13688ae827872bedbc267544.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job b494e0c8586cd374f4daf94e56b080ea with allocation id a1378cdae9e3b7d3815f4f2cf2dd3138.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request bb806bf3076c60bdb13fbcf9849e5a15 for job b494e0c8586cd374f4daf94e56b080ea from resource manager with leader id add4e2788d59be187f5697dc76a9436d.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for bb806bf3076c60bdb13fbcf9849e5a15.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-1] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 6cf9f41a-8f8e-457c-9106-ef05e117becf.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job b494e0c8586cd374f4daf94e56b080ea with allocation id b848e258fb6643be4d36898b16025a99.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-2] [193] [INFO ] Add job b494e0c8586cd374f4daf94e56b080ea for job leader monitoring.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-8] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 6cf9f41a-8f8e-457c-9106-ef05e117becf.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request 7f36b52f13688ae827872bedbc267544 for job b494e0c8586cd374f4daf94e56b080ea from resource manager with leader id add4e2788d59be187f5697dc76a9436d.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job b494e0c8586cd374f4daf94e56b080ea with allocation id c7af018fe45d274571c4991035ad84cd.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-5] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for 7f36b52f13688ae827872bedbc267544.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-4] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-2] [193] [INFO ] Add job b494e0c8586cd374f4daf94e56b080ea for job leader monitoring.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job b494e0c8586cd374f4daf94e56b080ea with allocation id d6eca956fa3157f6a233adfb94aa6ead.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-4] [204] [INFO ] Registration at JobManager attempt 1 (timeout=100ms)
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-5] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 6cf9f41a-8f8e-457c-9106-ef05e117becf.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request a1378cdae9e3b7d3815f4f2cf2dd3138 for job b494e0c8586cd374f4daf94e56b080ea from resource manager with leader id add4e2788d59be187f5697dc76a9436d.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job b494e0c8586cd374f4daf94e56b080ea with allocation id a303a419bc1c1e2425156e0a7a6a7e7b.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for a1378cdae9e3b7d3815f4f2cf2dd3138.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-2] [193] [INFO ] Add job b494e0c8586cd374f4daf94e56b080ea for job leader monitoring.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-7] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 6cf9f41a-8f8e-457c-9106-ef05e117becf.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request b848e258fb6643be4d36898b16025a99 for job b494e0c8586cd374f4daf94e56b080ea from resource manager with leader id add4e2788d59be187f5697dc76a9436d.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for b848e258fb6643be4d36898b16025a99.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-3] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-2] [193] [INFO ] Add job b494e0c8586cd374f4daf94e56b080ea for job leader monitoring.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-5] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-6] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 6cf9f41a-8f8e-457c-9106-ef05e117becf.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request c7af018fe45d274571c4991035ad84cd for job b494e0c8586cd374f4daf94e56b080ea from resource manager with leader id add4e2788d59be187f5697dc76a9436d.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for c7af018fe45d274571c4991035ad84cd.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-2] [193] [INFO ] Add job b494e0c8586cd374f4daf94e56b080ea for job leader monitoring.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-5] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-3] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 6cf9f41a-8f8e-457c-9106-ef05e117becf.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request d6eca956fa3157f6a233adfb94aa6ead for job b494e0c8586cd374f4daf94e56b080ea from resource manager with leader id add4e2788d59be187f5697dc76a9436d.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for d6eca956fa3157f6a233adfb94aa6ead.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-2] [193] [INFO ] Add job b494e0c8586cd374f4daf94e56b080ea for job leader monitoring.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-3] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-2] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 6cf9f41a-8f8e-457c-9106-ef05e117becf.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [816] [INFO ] Receive slot request a303a419bc1c1e2425156e0a7a6a7e7b for job b494e0c8586cd374f4daf94e56b080ea from resource manager with leader id add4e2788d59be187f5697dc76a9436d.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [828] [INFO ] Allocated slot for a303a419bc1c1e2425156e0a7a6a7e7b.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-2] [193] [INFO ] Add job b494e0c8586cd374f4daf94e56b080ea for job leader monitoring.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-5] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-4] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 6cf9f41a-8f8e-457c-9106-ef05e117becf.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-2] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-2] [204] [INFO ] Registration at JobManager attempt 1 (timeout=100ms)
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener$JobManagerRegisteredRpcConnection] [flink-akka.actor.default-dispatcher-2] [382] [INFO ] Successful registration at job manager akka://flink/user/jobmanager_1 for job b494e0c8586cd374f4daf94e56b080ea.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [1220] [INFO ] Establish JobManager connection for job b494e0c8586cd374f4daf94e56b080ea.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [1121] [INFO ] Offer reserved slots to the leader of job b494e0c8586cd374f4daf94e56b080ea.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (16ee0a2b93bc5dee8148e9426a78fe37) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (attempt #0) to b856774f-4b0c-4e3f-b383-07f51eb59c9a @ localhost (dataPort=-1)
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (4e6246ab149f469d0a286a4b0ce3ef1e) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (attempt #0) to b856774f-4b0c-4e3f-b383-07f51eb59c9a @ localhost (dataPort=-1)
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (c52a42f18e1a0db0328dc0d681947ba3) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (attempt #0) to b856774f-4b0c-4e3f-b383-07f51eb59c9a @ localhost (dataPort=-1)
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (5b200f7244da16752d1b91832fc8e8fb) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (attempt #0) to b856774f-4b0c-4e3f-b383-07f51eb59c9a @ localhost (dataPort=-1)
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8) (9570c081fb294ac4950018d915ac0725) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8) (attempt #0) to b856774f-4b0c-4e3f-b383-07f51eb59c9a @ localhost (dataPort=-1)
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (35921e838cfa72504f1bd219144e4a5f) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (attempt #0) to b856774f-4b0c-4e3f-b383-07f51eb59c9a @ localhost (dataPort=-1)
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (6e20b444ef932b409b25463ab79287dc) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (attempt #0) to b856774f-4b0c-4e3f-b383-07f51eb59c9a @ localhost (dataPort=-1)
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (c225dfa8c48457fdf18c473471dd49b4) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [712] [INFO ] Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (attempt #0) to b856774f-4b0c-4e3f-b383-07f51eb59c9a @ localhost (dataPort=-1)
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8).
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (16ee0a2b93bc5dee8148e9426a78fe37) switched from CREATED to DEPLOYING.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (16ee0a2b93bc5dee8148e9426a78fe37) [DEPLOYING]
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (16ee0a2b93bc5dee8148e9426a78fe37) [DEPLOYING].
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (16ee0a2b93bc5dee8148e9426a78fe37) [DEPLOYING].
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8).
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (4e6246ab149f469d0a286a4b0ce3ef1e) switched from CREATED to DEPLOYING.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (4e6246ab149f469d0a286a4b0ce3ef1e) [DEPLOYING]
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (4e6246ab149f469d0a286a4b0ce3ef1e) [DEPLOYING].
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (4e6246ab149f469d0a286a4b0ce3ef1e) [DEPLOYING].
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8).
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (c52a42f18e1a0db0328dc0d681947ba3) switched from CREATED to DEPLOYING.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (c52a42f18e1a0db0328dc0d681947ba3) [DEPLOYING]
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (c52a42f18e1a0db0328dc0d681947ba3) [DEPLOYING].
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (c52a42f18e1a0db0328dc0d681947ba3) [DEPLOYING].
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8).
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (5b200f7244da16752d1b91832fc8e8fb) switched from CREATED to DEPLOYING.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (5b200f7244da16752d1b91832fc8e8fb) [DEPLOYING]
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (5b200f7244da16752d1b91832fc8e8fb) [DEPLOYING].
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (5b200f7244da16752d1b91832fc8e8fb) [DEPLOYING].
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8).
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8) (9570c081fb294ac4950018d915ac0725) switched from CREATED to DEPLOYING.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (c52a42f18e1a0db0328dc0d681947ba3) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (5b200f7244da16752d1b91832fc8e8fb) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (16ee0a2b93bc5dee8148e9426a78fe37) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8) (9570c081fb294ac4950018d915ac0725) [DEPLOYING]
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (4e6246ab149f469d0a286a4b0ce3ef1e) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (c52a42f18e1a0db0328dc0d681947ba3) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8) (9570c081fb294ac4950018d915ac0725) [DEPLOYING].
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (5b200f7244da16752d1b91832fc8e8fb) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (16ee0a2b93bc5dee8148e9426a78fe37) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8) (9570c081fb294ac4950018d915ac0725) [DEPLOYING].
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (4e6246ab149f469d0a286a4b0ce3ef1e) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8).
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (35921e838cfa72504f1bd219144e4a5f) switched from CREATED to DEPLOYING.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (35921e838cfa72504f1bd219144e4a5f) [DEPLOYING]
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8) (9570c081fb294ac4950018d915ac0725) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (35921e838cfa72504f1bd219144e4a5f) [DEPLOYING].
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8) (9570c081fb294ac4950018d915ac0725) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (35921e838cfa72504f1bd219144e4a5f) [DEPLOYING].
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8).
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (35921e838cfa72504f1bd219144e4a5f) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (6e20b444ef932b409b25463ab79287dc) switched from CREATED to DEPLOYING.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (35921e838cfa72504f1bd219144e4a5f) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (6e20b444ef932b409b25463ab79287dc) [DEPLOYING]
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8).
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (6e20b444ef932b409b25463ab79287dc) [DEPLOYING].
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (c225dfa8c48457fdf18c473471dd49b4) switched from CREATED to DEPLOYING.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 7f36b52f13688ae827872bedbc267544.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (c225dfa8c48457fdf18c473471dd49b4) [DEPLOYING]
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot d6eca956fa3157f6a233adfb94aa6ead.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (6e20b444ef932b409b25463ab79287dc) [DEPLOYING].
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (c225dfa8c48457fdf18c473471dd49b4) [DEPLOYING].
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot a1378cdae9e3b7d3815f4f2cf2dd3138.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot c7af018fe45d274571c4991035ad84cd.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (6e20b444ef932b409b25463ab79287dc) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot a303a419bc1c1e2425156e0a7a6a7e7b.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (c225dfa8c48457fdf18c473471dd49b4) [DEPLOYING].
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (6e20b444ef932b409b25463ab79287dc) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 9885e630d6583a1e5a7c8bef141e9850.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot b848e258fb6643be4d36898b16025a99.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot bb806bf3076c60bdb13fbcf9849e5a15.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (c225dfa8c48457fdf18c473471dd49b4) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:44:22.022] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (c225dfa8c48457fdf18c473471dd49b4) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:22.022] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:44:22.022] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:44:22.022] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:44:22.022] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:44:22.022] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:44:22.022] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:44:22.022] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:44:22.022] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:44:22.022] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:44:22.022] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:44:22.022] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:44:22.022] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:44:22.022] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:44:22.022] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:44:22.022] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:44:22.022] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:44:22.022] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [886] [INFO ] Consumer subtask 6 has no restore state.
[2019-11-28 00:44:22.022] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [886] [INFO ] Consumer subtask 5 has no restore state.
[2019-11-28 00:44:22.022] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [886] [INFO ] Consumer subtask 1 has no restore state.
[2019-11-28 00:44:22.022] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [886] [INFO ] Consumer subtask 7 has no restore state.
[2019-11-28 00:44:22.022] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [886] [INFO ] Consumer subtask 3 has no restore state.
[2019-11-28 00:44:22.022] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [886] [INFO ] Consumer subtask 4 has no restore state.
[2019-11-28 00:44:22.022] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [886] [INFO ] Consumer subtask 2 has no restore state.
[2019-11-28 00:44:22.022] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [886] [INFO ] Consumer subtask 0 has no restore state.
[2019-11-28 00:44:22.022] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:22.022] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:22.022] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:22.022] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:22.022] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:22.022] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:22.022] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:22.022] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:22.022] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:22.022] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:22.022] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:22.022] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:22.022] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:22.022] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:22.022] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:22.022] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:22.022] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:22.022] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:22.022] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:22.022] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:22.022] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:22.022] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:22.022] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:22.022] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:22.022] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:22.022] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:22.022] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:22.022] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:22.022] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:22.022] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:22.022] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:22.022] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:23.023] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:44:23.023] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:44:23.023] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:44:23.023] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:44:23.023] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:44:23.023] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:44:23.023] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:44:23.023] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:44:23.023] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [651] [INFO ] Consumer subtask 5 initially has no partitions to read from.
[2019-11-28 00:44:23.023] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [651] [INFO ] Consumer subtask 1 initially has no partitions to read from.
[2019-11-28 00:44:23.023] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [610] [INFO ] Consumer subtask 4 will start reading the following 1 partitions from the latest offsets: [KafkaTopicPartition{topic='ota', partition=0}]
[2019-11-28 00:44:23.023] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [651] [INFO ] Consumer subtask 0 initially has no partitions to read from.
[2019-11-28 00:44:23.023] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [651] [INFO ] Consumer subtask 7 initially has no partitions to read from.
[2019-11-28 00:44:23.023] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [651] [INFO ] Consumer subtask 3 initially has no partitions to read from.
[2019-11-28 00:44:23.023] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [651] [INFO ] Consumer subtask 2 initially has no partitions to read from.
[2019-11-28 00:44:23.023] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [651] [INFO ] Consumer subtask 6 initially has no partitions to read from.
[2019-11-28 00:44:23.023] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-13] [688] [INFO ] Consumer subtask 6 creating fetcher with offsets {}.
[2019-11-28 00:44:23.023] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-10] [688] [INFO ] Consumer subtask 1 creating fetcher with offsets {}.
[2019-11-28 00:44:23.023] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-8] [688] [INFO ] Consumer subtask 3 creating fetcher with offsets {}.
[2019-11-28 00:44:23.023] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-9] [688] [INFO ] Consumer subtask 0 creating fetcher with offsets {}.
[2019-11-28 00:44:23.023] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-14] [688] [INFO ] Consumer subtask 7 creating fetcher with offsets {}.
[2019-11-28 00:44:23.023] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-12] [688] [INFO ] Consumer subtask 5 creating fetcher with offsets {}.
[2019-11-28 00:44:23.023] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-7] [688] [INFO ] Consumer subtask 2 creating fetcher with offsets {}.
[2019-11-28 00:44:23.023] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-11] [688] [INFO ] Consumer subtask 4 creating fetcher with offsets {KafkaTopicPartition{topic='ota', partition=0}=-915623761774}.
[2019-11-28 00:44:23.023] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:23.023] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:23.023] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:23.023] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:23.023] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:23.023] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:23.023] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:23.023] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:23.023] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:23.023] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:23.023] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:23.023] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:23.023] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:23.023] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:23.023] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:23.023] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:23.023] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:23.023] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:23.023] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:23.023] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:23.023] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:23.023] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:23.023] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:23.023] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:23.023] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:23.023] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:23.023] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:23.023] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:23.023] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:23.023] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:23.023] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:23.023] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:23.023] [org.apache.kafka.clients.consumer.KafkaConsumer] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [1090] [INFO ] [Consumer clientId=consumer-13, groupId=test] Subscribed to partition(s): ota-0
[2019-11-28 00:44:23.023] [org.apache.kafka.clients.Metadata] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:44:23.023] [org.apache.kafka.clients.consumer.internals.Fetcher] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [584] [INFO ] [Consumer clientId=consumer-13, groupId=test] Resetting offset for partition ota-0 to offset 12.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [960] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8) (9570c081fb294ac4950018d915ac0725) switched from RUNNING to FAILED.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unexpected character ('<' (code 60)): expected a valid value (number, String, array, object, 'true', 'false' or 'null')
 at [Source: (byte[])"<dependency>"; line: 1, column: 2]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:212) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.performDefaultAction(SourceStreamTask.java:132) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:298) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:403) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) [flink-runtime_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) [flink-runtime_2.11-1.9.0.jar:1.9.0]
	at java.lang.Thread.run(Thread.java:748) [na:1.8.0_131]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unexpected character ('<' (code 60)): expected a valid value (number, String, array, object, 'true', 'false' or 'null')
 at [Source: (byte[])"<dependency>"; line: 1, column: 2]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1804) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:693) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportUnexpectedChar(ParserMinimalBase.java:591) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser._handleUnexpectedValue(UTF8StreamJsonParser.java:2630) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser._nextTokenNotInObject(UTF8StreamJsonParser.java:832) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextToken(UTF8StreamJsonParser.java:729) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:4141) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4000) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:202) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [804] [INFO ] Freeing task resources for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8) (9570c081fb294ac4950018d915ac0725).
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8) (9570c081fb294ac4950018d915ac0725) [FAILED]
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [1438] [INFO ] Un-registering task and sending final execution state FAILED to JobManager for task Source: Custom Source -> Map -> Sink: Print to Std. Out 9570c081fb294ac4950018d915ac0725.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1493] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8) (9570c081fb294ac4950018d915ac0725) switched from RUNNING to FAILED.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unexpected character ('<' (code 60)): expected a valid value (number, String, array, object, 'true', 'false' or 'null')
 at [Source: (byte[])"<dependency>"; line: 1, column: 2]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:212) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.performDefaultAction(SourceStreamTask.java:132) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:298) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:403) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_131]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unexpected character ('<' (code 60)): expected a valid value (number, String, array, object, 'true', 'false' or 'null')
 at [Source: (byte[])"<dependency>"; line: 1, column: 2]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1804) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:693) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportUnexpectedChar(ParserMinimalBase.java:591) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser._handleUnexpectedValue(UTF8StreamJsonParser.java:2630) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser._nextTokenNotInObject(UTF8StreamJsonParser.java:832) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextToken(UTF8StreamJsonParser.java:729) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:4141) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4000) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:202) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-2] [1324] [INFO ] Job Flink Streaming Job (b494e0c8586cd374f4daf94e56b080ea) switched from state RUNNING to FAILING.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unexpected character ('<' (code 60)): expected a valid value (number, String, array, object, 'true', 'false' or 'null')
 at [Source: (byte[])"<dependency>"; line: 1, column: 2]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:212) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.performDefaultAction(SourceStreamTask.java:132) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:298) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:403) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_131]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unexpected character ('<' (code 60)): expected a valid value (number, String, array, object, 'true', 'false' or 'null')
 at [Source: (byte[])"<dependency>"; line: 1, column: 2]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1804) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:693) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportUnexpectedChar(ParserMinimalBase.java:591) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser._handleUnexpectedValue(UTF8StreamJsonParser.java:2630) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser._nextTokenNotInObject(UTF8StreamJsonParser.java:832) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextToken(UTF8StreamJsonParser.java:729) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:4141) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4000) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:202) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (16ee0a2b93bc5dee8148e9426a78fe37) switched from RUNNING to CANCELING.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-4] [982] [INFO ] Attempting to cancel task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (16ee0a2b93bc5dee8148e9426a78fe37).
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-4] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (16ee0a2b93bc5dee8148e9426a78fe37) switched from RUNNING to CANCELING.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-4] [1031] [INFO ] Triggering cancellation of task code Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (16ee0a2b93bc5dee8148e9426a78fe37).
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (4e6246ab149f469d0a286a4b0ce3ef1e) switched from RUNNING to CANCELING.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (c52a42f18e1a0db0328dc0d681947ba3) switched from RUNNING to CANCELING.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (5b200f7244da16752d1b91832fc8e8fb) switched from RUNNING to CANCELING.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-4] [982] [INFO ] Attempting to cancel task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (4e6246ab149f469d0a286a4b0ce3ef1e).
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (35921e838cfa72504f1bd219144e4a5f) switched from RUNNING to CANCELING.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-4] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (4e6246ab149f469d0a286a4b0ce3ef1e) switched from RUNNING to CANCELING.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (6e20b444ef932b409b25463ab79287dc) switched from RUNNING to CANCELING.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-4] [1031] [INFO ] Triggering cancellation of task code Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (4e6246ab149f469d0a286a4b0ce3ef1e).
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (c225dfa8c48457fdf18c473471dd49b4) switched from RUNNING to CANCELING.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-4] [982] [INFO ] Attempting to cancel task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (c52a42f18e1a0db0328dc0d681947ba3).
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-4] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (c52a42f18e1a0db0328dc0d681947ba3) switched from RUNNING to CANCELING.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-4] [1031] [INFO ] Triggering cancellation of task code Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (c52a42f18e1a0db0328dc0d681947ba3).
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (16ee0a2b93bc5dee8148e9426a78fe37) switched from CANCELING to CANCELED.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [804] [INFO ] Freeing task resources for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (16ee0a2b93bc5dee8148e9426a78fe37).
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (16ee0a2b93bc5dee8148e9426a78fe37) [CANCELED]
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-4] [982] [INFO ] Attempting to cancel task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (5b200f7244da16752d1b91832fc8e8fb).
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-4] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (5b200f7244da16752d1b91832fc8e8fb) switched from RUNNING to CANCELING.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-4] [1031] [INFO ] Triggering cancellation of task code Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (5b200f7244da16752d1b91832fc8e8fb).
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-4] [982] [INFO ] Attempting to cancel task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (35921e838cfa72504f1bd219144e4a5f).
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-4] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (35921e838cfa72504f1bd219144e4a5f) switched from RUNNING to CANCELING.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-4] [1031] [INFO ] Triggering cancellation of task code Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (35921e838cfa72504f1bd219144e4a5f).
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-4] [982] [INFO ] Attempting to cancel task Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (6e20b444ef932b409b25463ab79287dc).
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-4] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (6e20b444ef932b409b25463ab79287dc) switched from RUNNING to CANCELING.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-4] [1031] [INFO ] Triggering cancellation of task code Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (6e20b444ef932b409b25463ab79287dc).
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-4] [982] [INFO ] Attempting to cancel task Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (c225dfa8c48457fdf18c473471dd49b4).
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-4] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (c225dfa8c48457fdf18c473471dd49b4) switched from RUNNING to CANCELING.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [flink-akka.actor.default-dispatcher-4] [1031] [INFO ] Triggering cancellation of task code Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (c225dfa8c48457fdf18c473471dd49b4).
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map -> Sink: Print to Std. Out 16ee0a2b93bc5dee8148e9426a78fe37.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-6] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (16ee0a2b93bc5dee8148e9426a78fe37) switched from CANCELING to CANCELED.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (4e6246ab149f469d0a286a4b0ce3ef1e) switched from CANCELING to CANCELED.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [804] [INFO ] Freeing task resources for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (4e6246ab149f469d0a286a4b0ce3ef1e).
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (4e6246ab149f469d0a286a4b0ce3ef1e) [CANCELED]
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (5b200f7244da16752d1b91832fc8e8fb) switched from CANCELING to CANCELED.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [804] [INFO ] Freeing task resources for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (5b200f7244da16752d1b91832fc8e8fb).
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map -> Sink: Print to Std. Out 4e6246ab149f469d0a286a4b0ce3ef1e.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (5b200f7244da16752d1b91832fc8e8fb) [CANCELED]
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map -> Sink: Print to Std. Out 5b200f7244da16752d1b91832fc8e8fb.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (c52a42f18e1a0db0328dc0d681947ba3) switched from CANCELING to CANCELED.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [804] [INFO ] Freeing task resources for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (c52a42f18e1a0db0328dc0d681947ba3).
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-6] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (4e6246ab149f469d0a286a4b0ce3ef1e) switched from CANCELING to CANCELED.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (c52a42f18e1a0db0328dc0d681947ba3) [CANCELED]
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (6e20b444ef932b409b25463ab79287dc) switched from CANCELING to CANCELED.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [804] [INFO ] Freeing task resources for Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (6e20b444ef932b409b25463ab79287dc).
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (6e20b444ef932b409b25463ab79287dc) [CANCELED]
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map -> Sink: Print to Std. Out c52a42f18e1a0db0328dc0d681947ba3.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (c225dfa8c48457fdf18c473471dd49b4) switched from CANCELING to CANCELED.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-6] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (5b200f7244da16752d1b91832fc8e8fb) switched from CANCELING to CANCELED.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map -> Sink: Print to Std. Out 6e20b444ef932b409b25463ab79287dc.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (35921e838cfa72504f1bd219144e4a5f) switched from CANCELING to CANCELED.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [804] [INFO ] Freeing task resources for Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (c225dfa8c48457fdf18c473471dd49b4).
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [804] [INFO ] Freeing task resources for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (35921e838cfa72504f1bd219144e4a5f).
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (c225dfa8c48457fdf18c473471dd49b4) [CANCELED]
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map -> Sink: Print to Std. Out c225dfa8c48457fdf18c473471dd49b4.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-6] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (c52a42f18e1a0db0328dc0d681947ba3) switched from CANCELING to CANCELED.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [831] [INFO ] Ensuring all FileSystem streams are closed for task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (35921e838cfa72504f1bd219144e4a5f) [CANCELED]
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [1438] [INFO ] Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Map -> Sink: Print to Std. Out 35921e838cfa72504f1bd219144e4a5f.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-6] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (6e20b444ef932b409b25463ab79287dc) switched from CANCELING to CANCELED.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-6] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (c225dfa8c48457fdf18c473471dd49b4) switched from CANCELING to CANCELED.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-6] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (35921e838cfa72504f1bd219144e4a5f) switched from CANCELING to CANCELED.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-6] [1446] [INFO ] Try to restart or fail the job Flink Streaming Job (b494e0c8586cd374f4daf94e56b080ea) if no longer possible.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-6] [1324] [INFO ] Job Flink Streaming Job (b494e0c8586cd374f4daf94e56b080ea) switched from state FAILING to FAILED.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unexpected character ('<' (code 60)): expected a valid value (number, String, array, object, 'true', 'false' or 'null')
 at [Source: (byte[])"<dependency>"; line: 1, column: 2]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:212) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.performDefaultAction(SourceStreamTask.java:132) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:298) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:403) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_131]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unexpected character ('<' (code 60)): expected a valid value (number, String, array, object, 'true', 'false' or 'null')
 at [Source: (byte[])"<dependency>"; line: 1, column: 2]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1804) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:693) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportUnexpectedChar(ParserMinimalBase.java:591) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser._handleUnexpectedValue(UTF8StreamJsonParser.java:2630) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser._nextTokenNotInObject(UTF8StreamJsonParser.java:832) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextToken(UTF8StreamJsonParser.java:729) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:4141) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4000) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:202) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-6] [1472] [INFO ] Could not restart the job Flink Streaming Job (b494e0c8586cd374f4daf94e56b080ea) because the restart strategy prevented it.
java.lang.Exception: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unexpected character ('<' (code 60)): expected a valid value (number, String, array, object, 'true', 'false' or 'null')
 at [Source: (byte[])"<dependency>"; line: 1, column: 2]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.checkThrowSourceExecutionException(SourceStreamTask.java:212) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask.performDefaultAction(SourceStreamTask.java:132) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.run(StreamTask.java:298) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:403) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:705) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:530) ~[flink-runtime_2.11-1.9.0.jar:1.9.0]
	at java.lang.Thread.run(Thread.java:748) ~[na:1.8.0_131]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParseException: Unexpected character ('<' (code 60)): expected a valid value (number, String, array, object, 'true', 'false' or 'null')
 at [Source: (byte[])"<dependency>"; line: 1, column: 2]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.JsonParser._constructError(JsonParser.java:1804) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportError(ParserMinimalBase.java:693) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.base.ParserMinimalBase._reportUnexpectedChar(ParserMinimalBase.java:591) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser._handleUnexpectedValue(UTF8StreamJsonParser.java:2630) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser._nextTokenNotInObject(UTF8StreamJsonParser.java:832) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.core.json.UTF8StreamJsonParser.nextToken(UTF8StreamJsonParser.java:729) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:4141) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4000) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3091) ~[flink-shaded-jackson-2.9.8-7.0.jar:2.9.8-7.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:64) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.util.serialization.JSONKeyValueDeserializationSchema.deserialize(JSONKeyValueDeserializationSchema.java:42) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.internal.KafkaFetcher.runFetchLoop(KafkaFetcher.java:140) ~[flink-connector-kafka_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase.run(FlinkKafkaConsumerBase.java:715) ~[flink-connector-kafka-base_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:100) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.api.operators.StreamSource.run(StreamSource.java:63) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
	at org.apache.flink.streaming.runtime.tasks.SourceStreamTask$LegacySourceFunctionThread.run(SourceStreamTask.java:202) ~[flink-streaming-java_2.11-1.9.0.jar:1.9.0]
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.checkpoint.CheckpointCoordinator] [flink-akka.actor.default-dispatcher-6] [329] [INFO ] Stopping checkpoint coordinator for job b494e0c8586cd374f4daf94e56b080ea.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore] [flink-akka.actor.default-dispatcher-6] [97] [INFO ] Shutting down
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-3] [775] [INFO ] Job b494e0c8586cd374f4daf94e56b080ea reached globally terminal state FAILED.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [417] [INFO ] Shutting down Flink Mini Cluster
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.rest.RestServerEndpoint] [main] [290] [INFO ] Shutting down rest endpoint.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [334] [INFO ] Stopping TaskExecutor akka://flink/user/taskmanager_0.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-6] [335] [INFO ] Stopping the JobMaster for job Flink Streaming Job(b494e0c8586cd374f4daf94e56b080ea).
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-4] [142] [INFO ] Stop job leader service.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager] [flink-akka.actor.default-dispatcher-4] [213] [INFO ] Shutting down TaskExecutorLocalStateStoresManager.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-6] [228] [INFO ] Suspending SlotPool.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-6] [1010] [INFO ] Close ResourceManager connection 199d75865d69c45aa123492d8ea1f39c: JobManager is shutting down..
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-6] [249] [INFO ] Stopping SlotPool.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-3] [774] [INFO ] Disconnect job manager 9106ef05e117becf6cf9f41a8f8e457c@akka://flink/user/jobmanager_1 for job b494e0c8586cd374f4daf94e56b080ea from the resource manager.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [flink-akka.actor.default-dispatcher-4] [112] [INFO ] FileChannelManager removed spill file directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-io-e400e5da-7ac0-4bdd-8cec-1af4f470a394
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.io.network.NettyShuffleEnvironment] [flink-akka.actor.default-dispatcher-4] [304] [INFO ] Shutting down the network environment and its components.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.webmonitor.WebMonitorEndpoint] [ForkJoinPool.commonPool-worker-1] [687] [INFO ] Removing cache directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-web-ui
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.rest.RestServerEndpoint] [ForkJoinPool.commonPool-worker-1] [299] [INFO ] Shut down complete.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [flink-akka.actor.default-dispatcher-4] [112] [INFO ] FileChannelManager removed spill file directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-netty-shuffle-00b93a9f-6d1d-4c6c-910a-5931a437cfbb
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskexecutor.KvStateService] [flink-akka.actor.default-dispatcher-4] [119] [INFO ] Shutting down the kvState service and its components.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-4] [142] [INFO ] Stop job leader service.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.filecache.FileCache] [flink-akka.actor.default-dispatcher-4] [153] [INFO ] removed file cache directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-dist-cache-dbf10f2f-380f-470e-b0e6-774288969c68
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-2] [499] [INFO ] Shut down cluster because application is in CANCELED, diagnostics DispatcherResourceManagerComponent has been closed..
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-4] [359] [INFO ] Stopped TaskExecutor akka://flink/user/taskmanager_0.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-6] [220] [INFO ] Stopping dispatcher akka://flink/user/dispatcher.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl] [flink-akka.actor.default-dispatcher-4] [280] [INFO ] Closing the SlotManager.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-6] [697] [INFO ] Stopping all currently running jobs of dispatcher akka://flink/user/dispatcher.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl] [flink-akka.actor.default-dispatcher-4] [243] [INFO ] Suspending the SlotManager.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.rest.handler.legacy.backpressure.StackTraceSampleCoordinator] [flink-akka.actor.default-dispatcher-6] [220] [INFO ] Shutting down stack trace sample coordinator.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-6] [229] [INFO ] Stopped dispatcher akka://flink/user/dispatcher.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [flink-akka.actor.default-dispatcher-6] [335] [INFO ] Stopping Akka RPC service.
[2019-11-28 00:44:26.026] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-2] [83] [INFO ] Shutting down remote daemon.
[2019-11-28 00:44:26.026] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-2] [83] [INFO ] Remote daemon shut down; proceeding with flushing remote transports.
[2019-11-28 00:44:26.026] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-2] [83] [INFO ] Remoting shut down.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [flink-metrics-2] [335] [INFO ] Stopping Akka RPC service.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [flink-metrics-2] [354] [INFO ] Stopped Akka RPC service.
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.blob.AbstractBlobCache] [flink-akka.actor.default-dispatcher-4] [247] [INFO ] Shutting down BLOB cache
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.blob.AbstractBlobCache] [flink-akka.actor.default-dispatcher-4] [247] [INFO ] Shutting down BLOB cache
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.blob.BlobServer] [flink-akka.actor.default-dispatcher-4] [340] [INFO ] Stopped BLOB server at 0.0.0.0:53117
[2019-11-28 00:44:26.026] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [flink-akka.actor.default-dispatcher-4] [354] [INFO ] Stopped Akka RPC service.
[2019-11-28 00:44:27.027] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [675] [INFO ] [Consumer clientId=consumer-13, groupId=test] Discovered group coordinator 192.168.1.14:9092 (id: 2147483647 rack: null)
[2019-11-28 00:44:33.033] [org.apache.flink.api.java.typeutils.TypeExtractor] [main] [1815] [INFO ] class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a getter for field _children
[2019-11-28 00:44:33.033] [org.apache.flink.api.java.typeutils.TypeExtractor] [main] [1818] [INFO ] class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode does not contain a setter for field _children
[2019-11-28 00:44:33.033] [org.apache.flink.api.java.typeutils.TypeExtractor] [main] [1857] [INFO ] Class class org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.node.ObjectNode cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:44:33.033] [org.apache.flink.streaming.api.environment.LocalStreamEnvironment] [main] [108] [INFO ] Running job on local embedded Flink mini cluster
[2019-11-28 00:44:33.033] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [254] [INFO ] Starting Flink Mini Cluster
[2019-11-28 00:44:33.033] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [263] [INFO ] Starting Metrics Registry
[2019-11-28 00:44:33.033] [org.apache.flink.runtime.metrics.MetricRegistryImpl] [main] [114] [INFO ] No metrics reporter configured, no metrics will be exposed/reported.
[2019-11-28 00:44:33.033] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [267] [INFO ] Starting RPC Service(s)
[2019-11-28 00:44:33.033] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1] [flink-akka.actor.default-dispatcher-2] [92] [INFO ] Slf4jLogger started
[2019-11-28 00:44:33.033] [org.apache.flink.runtime.clusterframework.BootstrapTools] [main] [244] [INFO ] Trying to start actor system at :0
[2019-11-28 00:44:33.033] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1] [flink-metrics-2] [92] [INFO ] Slf4jLogger started
[2019-11-28 00:44:33.033] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-2] [83] [INFO ] Starting remoting
[2019-11-28 00:44:34.034] [akka.event.slf4j.Slf4jLogger$$anonfun$receive$1$$anonfun$applyOrElse$3] [flink-metrics-2] [83] [INFO ] Remoting started; listening on addresses :[akka.tcp://flink-metrics@192.168.1.14:53135]
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.clusterframework.BootstrapTools] [main] [256] [INFO ] Actor system started at akka.tcp://flink-metrics@192.168.1.14:53135
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/MetricQueryService .
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [398] [INFO ] Starting high-availability services
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.blob.BlobServer] [main] [141] [INFO ] Created BLOB server storage directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/blobStore-75c15de0-ed72-4839-927e-b27a5279fd57
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.blob.BlobServer] [main] [203] [INFO ] Started BLOB server at 0.0.0.0:53136 - max concurrent requests: 50 - max backlog: 1000
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.blob.AbstractBlobCache] [main] [107] [INFO ] Created BLOB cache storage directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/blobStore-65dba63c-e4aa-4505-890e-6dd7f5f92231
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.blob.AbstractBlobCache] [main] [107] [INFO ] Created BLOB cache storage directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/blobStore-ef025539-1727-4816-a90e-9948d0e2e185
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [480] [INFO ] Starting 1 TaskManger(s)
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.taskexecutor.TaskManagerRunner] [main] [351] [INFO ] Starting TaskManager with ResourceID: 7d7a44e3-8d5f-4434-b77c-6f0308040893
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.taskexecutor.TaskManagerServices] [main] [519] [INFO ] Temporary file directory '/var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T': total 233 GB, usable 169 GB (72.53% usable)
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [main] [76] [INFO ] FileChannelManager uses directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-io-c8e9ded8-e77b-4c9a-bd4f-29d2a58e0699 for spill files.
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [main] [76] [INFO ] FileChannelManager uses directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-netty-shuffle-e9ed01f8-3618-44e4-813d-80428418fa81 for spill files.
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.io.network.buffer.NetworkBufferPool] [main] [140] [INFO ] Allocated 202 MB for network buffer pool (number of memory segments: 6472, bytes per segment: 32768).
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.io.network.NettyShuffleEnvironment] [main] [283] [INFO ] Starting the network environment and its components.
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.taskexecutor.KvStateService] [main] [89] [INFO ] Starting the kvState service and its components.
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.taskexecutor.TaskManagerServices] [main] [364] [INFO ] Limiting managed memory to 0.7 of the currently free heap space (1267 MB), memory will be allocated lazily.
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.taskexecutor.TaskManagerConfiguration] [main] [197] [INFO ] Messages have a max timeout of 10000 ms
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/taskmanager_0 .
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-2] [125] [INFO ] Start job leader service.
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.filecache.FileCache] [flink-akka.actor.default-dispatcher-2] [107] [INFO ] User file cache uses directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-dist-cache-fca88aac-bbe1-4f2a-9133-6135108f7ff8
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.rest.RestServerEndpoint] [main] [136] [INFO ] Starting rest endpoint.
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.webmonitor.WebMonitorUtils$LogFileLocation] [main] [87] [WARN ] Log file environment variable 'log.file' is not set.
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.webmonitor.WebMonitorUtils$LogFileLocation] [main] [93] [WARN ] JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'Key: 'web.log.path' , default: null (fallback keys: [{key=jobmanager.web.log.path, isDeprecated=true}])'.
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint] [main] [114] [INFO ] Failed to load web based job submission extension. Probable reason: flink-runtime-web is not in the classpath.
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.rest.RestServerEndpoint] [main] [233] [INFO ] Rest endpoint listening at localhost:53137
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [main] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint@42b21d99 @ http://localhost:53137
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.webmonitor.WebMonitorEndpoint] [mini-cluster-io-thread-1] [711] [INFO ] http://localhost:53137 was granted leadership with leaderSessionID=d0f6ae6f-c7f5-4912-8d56-3080ff41e932
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [mini-cluster-io-thread-1] [250] [INFO ] Received confirmation of leadership for leader http://localhost:53137 , session=d0f6ae6f-c7f5-4912-8d56-3080ff41e932
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/resourcemanager .
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [main] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/dispatcher .
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-2] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.resourcemanager.StandaloneResourceManager@3cb1568e @ akka://flink/user/resourcemanager
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-3] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.dispatcher.StandaloneDispatcher@21d0e909 @ akka://flink/user/dispatcher
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-3] [885] [INFO ] Dispatcher akka://flink/user/dispatcher was granted leadership with fencing token 02ea6a67-1ee4-42dc-a07b-0f078921761e
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-2] [919] [INFO ] ResourceManager akka://flink/user/resourcemanager was granted leadership with fencing token 9de6d6b68b13556e57a4051a8b8147d3
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.minicluster.MiniCluster] [main] [363] [INFO ] Flink Mini Cluster started successfully
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.resourcemanager.slotmanager.SlotManagerImpl] [flink-akka.actor.default-dispatcher-2] [215] [INFO ] Starting the SlotManager.
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-4] [717] [INFO ] Recovering all persisted jobs.
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-3] [250] [INFO ] Received confirmation of leadership for leader akka://flink/user/dispatcher , session=02ea6a67-1ee4-42dc-a07b-0f078921761e
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-2] [250] [INFO ] Received confirmation of leadership for leader akka://flink/user/resourcemanager , session=57a4051a-8b81-47d3-9de6-d6b68b13556e
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [982] [INFO ] Connecting to ResourceManager akka://flink/user/resourcemanager(9de6d6b68b13556e57a4051a8b8147d3).
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-3] [155] [INFO ] Resolved ResourceManager address, beginning registration
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-3] [204] [INFO ] Registration at ResourceManager attempt 1 (timeout=100ms)
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-2] [711] [INFO ] Registering TaskManager with ResourceID 7d7a44e3-8d5f-4434-b77c-6f0308040893 (akka://flink/user/taskmanager_0) at ResourceManager
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-4] [264] [INFO ] Received JobGraph submission 21cccbc4228bbec7403dbe4ff66e51c2 (Flink Streaming Job).
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.taskexecutor.TaskExecutorToResourceManagerConnection] [flink-akka.actor.default-dispatcher-5] [100] [INFO ] Successful registration at resource manager akka://flink/user/resourcemanager under registration id f26d04cc39aa52928d33f081f882d71f.
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.dispatcher.Dispatcher] [flink-akka.actor.default-dispatcher-4] [321] [INFO ] Submitting job 21cccbc4228bbec7403dbe4ff66e51c2 (Flink Streaming Job).
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.rpc.akka.AkkaRpcService] [flink-akka.actor.default-dispatcher-5] [223] [INFO ] Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/jobmanager_1 .
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-5] [241] [INFO ] Initializing job Flink Streaming Job (21cccbc4228bbec7403dbe4ff66e51c2).
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.scheduler.LegacyScheduler] [flink-akka.actor.default-dispatcher-5] [171] [INFO ] Using restart strategy NoRestartStrategy for Flink Streaming Job (21cccbc4228bbec7403dbe4ff66e51c2).
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-5] [516] [INFO ] Job recovers via failover strategy: full graph restart
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.executiongraph.ExecutionGraphBuilder] [flink-akka.actor.default-dispatcher-5] [204] [INFO ] Running initialization on master for job Flink Streaming Job (21cccbc4228bbec7403dbe4ff66e51c2).
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.executiongraph.ExecutionGraphBuilder] [flink-akka.actor.default-dispatcher-5] [222] [INFO ] Successfully ran initialization on master in 0 ms.
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.state.StateBackendLoader] [flink-akka.actor.default-dispatcher-5] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [flink-akka.actor.default-dispatcher-5] [300] [INFO ] Proposing leadership to contender org.apache.flink.runtime.jobmaster.JobManagerRunner@47b66b87 @ akka://flink/user/jobmanager_1
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.jobmaster.JobManagerRunner] [mini-cluster-io-thread-3] [313] [INFO ] JobManager runner for job Flink Streaming Job (21cccbc4228bbec7403dbe4ff66e51c2) was granted leadership with session id 32d16eca-1ec7-4a8d-a728-962483e95a5c at akka://flink/user/jobmanager_1.
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-3] [709] [INFO ] Starting execution of job Flink Streaming Job (21cccbc4228bbec7403dbe4ff66e51c2) under job master id a728962483e95a5c32d16eca1ec74a8d.
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.executiongraph.ExecutionGraph] [flink-akka.actor.default-dispatcher-3] [1324] [INFO ] Job Flink Streaming Job (21cccbc4228bbec7403dbe4ff66e51c2) switched from state CREATED to RUNNING.
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (4572f301ff32d388ca2b894a45f3d061) switched from CREATED to SCHEDULED.
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-3] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{e47bf1a5de405ae28d4d11293ece1bea}]
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (7122c840aa4e6093aa677bdb9be51f52) switched from CREATED to SCHEDULED.
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-3] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{aae64e52f76dfe9678bfc738d781f641}]
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (8406dbb03dc6e8179295ecae40271ef4) switched from CREATED to SCHEDULED.
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-3] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{bd98603332ad7c6dd0942521f55726cf}]
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (13b814fdc2f2c3961ad436177cbf13e7) switched from CREATED to SCHEDULED.
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-3] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{a7032d6b01ad0e20a9b3943db64b0c7c}]
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8) (c87d6182eef0deb4bcf096f07ce393c1) switched from CREATED to SCHEDULED.
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-3] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{b1337e8c331890b39c9aa07069fbf08f}]
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (0af07e808e3bee2d2667d07758039720) switched from CREATED to SCHEDULED.
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-3] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{778f87a8a54b4690c93dc61148a6bc26}]
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (12aea3ac28c5a209e7043e75d4641902) switched from CREATED to SCHEDULED.
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-3] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{801e03987e2cbee528c49c20704b74f6}]
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (1a0ad1eacc56470ef593cda44027d753) switched from CREATED to SCHEDULED.
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-3] [369] [INFO ] Cannot serve slot request, no ResourceManager connected. Adding as pending request [SlotRequestId{f0f02d881493de401e40a6a56721dd44}]
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.highavailability.nonha.embedded.EmbeddedLeaderService] [jobmanager-future-thread-1] [250] [INFO ] Received confirmation of leadership for leader akka://flink/user/jobmanager_1 , session=32d16eca-1ec7-4a8d-a728-962483e95a5c
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-3] [940] [INFO ] Connecting to ResourceManager akka://flink/user/resourcemanager(9de6d6b68b13556e57a4051a8b8147d3)
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-3] [155] [INFO ] Resolved ResourceManager address, beginning registration
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-3] [204] [INFO ] Registration at ResourceManager attempt 1 (timeout=100ms)
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-5] [302] [INFO ] Registering job manager a728962483e95a5c32d16eca1ec74a8d@akka://flink/user/jobmanager_1 for job 21cccbc4228bbec7403dbe4ff66e51c2.
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-4] [657] [INFO ] Registered job manager a728962483e95a5c32d16eca1ec74a8d@akka://flink/user/jobmanager_1 for job 21cccbc4228bbec7403dbe4ff66e51c2.
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.jobmaster.JobMaster] [flink-akka.actor.default-dispatcher-4] [962] [INFO ] JobManager successfully registered at ResourceManager, leader id: 9de6d6b68b13556e57a4051a8b8147d3.
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{e47bf1a5de405ae28d4d11293ece1bea}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-5] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 21cccbc4228bbec7403dbe4ff66e51c2 with allocation id 0b36432477c9980b1f9864ea16e575ef.
[2019-11-28 00:44:34.034] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{aae64e52f76dfe9678bfc738d781f641}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{bd98603332ad7c6dd0942521f55726cf}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [816] [INFO ] Receive slot request 0b36432477c9980b1f9864ea16e575ef for job 21cccbc4228bbec7403dbe4ff66e51c2 from resource manager with leader id 9de6d6b68b13556e57a4051a8b8147d3.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{a7032d6b01ad0e20a9b3943db64b0c7c}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{b1337e8c331890b39c9aa07069fbf08f}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-5] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 21cccbc4228bbec7403dbe4ff66e51c2 with allocation id 9acc44c4155a44685c435d65f508d323.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [828] [INFO ] Allocated slot for 0b36432477c9980b1f9864ea16e575ef.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{778f87a8a54b4690c93dc61148a6bc26}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-3] [193] [INFO ] Add job 21cccbc4228bbec7403dbe4ff66e51c2 for job leader monitoring.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-5] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 21cccbc4228bbec7403dbe4ff66e51c2 with allocation id 6737f3e883f03d393820cacc01aa49c6.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{801e03987e2cbee528c49c20704b74f6}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.jobmaster.slotpool.SlotPoolImpl] [flink-akka.actor.default-dispatcher-4] [319] [INFO ] Requesting new slot [SlotRequestId{f0f02d881493de401e40a6a56721dd44}] and profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} from resource manager.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-5] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 21cccbc4228bbec7403dbe4ff66e51c2 with allocation id 327f8909d660f126b44bf97971c25be0.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [816] [INFO ] Receive slot request 9acc44c4155a44685c435d65f508d323 for job 21cccbc4228bbec7403dbe4ff66e51c2 from resource manager with leader id 9de6d6b68b13556e57a4051a8b8147d3.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-5] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 21cccbc4228bbec7403dbe4ff66e51c2 with allocation id 038686c5c6f58b7ed1a132ce34584aef.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [828] [INFO ] Allocated slot for 9acc44c4155a44685c435d65f508d323.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-1] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 32d16eca-1ec7-4a8d-a728-962483e95a5c.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-3] [193] [INFO ] Add job 21cccbc4228bbec7403dbe4ff66e51c2 for job leader monitoring.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-5] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 21cccbc4228bbec7403dbe4ff66e51c2 with allocation id c7124c283076532472d46312356191fb.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-8] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 32d16eca-1ec7-4a8d-a728-962483e95a5c.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [816] [INFO ] Receive slot request 6737f3e883f03d393820cacc01aa49c6 for job 21cccbc4228bbec7403dbe4ff66e51c2 from resource manager with leader id 9de6d6b68b13556e57a4051a8b8147d3.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-2] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-5] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 21cccbc4228bbec7403dbe4ff66e51c2 with allocation id 730f072b0e1884c746b1b99704566ce8.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [828] [INFO ] Allocated slot for 6737f3e883f03d393820cacc01aa49c6.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-2] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-3] [193] [INFO ] Add job 21cccbc4228bbec7403dbe4ff66e51c2 for job leader monitoring.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-2] [204] [INFO ] Registration at JobManager attempt 1 (timeout=100ms)
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.resourcemanager.ResourceManager] [flink-akka.actor.default-dispatcher-5] [437] [INFO ] Request slot with profile ResourceProfile{cpuCores=-1.0, heapMemoryInMB=-1, directMemoryInMB=-1, nativeMemoryInMB=-1, networkMemoryInMB=-1, managedMemoryInMB=-1} for job 21cccbc4228bbec7403dbe4ff66e51c2 with allocation id fed2cb806b331c559405a71a50b7010a.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-6] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 32d16eca-1ec7-4a8d-a728-962483e95a5c.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [816] [INFO ] Receive slot request 327f8909d660f126b44bf97971c25be0 for job 21cccbc4228bbec7403dbe4ff66e51c2 from resource manager with leader id 9de6d6b68b13556e57a4051a8b8147d3.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [828] [INFO ] Allocated slot for 327f8909d660f126b44bf97971c25be0.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-3] [193] [INFO ] Add job 21cccbc4228bbec7403dbe4ff66e51c2 for job leader monitoring.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-5] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 32d16eca-1ec7-4a8d-a728-962483e95a5c.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [816] [INFO ] Receive slot request 038686c5c6f58b7ed1a132ce34584aef for job 21cccbc4228bbec7403dbe4ff66e51c2 from resource manager with leader id 9de6d6b68b13556e57a4051a8b8147d3.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-2] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [828] [INFO ] Allocated slot for 038686c5c6f58b7ed1a132ce34584aef.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-5] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-3] [193] [INFO ] Add job 21cccbc4228bbec7403dbe4ff66e51c2 for job leader monitoring.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-5] [204] [INFO ] Registration at JobManager attempt 1 (timeout=100ms)
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-7] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 32d16eca-1ec7-4a8d-a728-962483e95a5c.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [816] [INFO ] Receive slot request c7124c283076532472d46312356191fb for job 21cccbc4228bbec7403dbe4ff66e51c2 from resource manager with leader id 9de6d6b68b13556e57a4051a8b8147d3.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [828] [INFO ] Allocated slot for c7124c283076532472d46312356191fb.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-3] [193] [INFO ] Add job 21cccbc4228bbec7403dbe4ff66e51c2 for job leader monitoring.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-5] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-3] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 32d16eca-1ec7-4a8d-a728-962483e95a5c.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [816] [INFO ] Receive slot request 730f072b0e1884c746b1b99704566ce8 for job 21cccbc4228bbec7403dbe4ff66e51c2 from resource manager with leader id 9de6d6b68b13556e57a4051a8b8147d3.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [828] [INFO ] Allocated slot for 730f072b0e1884c746b1b99704566ce8.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-3] [193] [INFO ] Add job 21cccbc4228bbec7403dbe4ff66e51c2 for job leader monitoring.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-2] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-2] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 32d16eca-1ec7-4a8d-a728-962483e95a5c.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [816] [INFO ] Receive slot request fed2cb806b331c559405a71a50b7010a for job 21cccbc4228bbec7403dbe4ff66e51c2 from resource manager with leader id 9de6d6b68b13556e57a4051a8b8147d3.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-3] [828] [INFO ] Allocated slot for fed2cb806b331c559405a71a50b7010a.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.JobLeaderService] [flink-akka.actor.default-dispatcher-3] [193] [INFO ] Add job 21cccbc4228bbec7403dbe4ff66e51c2 for job leader monitoring.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-2] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener] [mini-cluster-io-thread-4] [333] [INFO ] Try to register at job manager akka://flink/user/jobmanager_1 with leader id 32d16eca-1ec7-4a8d-a728-962483e95a5c.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-4] [155] [INFO ] Resolved JobManager address, beginning registration
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.registration.RetryingRegistration] [flink-akka.actor.default-dispatcher-4] [204] [INFO ] Registration at JobManager attempt 1 (timeout=100ms)
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.JobLeaderService$JobManagerLeaderListener$JobManagerRegisteredRpcConnection] [flink-akka.actor.default-dispatcher-2] [382] [INFO ] Successful registration at job manager akka://flink/user/jobmanager_1 for job 21cccbc4228bbec7403dbe4ff66e51c2.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [1220] [INFO ] Establish JobManager connection for job 21cccbc4228bbec7403dbe4ff66e51c2.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [1121] [INFO ] Offer reserved slots to the leader of job 21cccbc4228bbec7403dbe4ff66e51c2.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (4572f301ff32d388ca2b894a45f3d061) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [712] [INFO ] Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (attempt #0) to 7d7a44e3-8d5f-4434-b77c-6f0308040893 @ localhost (dataPort=-1)
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (7122c840aa4e6093aa677bdb9be51f52) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [712] [INFO ] Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (attempt #0) to 7d7a44e3-8d5f-4434-b77c-6f0308040893 @ localhost (dataPort=-1)
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (8406dbb03dc6e8179295ecae40271ef4) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [712] [INFO ] Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (attempt #0) to 7d7a44e3-8d5f-4434-b77c-6f0308040893 @ localhost (dataPort=-1)
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (13b814fdc2f2c3961ad436177cbf13e7) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [712] [INFO ] Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (attempt #0) to 7d7a44e3-8d5f-4434-b77c-6f0308040893 @ localhost (dataPort=-1)
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8) (c87d6182eef0deb4bcf096f07ce393c1) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [712] [INFO ] Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8) (attempt #0) to 7d7a44e3-8d5f-4434-b77c-6f0308040893 @ localhost (dataPort=-1)
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (0af07e808e3bee2d2667d07758039720) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [712] [INFO ] Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (attempt #0) to 7d7a44e3-8d5f-4434-b77c-6f0308040893 @ localhost (dataPort=-1)
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (12aea3ac28c5a209e7043e75d4641902) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [712] [INFO ] Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (attempt #0) to 7d7a44e3-8d5f-4434-b77c-6f0308040893 @ localhost (dataPort=-1)
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (1a0ad1eacc56470ef593cda44027d753) switched from SCHEDULED to DEPLOYING.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-5] [712] [INFO ] Deploying Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (attempt #0) to 7d7a44e3-8d5f-4434-b77c-6f0308040893 @ localhost (dataPort=-1)
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8).
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (4572f301ff32d388ca2b894a45f3d061) switched from CREATED to DEPLOYING.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (4572f301ff32d388ca2b894a45f3d061) [DEPLOYING]
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (4572f301ff32d388ca2b894a45f3d061) [DEPLOYING].
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8).
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (7122c840aa4e6093aa677bdb9be51f52) switched from CREATED to DEPLOYING.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (7122c840aa4e6093aa677bdb9be51f52) [DEPLOYING]
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (4572f301ff32d388ca2b894a45f3d061) [DEPLOYING].
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (7122c840aa4e6093aa677bdb9be51f52) [DEPLOYING].
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8).
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (7122c840aa4e6093aa677bdb9be51f52) [DEPLOYING].
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (8406dbb03dc6e8179295ecae40271ef4) switched from CREATED to DEPLOYING.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (8406dbb03dc6e8179295ecae40271ef4) [DEPLOYING]
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (8406dbb03dc6e8179295ecae40271ef4) [DEPLOYING].
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (8406dbb03dc6e8179295ecae40271ef4) [DEPLOYING].
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8).
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (13b814fdc2f2c3961ad436177cbf13e7) switched from CREATED to DEPLOYING.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (13b814fdc2f2c3961ad436177cbf13e7) [DEPLOYING]
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (13b814fdc2f2c3961ad436177cbf13e7) [DEPLOYING].
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (13b814fdc2f2c3961ad436177cbf13e7) [DEPLOYING].
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8).
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8) (c87d6182eef0deb4bcf096f07ce393c1) switched from CREATED to DEPLOYING.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8) (c87d6182eef0deb4bcf096f07ce393c1) [DEPLOYING]
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8) (c87d6182eef0deb4bcf096f07ce393c1) [DEPLOYING].
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8) (c87d6182eef0deb4bcf096f07ce393c1) [DEPLOYING].
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (7122c840aa4e6093aa677bdb9be51f52) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (13b814fdc2f2c3961ad436177cbf13e7) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (8406dbb03dc6e8179295ecae40271ef4) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (4572f301ff32d388ca2b894a45f3d061) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8).
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8) (c87d6182eef0deb4bcf096f07ce393c1) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8) (7122c840aa4e6093aa677bdb9be51f52) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (0af07e808e3bee2d2667d07758039720) switched from CREATED to DEPLOYING.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8) (13b814fdc2f2c3961ad436177cbf13e7) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (0af07e808e3bee2d2667d07758039720) [DEPLOYING]
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8) (8406dbb03dc6e8179295ecae40271ef4) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (0af07e808e3bee2d2667d07758039720) [DEPLOYING].
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8) (4572f301ff32d388ca2b894a45f3d061) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8) (c87d6182eef0deb4bcf096f07ce393c1) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8).
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (0af07e808e3bee2d2667d07758039720) [DEPLOYING].
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (12aea3ac28c5a209e7043e75d4641902) switched from CREATED to DEPLOYING.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (12aea3ac28c5a209e7043e75d4641902) [DEPLOYING]
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (12aea3ac28c5a209e7043e75d4641902) [DEPLOYING].
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (0af07e808e3bee2d2667d07758039720) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-4] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8) (0af07e808e3bee2d2667d07758039720) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.TaskExecutor] [flink-akka.actor.default-dispatcher-2] [587] [INFO ] Received task Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8).
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (12aea3ac28c5a209e7043e75d4641902) [DEPLOYING].
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (12aea3ac28c5a209e7043e75d4641902) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 327f8909d660f126b44bf97971c25be0.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 038686c5c6f58b7ed1a132ce34584aef.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (1a0ad1eacc56470ef593cda44027d753) switched from CREATED to DEPLOYING.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-3] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8) (12aea3ac28c5a209e7043e75d4641902) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 730f072b0e1884c746b1b99704566ce8.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [586] [INFO ] Creating FileSystem stream leak safety net for task Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (1a0ad1eacc56470ef593cda44027d753) [DEPLOYING]
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot c7124c283076532472d46312356191fb.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [593] [INFO ] Loading JAR files for task Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (1a0ad1eacc56470ef593cda44027d753) [DEPLOYING].
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 6737f3e883f03d393820cacc01aa49c6.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot fed2cb806b331c559405a71a50b7010a.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 9acc44c4155a44685c435d65f508d323.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskexecutor.slot.TaskSlotTable] [flink-akka.actor.default-dispatcher-2] [237] [INFO ] Activate slot 0b36432477c9980b1f9864ea16e575ef.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [619] [INFO ] Registering task at network: Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (1a0ad1eacc56470ef593cda44027d753) [DEPLOYING].
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.taskmanager.Task] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [958] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (1a0ad1eacc56470ef593cda44027d753) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.state.StateBackendLoader] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [227] [INFO ] No state backend has been configured, using default (Memory / JobManager) MemoryStateBackend (data in heap memory / checkpoints to JobManager) (checkpoints: 'null', savepoints: 'null', asynchronous: TRUE, maxStateSize: 5242880)
[2019-11-28 00:44:35.035] [org.apache.flink.runtime.executiongraph.Execution] [flink-akka.actor.default-dispatcher-2] [1491] [INFO ] Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8) (1a0ad1eacc56470ef593cda44027d753) switched from DEPLOYING to RUNNING.
[2019-11-28 00:44:35.035] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:44:35.035] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:44:35.035] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:44:35.035] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:44:35.035] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:44:35.035] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:44:35.035] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:44:35.035] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [1818] [INFO ] class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition does not contain a setter for field topic
[2019-11-28 00:44:35.035] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:44:35.035] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:44:35.035] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:44:35.035] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:44:35.035] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:44:35.035] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:44:35.035] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:44:35.035] [org.apache.flink.api.java.typeutils.TypeExtractor] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [1857] [INFO ] Class class org.apache.flink.streaming.connectors.kafka.internals.KafkaTopicPartition cannot be used as a POJO type because not all fields are valid POJO fields, and must be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance.
[2019-11-28 00:44:35.035] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [886] [INFO ] Consumer subtask 0 has no restore state.
[2019-11-28 00:44:35.035] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [886] [INFO ] Consumer subtask 2 has no restore state.
[2019-11-28 00:44:35.035] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [886] [INFO ] Consumer subtask 7 has no restore state.
[2019-11-28 00:44:35.035] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [886] [INFO ] Consumer subtask 5 has no restore state.
[2019-11-28 00:44:35.035] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [886] [INFO ] Consumer subtask 1 has no restore state.
[2019-11-28 00:44:35.035] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [886] [INFO ] Consumer subtask 6 has no restore state.
[2019-11-28 00:44:35.035] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [886] [INFO ] Consumer subtask 3 has no restore state.
[2019-11-28 00:44:35.035] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [886] [INFO ] Consumer subtask 4 has no restore state.
[2019-11-28 00:44:35.035] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:35.035] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:35.035] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:35.035] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:35.035] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:35.035] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:35.035] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:35.035] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:35.035] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:35.035] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:35.035] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:35.035] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:35.035] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:35.035] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:35.035] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:35.035] [org.apache.kafka.common.config.AbstractConfig] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:35.035] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:35.035] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:35.035] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:35.035] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:35.035] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:35.035] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:35.035] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:35.035] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:35.035] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:35.035] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:35.035] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:35.035] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:35.035] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:35.035] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:35.035] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:35.035] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:35.035] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:44:35.035] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:44:35.035] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:44:35.035] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:44:35.035] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:44:35.035] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:44:35.035] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:44:35.035] [org.apache.kafka.clients.Metadata] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:44:35.035] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [651] [INFO ] Consumer subtask 2 initially has no partitions to read from.
[2019-11-28 00:44:35.035] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [651] [INFO ] Consumer subtask 0 initially has no partitions to read from.
[2019-11-28 00:44:35.035] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [651] [INFO ] Consumer subtask 6 initially has no partitions to read from.
[2019-11-28 00:44:35.035] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [651] [INFO ] Consumer subtask 7 initially has no partitions to read from.
[2019-11-28 00:44:35.035] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [651] [INFO ] Consumer subtask 5 initially has no partitions to read from.
[2019-11-28 00:44:35.035] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [651] [INFO ] Consumer subtask 3 initially has no partitions to read from.
[2019-11-28 00:44:35.035] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [651] [INFO ] Consumer subtask 1 initially has no partitions to read from.
[2019-11-28 00:44:35.035] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [610] [INFO ] Consumer subtask 4 will start reading the following 1 partitions from the latest offsets: [KafkaTopicPartition{topic='ota', partition=0}]
[2019-11-28 00:44:35.035] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-8] [688] [INFO ] Consumer subtask 1 creating fetcher with offsets {}.
[2019-11-28 00:44:35.035] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-13] [688] [INFO ] Consumer subtask 6 creating fetcher with offsets {}.
[2019-11-28 00:44:35.035] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-14] [688] [INFO ] Consumer subtask 7 creating fetcher with offsets {}.
[2019-11-28 00:44:35.035] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-7] [688] [INFO ] Consumer subtask 3 creating fetcher with offsets {}.
[2019-11-28 00:44:35.035] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-11] [688] [INFO ] Consumer subtask 4 creating fetcher with offsets {KafkaTopicPartition{topic='ota', partition=0}=-915623761774}.
[2019-11-28 00:44:35.035] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-12] [688] [INFO ] Consumer subtask 5 creating fetcher with offsets {}.
[2019-11-28 00:44:35.035] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-10] [688] [INFO ] Consumer subtask 0 creating fetcher with offsets {}.
[2019-11-28 00:44:35.035] [org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase] [Thread-9] [688] [INFO ] Consumer subtask 2 creating fetcher with offsets {}.
[2019-11-28 00:44:35.035] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:35.035] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:35.035] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:35.035] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:35.035] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:35.035] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:35.035] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:35.035] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [279] [INFO ] ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:9092]
	check.crcs = true
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = test
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

[2019-11-28 00:44:35.035] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:35.035] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:35.035] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (3/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:35.035] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:35.035] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:35.035] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:35.035] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:35.035] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:35.035] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (7/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:35.035] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:35.035] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:35.035] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:35.035] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (4/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:35.035] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:35.035] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:35.035] [org.apache.kafka.common.config.AbstractConfig] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [287] [WARN ] The configuration 'zookeeper.connect' was supplied but isn't a known config.
[2019-11-28 00:44:35.035] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:35.035] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (1/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:35.035] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:35.035] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (2/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:35.035] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:35.035] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (8/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:35.035] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [109] [INFO ] Kafka version: 2.2.0
[2019-11-28 00:44:35.035] [org.apache.kafka.common.utils.AppInfoParser$AppInfo] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (6/8)] [110] [INFO ] Kafka commitId: 05fcfde8f69b0349
[2019-11-28 00:44:35.035] [org.apache.kafka.clients.consumer.KafkaConsumer] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [1090] [INFO ] [Consumer clientId=consumer-9, groupId=test] Subscribed to partition(s): ota-0
[2019-11-28 00:44:35.035] [org.apache.kafka.clients.Metadata] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [365] [INFO ] Cluster ID: Ie4tx2IzSmGFBYLQUtT9xQ
[2019-11-28 00:44:35.035] [org.apache.kafka.clients.consumer.internals.Fetcher] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [584] [INFO ] [Consumer clientId=consumer-9, groupId=test] Resetting offset for partition ota-0 to offset 20.
[2019-11-28 00:44:40.040] [org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler] [Kafka Fetcher for Source: Custom Source -> Map -> Sink: Print to Std. Out (5/8)] [675] [INFO ] [Consumer clientId=consumer-9, groupId=test] Discovered group coordinator 192.168.1.14:9092 (id: 2147483647 rack: null)
[2019-11-28 00:46:25.025] [org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager] [TaskExecutorLocalStateStoresManager shutdown hook] [213] [INFO ] Shutting down TaskExecutorLocalStateStoresManager.
[2019-11-28 00:46:25.025] [org.apache.flink.runtime.blob.AbstractBlobCache] [TransientBlobCache shutdown hook] [247] [INFO ] Shutting down BLOB cache
[2019-11-28 00:46:25.025] [org.apache.flink.runtime.blob.AbstractBlobCache] [PermanentBlobCache shutdown hook] [247] [INFO ] Shutting down BLOB cache
[2019-11-28 00:46:25.025] [org.apache.flink.runtime.io.disk.FileChannelManagerImpl] [IOManagerAsync shutdown hook] [112] [INFO ] FileChannelManager removed spill file directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-io-c8e9ded8-e77b-4c9a-bd4f-29d2a58e0699
[2019-11-28 00:46:25.025] [org.apache.flink.runtime.filecache.FileCache] [FileCache shutdown hook] [153] [INFO ] removed file cache directory /var/folders/01/fk7f6yq52931j3wtp_71n9n80000gn/T/flink-dist-cache-fca88aac-bbe1-4f2a-9133-6135108f7ff8
[2019-11-28 00:46:25.025] [org.apache.flink.runtime.blob.BlobServer] [BlobServer shutdown hook] [340] [INFO ] Stopped BLOB server at 0.0.0.0:53136
